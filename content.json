{"meta":{"title":"宇航员不会飞","subtitle":"里面的人想出去，外面的人想进来","description":"很多事情就像是旅行一样，当你决定要出发的时候，最困难的那部分其实就已经完成了","author":"白日梦想家","url":"https://yugd.cn","root":"/"},"pages":[{"title":"","date":"2021-09-20T21:04:02.813Z","updated":"2021-09-20T21:03:03.921Z","comments":true,"path":"404.html","permalink":"https://yugd.cn/404.html","excerpt":"","text":"额...走丢了哦~ .primary{ background:#2d8cf0; border: 0; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.2); /*margin-left: 160px;*/ border-radius: 15px; color: white; width: 250px; height: 50px; font-size: 18px; } .error-page { display: flex; justify-content: center; align-items: center; flex-direction: column; width: 100%; height: 100%; /*background: #f3f3f3;*/ box-sizing: border-box; } .error-code { line-height: 1; font-size: 250px; font-weight: bolder; color: #2d8cf0; } .error-code span { color: #00a854; } .error-desc { font-size: 30px; color: #777; } .error-handle { margin-top: 30px; padding-bottom: 200px; } .error-btn { margin-left: 100px; } 404 啊哦~ 你所访问的页面不存在"},{"title":" ","date":"2021-09-20T20:48:14.000Z","updated":"2021-10-26T14:21:26.822Z","comments":false,"path":"/404.html","permalink":"https://yugd.cn/404.html","excerpt":"","text":"额...走丢了哦~ .primary{ background:#2d8cf0; border: 0; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.2); /*margin-left: 160px;*/ border-radius: 15px; color: white; width: 250px; height: 50px; font-size: 18px; } .error-page { display: flex; justify-content: center; align-items: center; flex-direction: column; width: 100%; height: 100%; /*background: #f3f3f3;*/ box-sizing: border-box; } .error-code { line-height: 1; font-size: 250px; font-weight: bolder; color: #2d8cf0; } .error-code span { color: #00a854; } .error-desc { font-size: 30px; color: #777; } .error-handle { margin-top: 30px; padding-bottom: 200px; } .error-btn { margin-left: 100px; } 404 啊哦~ 你所访问的页面不存在"},{"title":"关于我","date":"2020-09-26T12:19:30.000Z","updated":"2022-05-27T00:54:53.680Z","comments":true,"path":"about/index.html","permalink":"https://yugd.cn/about/index.html","excerpt":"","text":"我相信3月许过的愿，9月能实现 如果有时间，多读读书，出去看看。"},{"title":"分类","date":"2020-05-16T06:29:58.000Z","updated":"2021-10-10T16:26:54.091Z","comments":false,"path":"categories/index.html","permalink":"https://yugd.cn/categories/index.html","excerpt":"","text":""},{"title":"留言板","date":"2021-09-19T22:14:40.000Z","updated":"2021-10-10T16:40:14.294Z","comments":true,"path":"guestbook/index.html","permalink":"https://yugd.cn/guestbook/index.html","excerpt":"","text":"欢迎来到我的博客！ 欢迎在这里留言！任何问题都可以在这里留言，我会及时回复的，添加email可以获得更快的回复速度，在nickname栏目输入QQ号可以直接获取你的QQ头像。"},{"title":"标签","date":"2020-09-26T12:08:39.000Z","updated":"2021-09-19T23:01:53.288Z","comments":false,"path":"tags/index.html","permalink":"https://yugd.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"面试--JUC-函数式接口","slug":"面试--JUC-函数式接口","date":"2022-09-10T01:00:00.000Z","updated":"2022-09-11T19:17:19.010Z","comments":true,"path":"posts/34600/","link":"","permalink":"https://yugd.cn/posts/34600/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 写在前面 进阶 JUC …","text":"每天一篇面试小知识 本篇着重介绍一下 写在前面 进阶 JUC … 所在包 名称 构成 方法 意思 java.util.function.Function 功能型函数接口 T =&gt; R apply() 申请 java.util.function.Predicate 断言型接口 T =&gt; true/false test() 测试 java.util.function.Supplier 供给型接口 （）=&gt;T get() 获取 java.util.function.Consumer 消费型接口 T accept() 接受 1.Function接口Function接口是对实例进行处理转换的接口，定义了一个名叫apply()的抽象方法，传入一个泛型T对象，并返回一个泛型R对象。 123456// 定义Object&lt;T&gt; -&gt; Object&lt;R&gt;//实例：入参求和Function&lt;Integer, Integer&gt; function = (num) -&gt; num + num; 2.Predicate接口Predicate接口是判断是与否的接口，定义了一个名叫test的抽象方法，传入一个泛型T对象，并返回一个boolean类型。 123456// 定义Object&lt;T&gt; -&gt; true/false //实例：判定true/falsePredicate&lt;String&gt; predicate = str -&gt; \"s\".startsWith(str) ? true : false;Predicate&lt;Integer&gt; predicate = num -&gt; num &gt; num * num; 3.Supplier接口Supplier接口是对象实例的提供者，定义了一个名叫get的抽象方法，它不用传入参数，并返回一个泛型T对象。 12345// 定义() -&gt; Object&lt;T&gt;//实例：无入参，有出参Supplier&lt;String&gt; supplier = () -&gt; \"return supplier\"; 4.Consumer接口Consumer接口是一个类似消费者的接口，定义了一个名叫accept的抽象方法，传入一个泛型T对象，没有返回值。 12345// 定义Object&lt;T&gt; //实例：有入参，无出参Consumer&lt;String&gt; consumer = str -&gt; System.out.println(str + \"consumer\");","categories":[{"name":"Java体系","slug":"Java体系","permalink":"https://yugd.cn/categories/Java%E4%BD%93%E7%B3%BB/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"}]},{"title":"每日一面--字符流和字节流","slug":"面试--字符流和字节流","date":"2022-07-01T01:00:00.000Z","updated":"2022-07-24T16:07:45.049Z","comments":true,"path":"posts/16284/","link":"","permalink":"https://yugd.cn/posts/16284/","excerpt":"每天一篇面试小知识 本篇着重介绍一下字符流和字节流 写在前面 来点有用的，巩固一下Java基础的字符流和字节流。、","text":"每天一篇面试小知识 本篇着重介绍一下字符流和字节流 写在前面 来点有用的，巩固一下Java基础的字符流和字节流。、 1.流的概念IO流：一串不连续的数据集合，就像是管道里的水流一样。 写入过程可以是一段一段不连续的，数据会按照先后顺序形成一个长流； 读取时看不到数据在写入时候的分段情况；所以无论是将数据分多次写入还是整体一次性写入，读取时候的效果都是一样的。 流是硬盘或者外设存储的数据的源点或者终点 2.流的分类按照流向可以分为：输入流（如：键盘，麦克风），输出流（如：显示器，音箱） 按照传输单位可以分为：字节流和字符流 3.字节流、字符流字节流： 它处理单元为1个字节（byte），操作字节和字节数组，存储的是二进制文件，如果是音频文件、图片、歌曲，就用字节流好点（1byte = 8位）； 字符流： 它处理的单元为2个字节的Unicode字符，分别操作字符、字符数组或字符串，字符流是由Java虚拟机将字节转化为2个字节的Unicode字符为单位的字符而成的，如果是关系到中文（文本）的，用字符流好点（1Unicode = 2字节 = 16位）； 总结 在使用字节流操作中，即使没有关闭资源（close方法），也能输出；而字符流不使用close方法的话，不会输出任何内容 字节流在操作的时候本身不会用到缓冲区的，是与文件本身直接操作的；而字符流在操作的时候使用到缓冲区的。 所有文件的存储都是字节(byte)的存储，在磁盘上保留的是字节。 12345671.word.doc 数据字节流还是字符流？答：.doc数据字节流。2.Excel 数据字节流还是字符流？答：要根据保存的格式进行判断，如果是保存为.csv那么他就是字符流，如果是其他的则数据字节流。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://yugd.cn/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"IO","slug":"IO","permalink":"https://yugd.cn/tags/IO/"}]},{"title":"实践一下--Spring Security","slug":"实践--Spring Security","date":"2022-06-01T01:00:00.000Z","updated":"2022-06-09T11:55:51.885Z","comments":true,"path":"posts/11315/","link":"","permalink":"https://yugd.cn/posts/11315/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Spring Security 写在前面 首先了解 Spring Security，是基于 Spring AOP 和 Servlet 过滤器的安全框架。 它提供全面的安全性解决方案，同时在 Web 请求级和方法调用级处理身份确认和授权。","text":"每天一篇面试小知识 本篇着重介绍一下 Spring Security 写在前面 首先了解 Spring Security，是基于 Spring AOP 和 Servlet 过滤器的安全框架。 它提供全面的安全性解决方案，同时在 Web 请求级和方法调用级处理身份确认和授权。 核心功能 认证 （你是谁） 授权 （你能干什么） 攻击防护 （防止伪造身份） Spring Security 执行流程过滤器图示 SpringSecurity 采用的是责任链的设计模式，它有一条很长的过滤器链。 链式调用 逐级通过，才能进入下一个过滤器，绿色部分是认证过滤器，需要我们自己配置，可以配置多个认证过滤器。 常用认证过滤器 SecurityContextPersistenceFilter (上下文安全持久性过滤器) 它主要存放用户的认证信息 UsernamePasswordAuthenticationFilter 该过滤器会拦截前端提交的 POST 方式的登录表单请求，并进行身份认证。 ExceptionTranslationFilter 该过滤器不需要我们配置，对于前端提交的请求会直接放行，捕获后续抛出的异常并进行处理（例如：权限访问限制）。 FilterSecurityInterceptor 该过滤器是过滤器链的最后一个过滤器，根据资源权限配置来判断当前请求是否有权限访问对应的资源。如果访问受限会抛出相关异常，并由 ExceptionTranslationFilter 过滤器进行捕获和处理。 实际操作整合springbootpom.xml 12345678910111213141516171819202122232425&lt;!-- web --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- test --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- lombok --&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;!-- security --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"框架","slug":"框架","permalink":"https://yugd.cn/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"Spring","slug":"Spring","permalink":"https://yugd.cn/tags/Spring/"}]},{"title":"每日一面--反射","slug":"面试--反射","date":"2022-05-01T01:00:00.000Z","updated":"2022-06-07T18:33:24.244Z","comments":true,"path":"posts/40042/","link":"","permalink":"https://yugd.cn/posts/40042/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Java中的反射 写在前面 什么是反射？有啥用？ 其实要是从常规的 crud 角度面向百度编程的话，掌不掌握反射知识都不重要，但是咱不能一直 crud 不是，所以有必要学习一下 Java 中的反射知识。 反射：JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 Java语言的反射机制。","text":"每天一篇面试小知识 本篇着重介绍一下 Java中的反射 写在前面 什么是反射？有啥用？ 其实要是从常规的 crud 角度面向百度编程的话，掌不掌握反射知识都不重要，但是咱不能一直 crud 不是，所以有必要学习一下 Java 中的反射知识。 反射：JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为 Java语言的反射机制。 反射总结开门见山的说：反射就是把 java 类中的各种成分映射成一个个的 Java 对象。 通过反射获取构造方法并使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.ase.structure.反射;public class Student &#123; private String name; private int age; private String gender; public Student() &#123; &#125; public Student(String name, int age, String gender) &#123; this.name = name; this.age = age; this.gender = gender; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getGender() &#123; return gender; &#125; public void setGender(String gender) &#123; this.gender = gender; &#125; @Override public String toString() &#123; return \"Student&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + \", gender='\" + gender + '\\'' + '&#125;'; &#125;&#125; 123456789101112131415161718192021222324package com.ase.structure.反射;public class Reflect &#123; public static void main(String[] args) &#123; //第一种方式获取Class对象 Student stu1 = new Student();//这一new 产生一个Student对象，一个Class对象。 Class stuClass = stu1.getClass();//获取Class对象 System.out.println(stuClass.getName()); //第二种方式获取Class对象 Class stuClass2 = Student.class; System.out.println(stuClass == stuClass2);//判断第一种方式获取的Class对象和第二种方式获取的是否是同一个 //第三种方式获取Class对象 try &#123; Class stuClass3 = Class.forName(\"com.ase.structure.反射.Student\");//注意此字符串必须是真实路径，就是带包名的类路径，包名.类名 System.out.println(stuClass3 == stuClass2);//判断三种方式是否获取的是同一个Class对象 &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 结果 123com.ase.structure.反射.Studenttruetrue","categories":[{"name":"Java","slug":"Java","permalink":"https://yugd.cn/categories/Java/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"}]},{"title":"实践一下-- Maven依赖冲突","slug":"实践--Maven依赖冲突","date":"2022-02-03T01:00:00.000Z","updated":"2022-05-26T18:18:37.673Z","comments":true,"path":"posts/37173/","link":"","permalink":"https://yugd.cn/posts/37173/","excerpt":"每天一篇面试小知识 记录一下项目中遇到的问题 写在前面 控制台打印如果出现warning怎么办？ 当然是一点点的排查了，不要小觑了不起眼的警告，有可能会出现大问题！ 当然本篇文章只是单纯的不喜欢控制台所出现的红色警告标识。","text":"每天一篇面试小知识 记录一下项目中遇到的问题 写在前面 控制台打印如果出现warning怎么办？ 当然是一点点的排查了，不要小觑了不起眼的警告，有可能会出现大问题！ 当然本篇文章只是单纯的不喜欢控制台所出现的红色警告标识。 Maven依赖冲突是什么依赖冲突是指项目依赖的某一个jar包，有多个不同的版本，因而造成类包版本冲突。 比如本文中所要提到的日志依赖… Maven依赖冲突的原因依赖冲突很经常是类包之间的间接依赖引起的。每个显式声明的类包都会依赖于一些其它的隐式类包，这些隐式的类包会被[maven]间接引入进来，从而造成类包冲突。 Maven依赖冲突解决方法1、查看依赖冲突 1$ mvn dependency:tree 2、找到冲突依赖 123456[INFO] +- org.springframework.boot:spring-boot-starter-log4j2:jar:2.4.0:compile[INFO] | +- org.apache.logging.log4j:log4j-slf4j-impl:jar:2.13.3:compile[INFO] | | \\- org.apache.logging.log4j:log4j-api:jar:2.13.3:compile[INFO] | +- org.apache.logging.log4j:log4j-core:jar:2.13.3:compile[INFO] | +- org.apache.logging.log4j:log4j-jul:jar:2.13.3:compile[INFO] | \\- org.slf4j:jul-to-slf4j:jar:1.7.30:compile 3、排除冲突的依赖 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 去掉springboot默认配置 --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;","categories":[{"name":"项目","slug":"项目","permalink":"https://yugd.cn/categories/%E9%A1%B9%E7%9B%AE/"}],"tags":[{"name":"博客","slug":"博客","permalink":"https://yugd.cn/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"实践一下--Docker基础版","slug":"面试--Docker","date":"2022-01-07T01:00:00.000Z","updated":"2022-05-26T18:16:56.011Z","comments":true,"path":"posts/59617/","link":"","permalink":"https://yugd.cn/posts/59617/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Docker (基础) 写在前面 what is docker？ Docker 是一个基于 Go 语言开源的应用容器引擎。可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。","text":"每天一篇面试小知识 本篇着重介绍一下 Docker (基础) 写在前面 what is docker？ Docker 是一个基于 Go 语言开源的应用容器引擎。可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 Docker 架构Docker 基本概念 镜像(Image)：Docker 镜像（Image），就相当于是一个 root 文件系统。 比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。 容器(Container)：镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。 容器可以被创建、启动、停止、删除、暂停等。 仓库(Repository)：仓库可看成一个代码控制中心，用来保存镜像。 Docker 容器通过 Docker 镜像来创建 架构如图 Docker 基本命令手动安装(默认是root权限) 卸载旧版本 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 设置存储库 1sudo yum install -y yum-utils 阿里云源地址 123sudo yum-config-manager \\ --add-repo \\ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装 Docker 引擎 1sudo yum install docker-ce docker-ce-cli containerd.io 启动docker 1sudo systemctl start docker 关闭docker 1sudo systemctl stop docker 重启docker 1sudo systemctl restart docker 设置开机自启docker: 1sudo systemctl enable docker 查看docker的状态 1sudo systemctl status docker 查看是否安装成功 1docker -v Docker 三要素镜像 (image) 列出主机上的镜像 1docker images 列出本地的所有镜像 1docker images -a 只显示镜像id 1docker images -q 查询某个镜像 1docker search xxx 查询某个镜像(取前5个) 1docker search --limit 5 xxx 下载镜像(:tag 指定版本) [不加tag默认lasted取最新的镜像] 1docker pull xxx:tag / docker pull xxx 查看镜像/容器/数据卷 所占用的空间 1docker system df 删除镜像(xxx 可以是name也可以是image_id) 1docker rmi xxx 删除镜像(强制) 1docker rmi -f xxx 运行模式 容器 (contain)明确一点 docker是运行在linux内核上的！ 启动守护式(后台运行) docker中的虚悬镜像 – repository、tag 都为 &lt; none &gt; 的镜像 (建议删除！) 启动一个容器(镜像实例) 1docker run images 启动一个交互式容器(镜像实例)(前端有伪终端, 说白了就是有个bash交互命令平台) 1234567891011docker run -it images -P 随机(端口映射) -p 指定(端口映射) [8080:8080]==&gt;[外部访问docker端口8080映射到里面的容器实例端口8080]eg：docker run -it --name=my_ubuntu ubuntu /bin/bash 退出终端exit; (容器停止)ctrl+p+q (容器不停止) 列出所有已启动的容器实例 1docker ps 列出所有容器实例(已启动的和未启动的) 1docker ps -a 启动容器(id)(name) 1docker start xxxxxxxxxx(id)(name) 重启容器(id)(name) 1docker restart xxxxxxxxxx(id)(name) 停止容器(id)(name) 1docker stop xxxxxxxxxx(id)(name) 强制停止容器(id)(name) 1docker kill xxxxxxxxxx(id)(name) 删除已停止的容器(id)(name) 1docker rm xxxxxxxxxx(id)(name) 强制删除已停止的容器(id)(name) 1docker rm -f xxxxxxxxxx(id)(name) 守护进程模式(返回一个容器id)[如果是ubuntu这种操作系统的话，就需要我们使用 -it 这种形式] -itd 123docker run -d ubuntudocker run -itd --name ubuntu-test ubuntu /bin/bash 进入已经启动的容器, 退出容器还继续运行 12345docker exec -it xxxxxxxxxx /bin/bash 退出终端(因为使用的是exec)exit (容器不停止)ctrl+p+q (容器不停止) 容器文件备份到主机上 1docker cp xxxxxxxxxx(id):/xx/xx.txt /xx/xxx.txt 容器(整个)导出到主机上 1docker export xxxxxxxxxx &gt; xxx.tar 容器(整个)导入到主机上 1cat xxx.tar | docker import -xxx/xxx:1.0 更新包管理工具 1234apt-get update#安装(vim)apt-get install vim 提交新的容器 12docker commit -m=\"xxxxx\" -a=\"zhangsan\" xxxxxxxxxx(id) linux/ubuntu_vim:1.0[docker commit -m=\"unbutu have vim\" -a=\"yuha\" 19654dd238a4 linux/ubuntu_vim:1.0] 容器卷 (container volume) 数据卷 挂载 (mount): docker挂载就是用本机文件或文件夹覆盖容器内的文件或文件夹; 容器卷和主机互通互联 [docker run -it –privileged=true -v /宿主机绝对路径目录:/容器内目录 –name=镜像别名 镜像名] 1docker run -it --privileged=true -v /temp/host_data:/temp/docker_data --name=my_ubuntu ubuntu privileged 容器内的root拥有真正的root权限; 否则，容器内的root只是外部的一个普通用户权限; privileged启动的容器，可以看到很多host上的设备，并且可以执行mount; 注意：如果实现容器卷和主机互通互联，即使容器stop，主机上与容器卷之间互通的文件部分也会做相应的同步。 Docker 常用软件安装Apache Tomcat pull 1docker pull tomcat run 指定外部端口映射8080 1docker run -d -p 8080:8080 --name my_tomcat tomcat 访问8080 1ip:8080 可能出现的问题：访问出现404 新版本 tomcat 的 webapp 是空的，新增了文件 webapps.dist，需要我们删除掉webapps，并重命名文件 webapps.dist 为 webapps ; 12rm -rf webappsmv webapps.dist webapps MySQL pull 1docker pull mysql:5.7 run 先查看端口号3306是否被占用 1ps -ef | grep mysql 1docker run -p 3306:3306 --name my_mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 注意：docker中的mysql字符自是默认拉丁，不是UTF-8 Redis pull 1docker pull redis:6.0.8 run 1run -d -p 6379:6379 --name my_redis redis:6.0.8 未完待续 … …","categories":[{"name":"容器","slug":"容器","permalink":"https://yugd.cn/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://yugd.cn/tags/Docker/"}]},{"title":"实践一下--MySQL 优化","slug":"面试--MySQL优化","date":"2022-01-04T01:00:00.000Z","updated":"2022-05-27T00:54:04.096Z","comments":true,"path":"posts/56511/","link":"","permalink":"https://yugd.cn/posts/56511/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 MySQL优化 写在前面 每次面试一定要问的 SQL 优化到底是个啥东西？ 因为之前没有大体量数据的场景导致在面对这个问题的时候回答不出来面试官想要的答案！ 特此，好好整理一下相关知识，工作中其实也遇到过类似的问题。","text":"每天一篇面试小知识 本篇着重介绍一下 MySQL优化 写在前面 每次面试一定要问的 SQL 优化到底是个啥东西？ 因为之前没有大体量数据的场景导致在面对这个问题的时候回答不出来面试官想要的答案！ 特此，好好整理一下相关知识，工作中其实也遇到过类似的问题。 SQL 执行顺序(MySQL) FROM&lt;表名&gt; # 选取表，将多个表数据通过笛卡尔积变成一个表。 ON&lt;筛选条件&gt; # 对笛卡尔积的虚表进行筛选 JOIN &lt;join, left join, right join…&gt; &lt;join表&gt; # 指定join，用于添加数据到on之后的虚表中，例如left join会将左表的剩余数据添加到虚表中 WHERE&lt;where条件&gt; # 对上述虚表进行筛选 GROUP BY&lt;分组条件&gt; # 分组 &lt;SUM()等聚合函数&gt; # 用于having子句进行判断，在书写上这类聚合函数是写在having判断里面的 HAVING&lt;分组筛选&gt; # 对分组后的结果进行聚合筛选 SELECT&lt;返回数据列表&gt; # 返回的单列必须在group by子句中，聚合函数除外 DISTINCT数据除重 ORDER BY&lt;排序条件&gt; # 排序 LIMIT&lt;行数限制&gt; SQL 优化策略(MySQL)SQL 优化策略适用于数据量较大的场景下！ 如果数据量较小，没必要以此为准，以免画蛇添足！ 索引 ( Index ) 1、 避免不走索引的场景 1234567891011121314-- 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描;SELECT * FROM user_info WHERE username LIKE &#39;%陈%&#39;; [x]-- 优化方式：尽量在字段后面使用模糊查询;SELECT * FROM user_info WHERE username LIKE &#39;陈%&#39;; [√]-- 如果需求是要在前面使用模糊查询-- 使用MySQL内置函数INSTR(str,substr) 来匹配;-- INSTR()函数返回字符串中子字符串第一次出现的位置。如果在str中找不到子字符串，则INSTR()函数返回零(0);SELECT * FROM user_info WHERE INSTR(username,&#39;陈&#39;) &gt; 0;-- 当表数据量较少(少于1万),直接用like &#39;%xx%&#39;; 2、尽量避免使用 in 和 not in，会导致引擎走全表扫描 12345678910SELECT * FROM user_info WHERE id IN (2,3);-- 优化方式：如果是连续数值，可以用between代替;SELECT * FROM user_info WHERE id BETWEEN 2 AND 3;-- 如果是子查询，可以用exists代替;-- 不走索引SELECT * FROM A WHERE A.id IN (SELECT id FROM B);-- 走索引SELECT * FROM A WHERE EXISTS (SELECT * FROM B WHERE B.id &#x3D; A.id); 3、 尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描 12345678SELECT * FROM user_info WHERE id &#x3D; 1 OR id &#x3D; 3;-- 优化方式：可以用union代替or-- UNION语句：用于将不同表中相同列中的数据展示出来;(不包括重复数据)-- UNION ALL语句：用于将不同表中相同列中的数据展示出来;(包括重复数据)SELECT * FROM user_info WHERE id &#x3D; 1; UNIONSELECT * FROM user_info WHERE id &#x3D; 3; 4、尽量避免进行 null 值的判断，会导致数据库引擎放弃索引进行全表扫描 1234SELECT * FROM user_info WHERE score IS NULL;-- 优化方式：可以给字段添加默认值0，对0值进行判断;SELECT * FROM user_info WHERE score &#x3D; 0; 5、尽量避免在where条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描 123456-- 可以将表达式、函数操作移动到等号右侧;-- 全表扫描SELECT * FROM user_info WHERE score&#x2F;10 &#x3D; 9;-- 走索引SELECT * FROM user_info WHERE score &#x3D; 10*9; 6、当数据量大时，避免使用 where 1=1 的条件。通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描 1234SELECT username, age, sex FROM user_info WHERE 1&#x3D;1-- 优化方式：用代码拼装sql时进行判断，没 where 条件就去掉 where，有where条件就加 and-- 比如这里比较推荐使用 MyBatis; 7、查询条件不能用 &lt;&gt; 或者 != 8、where条件仅包含复合索引非前置列 9、order by 条件要与where中条件一致，否则order by不会利用索引进行排序 12345-- 不走age索引;SELECT * FROM user_info order by age; -- 走age索引;SELECT * FROM user_info where age &gt; 0 order by age; SELECT 语句优化(MySQL)1、避免出现select 2、多表关联查询时，小表在前，大表在后 12345678&#x2F;** * 1.当使用 left join 时，左表是驱动表，右表是被驱动表; * 2.当使用 right join 时，右表时驱动表，左表是驱动表; * 3.当使用 inner join 时，mysql 会选择数据量比较小的表作为驱动表，大表作为被驱动表; *&#x2F;-- 在执行效率上，小表驱动大表 优于 大表驱动小表;-- 驱动表索引没有生效，被驱动表索引有效; 3、使用表的别名 4、用where字句替换HAVING字句 1234&#x2F;** * 因为HAVING只会在检索出所有记录之后才对结果集进行过滤，而where则是在聚合前刷选记录; * 如果能通过where字句限制记录的数目，那就能减少这方面的开销; *&#x2F; 5、调整Where字句中的连接顺序 123&#x2F;** * MySQL采用从左往右，自上而下的顺序解析where子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集; *&#x2F; 增删改 DML 语句优化1、大批量插入数据 如果同时执行大量的插入，建议使用多个值的INSERT语句(方法二) 方法一： 12345INSERT INTO user_info VALUES(1,2); INSERT INTO user_info VALUES(1,3); INSERT INTO user_info VALUES(1,4); 方法二： 1INSERT INTO user_info VALUES(1,2),(1,3),(1,4); 2、避免重复查询更新的数据 针对业务中经常出现的更新行同时又希望获得改行信息的需求，MySQL并不支持PostgreSQL那样的UPDATE RETURNING语法，在MySQL中可以通过变量实现。 例如，更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么，简单方法实现： 123Update t1 set time&#x3D;now() where col1&#x3D;1; Select time from t1 where id &#x3D;1; 使用变量，可以重写为以下方式： 123Update t1 set time&#x3D;now () where col1&#x3D;1 and @now: &#x3D; now (); Select @now; 前后二者都需要两次网络来回，但使用变量避免了再次访问数据表，特别是当t1表数据量较大时，后者比前者快很多。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"MySQL","slug":"MySQL","permalink":"https://yugd.cn/tags/MySQL/"}]},{"title":"hexo 博客总结","slug":"博客--Hexo","date":"2021-10-10T01:00:00.000Z","updated":"2022-05-26T18:16:27.679Z","comments":true,"path":"posts/30553/","link":"","permalink":"https://yugd.cn/posts/30553/","excerpt":"hexo 博客优化总结 Hexo 官网","text":"hexo 博客优化总结 Hexo 官网 Hexo 生成唯一文章链接Hexo 生成博客文章的链接时，默认格式 permalink: :year/:month/:day/:title/ ，即按照 年：月：日：标题的格式来生成的。 如果标题中含中文的话，复制URL链接的话中文字符就会是一大串编码字符。如果想为每一篇文章生成唯一 ID 的话，推荐使用 hexo-abbrlink 或 hexo-uuid hexo-abbrlink博客根目录下安装 1npm install hexo-abbrlink --save config.yml 中修改 1permalink: posts/:abbrlink/ hexo-uuid博客根目录下安装 1npm install hexo-uuid --save config.yml 中修改 1permalink: posts/:uuid/","categories":[{"name":"博客框架","slug":"博客框架","permalink":"https://yugd.cn/categories/%E5%8D%9A%E5%AE%A2%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://yugd.cn/tags/hexo/"}]},{"title":"学习--ElasticSearch","slug":"学习--ElasticSearch--01","date":"2021-09-29T01:00:00.000Z","updated":"2022-05-26T18:19:03.431Z","comments":true,"path":"posts/27951/","link":"","permalink":"https://yugd.cn/posts/27951/","excerpt":"每天一篇面小水文，记录一下学习历程 本篇着重介绍一下 ElasticSearch 写在前面 好久没有跟新博客了，话不多说，开始学习 elastic search ! 1You Know, for Search","text":"每天一篇面小水文，记录一下学习历程 本篇着重介绍一下 ElasticSearch 写在前面 好久没有跟新博客了，话不多说，开始学习 elastic search ! 1You Know, for Search ElasticSearch 的基本概念概念包括cluster, node, index, document, shards 及 replica 集群（cluster） Cluster 也就是集群的意思。Elasticsearch 集群由一个或多个节点组成，可通过其集群名称进行标识。通常这个 Cluster 的名字是可以在 Elasticsearch 里的配置文件中设置的。在默认的情况下，Elasticsearch 已经开始运行，那么它会自动生成一个叫做 “elasticsearch” 的集群。我们可以在 config/elasticsearch.yml 里定制我们的集群的名字。 一个 Elasticsearch 的集群就像是下面的一个布局 带有 NGINX 代理及 Balancer 的架构图 实例（node）单个 Elasticsearch 实例。 在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。一个集群由一个或多个 node 组成。在测试的环境中，我可以把多个 node 运行在一个 server 上。在实际的部署中，大多数情况还是需要一个 server 上运行一个 node。 根据 node 的作用，可以分为如下的几种： master-eligible：可以作为主 node，一旦成为主 node，它可以管理整个 cluster 的设置及变化：创建，更新，删除 index；添加或删除 node；为 node 分配 shard data：数据 node ingest: 数据接入 machine learning Node类型 配置参数 默认值 master-eligible node.master true data node.data true ingest node.ingest true machine learning node.ml true (除了OSS发布版） 整个 Elastic 的架构中，Data Node 和 Cluster 的关系表 索引（index）在 Elasticsearch 中，索引是文档的集合。 索引是 Elasticsearch 对逻辑数据的逻辑存储，所以它可以分为更小的部分。 可以把索引看成关系型数据库的表，索引的结构是为快速有效的全文索引准备的，特别是它不存储原始值。 Elasticsearch 可以把索引存放在一台机器或者分散在多台服务器上，每个索引有一或多个分片（shard），每个分片可以有多个副本（replica）。 每个 Index 一个或许多的 documents 组成，并且这些 document 可以分布于不同的 shard 之中 注意 正向索引使用的是一种文档到关键字的方式 document -&gt; to -&gt; words，那如果将 文档到关键字的结构反过来呢？是不是 word -&gt; to -&gt; documents，称之为 反向索引，也称为倒排索引 文档（document）Elasticsearch 是面向文档的，这意味着你索引或搜索的最小数据单元是文档。 存储在 Elasticsearch 中的主要实体叫文档（document）。用关系型数据库来类比的话，一个文档相当于数据库表中的一行记录。 Elasticsearch 和 MongoDB 中的文档类似，都可以有不同的结构，但 Elasticsearch 的文档中，相同字段必须有相同类型。 文档由多个字段组成，每个字段可能多次出现在一个文档里，这样的字段叫多值字段（multivalued）。 每个字段的类型，可以是文本、数值、日期等。字段类型也可以是复杂类型，一个字段包含其他子文档或者数组。 它是独立的。文档包含字段（名称）及其值。 注意 文档通常是数据的 JSON 表示形式 例如： 12345&#123; \"name\": \"Elasticsearch Denver\", \"organizer\": \"Lee\", \"location\": \"Denver, Colorado, USA\"&#125; 分片（shard）由于 Elasticsearch 是一个分布式搜索引擎，因此索引通常会拆分为分布在多个节点上的称为分片的元素。 Elasticsearch 自动管理这些分片的排列。 当索引过于庞大的时候（磁盘无法存储下），为了解决这个问题，Elasticsearch 提供了将索引划分成多份的能力，这些份就叫做分片（shard）。 当创建一个索引的时候，你可以指定你想要的分片(shard)的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片之所以重要，主要有两方面的原因： 允许水平分割/扩展你的内容容量 允许在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量 有两种类型的分片：primary shard 和 replica shard Primary shard: 每个文档都存储在一个Primary shard Replica shard: 每个主分片可以具有零个或多个副本 建议 50G 为索引的大小以求得最好的性能。在我们实际的 Beats 的使用中，默认的 ILM 索引大小就是 50G。 副本（replica）默认情况下，Elasticsearch 为每个索引创建一个主分片和一个副本。这意味着每个索引将包含一个主分片，每个分片将具有一个副本。 shard 健康 红色：集群中未分配至少一个主分片 黄色：已分配所有主副本，但未分配至少一个副本 绿色：分配所有分片 映射（mapping）所有文档写进索引之前都会先进行分析，如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做 映射（mapping）。一般由用户自己定义规则。 每当一个文档进来后，根据文档的 id 会自动进行 hash 计算，并存放于计算出来的 shard 实例中，这样的结果可以使得所有的 shard 都比较有均衡的存储，而不至于有的 shard 很忙。 1shard_num = hash(_routing) % num_primary_shards 文档类型（type） 在 Elasticsearch 中，一个索引对象可以存储很多不同用途的对象。例如，一个博客应用程序可以保存文章和评论。 每个文档可以有不同的结构。 不同的文档类型不能为相同的属性设置不同的类型。例如，在同一索引中的所有文档类型中，一个叫 title 的字段必须具有相同的类型。 Elasticsearch 的数据类型： text：全文搜索字符串 keyword：用于精确字符串匹配和聚合 date 及 date_nanos：格式化为日期或数字日期的字符串 byte, short, integer, long：整数类型 boolean：布尔类型 float，double，half_float：浮点数类型 分级的类型：object 及 nested 注意 在未来的版本中，type 将被彻底删除 RESTful API在 Elasticsearch 中，提供了功能丰富的 RESTful API 的操作，包括基本的 CRUD、创建索引、删除索引等操作。 数据格式Elasticsearch 是面向文档型数据库，一条数据在这里就是一个文档。以 Elasticsearch 里存储文档数据和关系型数据库 MySQL 存储数据的概念进行一个类比。 ES 里的 Index 可以看做一个库，而 Types 相当于表，Documents 则相当于表的行。 这里 Types 的概念已经被逐渐弱化，Elasticsearch 6.X 中，一个 index 下已经只能包含一个 type，Elasticsearch 7.X 中, Type 的概念已经被删除了。 ElasticSearch 操作ElasticSearch API查看所有索引在 Postman 中，向 ES 服务器发 GET 请求 ：http://127.0.0.1:9200/_cat/indices?v _cat 表示查看的意思 indices 表示索引 {&thinsp;{&thinsp;es_url&thinsp;}&thinsp;} =&gt; http://localhost:9200 表头 含义 health 当前服务器健康状态： green (集群完整)、yellow (单点正常、集群不完整)、red (单点不正常) status 索引打开、关闭状态 index 索引名 uuid 索引统一编号 pri 主分片数量 rep 副本数量 docs.count 可用文档数量 docs.deleted 文档删除状态（逻辑删除） store.size 主分片和副分片整体占空间大小 pri.store.size 主分片占空间大小 创建一个索引及文档创建一个叫做 twitter 的索引（index），并插入一个文档（document)。 在 kibana 中，向 ES 服务器发 PUT 请求 12345678PUT twitter/_doc/1&#123; \"user\": \"GB\", \"uid\": 1, \"city\": \"Beijing\", \"province\": \"Beijing\", \"country\": \"China\"&#125; 自动 ID 生成Elasticsearch 自动帮我们生成一个 ID，这个时候使用的是 POST 而不是 PUT 操作数据的时候PUT和POST的区别： 更新：PUT 会将新的 json 值完全替换掉旧的；而 POST 方式只会更新相同字段的值，其他数据不会改变，新提交的字段若不存在则增加。 PUT 和 DELETE 操作是幂等的。 所谓幂等是指不管进行多少次操作，结果都一样。比如用PUT修改一篇文章，然后在做同样的操作，每次操作后的结果并没有什么不同，DELETE也是一样。 POST 操作不是幂等的，比如常见的 POST 重复加载问题：当我们多次发出同样的 POST 请求后，其结果是创建了若干的资源。 创建操作可以使用 POST，也可以使用 PUT，区别就在于 POST 是作用在一个集合资源(/articles)之上的，而 PUT 操作是作用在一个具体资源之上的(/articles/1)。 修改一个文档1POST /&lt;index&gt;/_update/&lt;_id&gt; 使用 PUT 命令来对我们的 id 为1的文档进行修改 123456789101112PUT twitter/_doc/1&#123; \"user\": \"GB\", \"uid\": 1, \"city\": \"北京\", \"province\": \"北京\", \"country\": \"中国\", \"location\":&#123; \"lat\":\"29.084661\", \"lon\":\"111.335210\" &#125;&#125; GET 来进行查询 1GET twitter/_doc/1 UPSERT 一个文档 upsert 宽松地表示更新或插入，即更新文档（如果存在），否则，插入新文档。 doc_as_upsert 参数检查具有给定ID的文档是否已经存在，并将提供的 doc 与现有文档合并。 12345678910POST /catalog/_update/3&#123; \"doc\": &#123; \"author\": \"Albert Paro\", \"title\": \"Elasticsearch 5.0 Cookbook\", \"description\": \"Elasticsearch 5.0 Cookbook Third Edition\", \"price\": \"54.99\" &#125;, \"doc_as_upsert\": true&#125; 检查一个文档是否存在1HEAD twitter/_doc/1 如果存在 1200 - OK 如果不存在 1404 - Not Found 删除一个文档1DELETE /&lt;index&gt;/_doc/&lt;_id&gt; 1DELETE twitter/_doc/1 检查一个索引是否存在1HEAD twitter 删除一个索引1DELETE twitter 批处理命令_bulk 命令 ,批量 API。 在单个 API 调用中执行多个索引或删除操作。这减少了开销并且可以大大提高索引速度。 12345678POST /_bulk?pretty&#123; \"index\" : &#123; \"_index\" : \"test\", \"_id\" : \"1\" &#125; &#125;&#123; \"field1\" : \"value1\" &#125;&#123; \"delete\" : &#123; \"_index\" : \"test\", \"_id\" : \"2\" &#125; &#125;&#123; \"create\" : &#123; \"_index\" : \"test\", \"_id\" : \"3\" &#125; &#125;&#123; \"field1\" : \"value3\" &#125;&#123; \"update\" : &#123;\"_id\" : \"1\", \"_index\" : \"test\"&#125; &#125;&#123; \"doc\" : &#123;\"field2\" : \"value2\"&#125; &#125; 结语Elasticsearch 最重要的功能就是查询，等有机会好好总结一下有关于 Elasticsearch 的各种查询！","categories":[{"name":"数据库","slug":"数据库","permalink":"https://yugd.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"es","slug":"es","permalink":"https://yugd.cn/tags/es/"}]},{"title":"实践一下--SpringBoot多模块项目","slug":"实践--SpringBoot多模块项目","date":"2021-09-20T01:00:00.000Z","updated":"2022-05-26T18:18:45.193Z","comments":true,"path":"posts/39089/","link":"","permalink":"https://yugd.cn/posts/39089/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 SpringBoot 多模块项目 写在前面 为什么要使用 SpringBoot 多模块项目？ 因为比起传统复杂的单体工程，使用Maven的多模块配置，可以帮助项目划分模块，达到代码重用； 有效的防止 pom 变得过于庞大，方便某个模块的构建，并且使得针对某个模块的特殊控制更为方便；","text":"每天一篇面试小知识 本篇着重介绍一下 SpringBoot 多模块项目 写在前面 为什么要使用 SpringBoot 多模块项目？ 因为比起传统复杂的单体工程，使用Maven的多模块配置，可以帮助项目划分模块，达到代码重用； 有效的防止 pom 变得过于庞大，方便某个模块的构建，并且使得针对某个模块的特殊控制更为方便； SpringBoot 项目结构传统单体项目一般分为如下几层： 开放接口层 终端显示层 Web 层 Service 层 Manager 层 DAO 层 外部接口或第三方平台 项目根目录/src/main/java：放置项目Java源代码 项目根目录/src/main/resources：放置项目静态资源和配置文件 项目根目录/src/test/java：放置项目测试用例代码 其中/src/main/java中通常的结构 1234567891011121314151617|_annotation：放置项目自定义注解|_aspect：放置切面代码|_config：放置配置类|_constant：放置常量、枚举等定义 |__consist：存放常量定义 |__enums：存放枚举定义|_controller：放置控制器代码|_filter：放置一些过滤、拦截相关的代码|_mapper：放置数据访问层代码接口|_model：放置数据模型代码 |__entity：放置数据库实体对象定义 |__dto：存放数据传输对象定义 |__vo：存放显示层对象定义|_service：放置具体的业务逻辑代码（接口和实现分离） |__intf：存放业务逻辑接口定义 |__impl：存放业务逻辑实际实现|_utils：放置工具类和辅助代码 SpringBoot 多模块项目结构然而随着项目的壮大，在多人协作的时候如果继续采用单体的方式就尤为麻烦，所以应该转向多模块项目结构的形式。 一、创建父工程 首先，先创建一个 Spring Initializr 工程 layered 作为 父工程（不添加任何依赖） 删除刚创建工程里不需要的文件， 只保留：.idea 文件夹 、项目 pom 文件、以及一个 *.iml 文件 二、创建子模块 右键点击父工程，选择 New -&gt; Module… 创建子模块 这里依次创建 spring-base、spring-dao、spring-service 、spring-pojo和 spring-web 共 5 个模块 将 5 个子模块的 mvnw、mvnw.cmd 文件及 .mvn 文件夹全部删除 对于 src 里的内容，只保留 spring-web 的启动类和配置文件，其他子模块的的启动类和配置文件都删除 三、编辑父工程 pom.xml 文件 将父工程 pom.xml 文件修改成如下内容，里面声明该父工程包含的子模块，同时抽取统一的配置信息和依赖版本控制，这样可以方便子 pom 直接引用，简化子 pom 的配置； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;layered&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;layered&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- &lt;properties&gt;--&gt; &lt;!-- &lt;java.version&gt;1.8&lt;/java.version&gt;--&gt; &lt;!-- &lt;/properties&gt;--&gt; &lt;!-- 模块说明：这里声明多个子模块 --&gt; &lt;modules&gt; &lt;module&gt;spring-base&lt;/module&gt; &lt;module&gt;spring-dao&lt;/module&gt; &lt;module&gt;spring-service&lt;/module&gt; &lt;module&gt;spring-web&lt;/module&gt; &lt;module&gt;spring-pojo&lt;/module&gt; &lt;/modules&gt; &lt;!-- 版本说明：这里统一管理依赖的版本号 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-base&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-dao&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- spring-boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!--去掉springboot自带日志依赖--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 引入log4j2依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--MyBatis-Plus代码生成器需要的依赖，开始--&gt; &lt;!-- lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- mysql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.49&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis-plus --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;!-- &lt;version&gt;3.2.0&lt;/version&gt;--&gt; &lt;version&gt;3.4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 代码生成器 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Velocity --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!--MyBatis-Plus代码生成器需要的依赖，结束--&gt; &lt;!-- swagger --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.auth0/java-jwt --&gt; &lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.14.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 四、编辑子模块 pom.xml 文件 spring-base 12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 继承本项目的父工程 --&gt; &lt;parent&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;layered&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-base&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-base&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&lt;!-- &lt;properties&gt;--&gt;&lt;!-- &lt;java.version&gt;1.8&lt;/java.version&gt;--&gt;&lt;!-- &lt;/properties&gt;--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; spring-dao 1234567891011121314151617181920212223242526272829303132333435363738394041424344 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 继承本项目的父工程 --&gt; &lt;parent&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;layered&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-dao&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-dao&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&lt;!-- &lt;properties&gt;--&gt;&lt;!-- &lt;java.version&gt;1.8&lt;/java.version&gt;--&gt;&lt;!-- &lt;/properties&gt;--&gt; &lt;dependencies&gt; &lt;!-- dao 子模块又依赖 base 子模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-base&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-pojo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; spring-pojo 12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 继承本项目的父工程 --&gt; &lt;parent&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;layered&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-pojo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;dependencies&gt; &lt;!-- pojo 子模块又依赖 base 子模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-base&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; spring-service 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 继承本项目的父工程 --&gt; &lt;parent&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;layered&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-service&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&lt;!-- &lt;properties&gt;--&gt;&lt;!-- &lt;java.version&gt;1.8&lt;/java.version&gt;--&gt;&lt;!-- &lt;/properties&gt;--&gt; &lt;dependencies&gt; &lt;!-- service 子模块又依赖 dao 子模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-dao&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- service 子模块又依赖 base 子模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-base&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; spring-web 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 继承本项目的父工程 --&gt; &lt;parent&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;layered&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-web&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&lt;!-- &lt;properties&gt;--&gt;&lt;!-- &lt;java.version&gt;1.8&lt;/java.version&gt;--&gt;&lt;!-- &lt;/properties&gt;--&gt; &lt;dependencies&gt; &lt;!-- web 子模块又依赖 service 子模块 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.ase&lt;/groupId&gt; &lt;artifactId&gt;spring-service&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 添加资源 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;!-- src/main/resources下的指定资源放行 --&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 五、移动项目启动类所在的包目前项目启动类 SpringWebApplication 在 com.ase.web 包下面，我们需要将其移动移动到 com.ase 包下 六、编码使用 mybatis-plus ：CodeGenerator 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class CodeGenerator &#123; public static void main(String[] args) &#123; // 代码生成器 AutoGenerator mpg = new AutoGenerator(); // 1、全局配置 GlobalConfig gc = new GlobalConfig(); String projectPath = System.getProperty(\"user.dir\"); //user.dir 获取到你当前工程的 src 目录路径 gc.setOutputDir(projectPath + \"/mybatis-plus\"); gc.setAuthor(\"astronautG24\"); gc.setOpen(false); //生成后是否打开资源管理器 gc.setFileOverride(false); // 是否文件覆盖 gc.setServiceName(\"%sService\"); // 去 Service 的 I 前缀 gc.setIdType(IdType.ASSIGN_UUID); gc.setDateType(DateType.ONLY_DATE); gc.setSwagger2(true); // 实体属性 Swagger2 注解 mpg.setGlobalConfig(gc); // 2、数据源配置 DataSourceConfig dsc = new DataSourceConfig(); dsc.setUrl(\"jdbc:mysql://localhost:3306/mybatis-plus?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=GMT%2B8&amp;useSSL=false\"); dsc.setDriverName(\"com.mysql.jdbc.Driver\"); dsc.setUsername(\"root\"); dsc.setPassword(\"root\"); dsc.setDbType(DbType.MYSQL); mpg.setDataSource(dsc); // 3、包配置 PackageConfig pc = new PackageConfig(); pc.setModuleName(\"abc\"); pc.setParent(\"com.ase.mybatis\"); pc.setController(\"controller\"); pc.setEntity(\"entity\"); pc.setService(\"service\"); pc.setMapper(\"mapper\");// pc.setXml(projectPath + \"/mybatis/src/main/resources/mapper/\"); mpg.setPackageInfo(pc); // 自定义配置// InjectionConfig cfg = new InjectionConfig() &#123;// @Override// public void initMap() &#123;// // to do nothing// &#125;// &#125;;//// //如果模板引擎是 velocity// String templatePath = \"/templates/mapper.xml.vm\";//// // 自定义输出配置// List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;();// // 自定义配置会被优先输出// focList.add(new FileOutConfig(templatePath) &#123;// @Override// public String outputFile(TableInfo tableInfo) &#123;// // 自定义输出文件名 ， 如果你 Entity 设置了前后缀、此处注意 xml 的名称会跟着发生变化！！// return projectPath + \"/mybatis/src/main/resources/mapper/\" + tableInfo.getEntityName() + \"Mapper\" + StringPool.DOT_XML;// &#125;// &#125;);//// cfg.setFileOutConfigList(focList);// mpg.setCfg(cfg); // 4、策略配置 StrategyConfig strategy = new StrategyConfig(); strategy.setNaming(NamingStrategy.underline_to_camel); strategy.setColumnNaming(NamingStrategy.underline_to_camel); strategy.setInclude(\"user\"); // 设置要映射的表名 strategy.setEntityLombokModel(true); // 自动 lombok strategy.setEntityTableFieldAnnotationEnable(true); strategy.setLogicDeleteFieldName(\"deleted\"); // 逻辑删除 strategy.setRestControllerStyle(true); //restful API 风格控制 strategy.setControllerMappingHyphenStyle(true); //url 中驼峰转连字符 localhost:8080/hello_id_2 // 5、自动填充配置 TableFill createTime = new TableFill(\"create_time\", FieldFill.INSERT); TableFill updateTime = new TableFill(\"update_time\", FieldFill.INSERT_UPDATE); ArrayList&lt;TableFill&gt; tableFills = new ArrayList&lt;&gt;(); tableFills.add(createTime); tableFills.add(updateTime); strategy.setTableFillList(tableFills); // 乐观锁 strategy.setVersionFieldName(\"version\"); mpg.setStrategy(strategy); // 6、执行 mpg.execute(); &#125;&#125; 首先在 spring-pojo，添加一个实体类 User 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Data@EqualsAndHashCode(callSuper = false)@TableName(\"user\")@ApiModel(value=\"User对象\", description=\"InnoDB free: 10240 kB\")public class User implements Serializable &#123; private static final long serialVersionUID = 1L; @ApiModelProperty(value = \"主键ID\") @TableId(value = \"id\", type = IdType.AUTO) private Long id; @ApiModelProperty(value = \"姓名\") @TableField(\"name\") private String name; @ApiModelProperty(value = \"密码\") @TableField(\"password\") private String password; @ApiModelProperty(value = \"年龄\") @TableField(\"age\") private Integer age; @ApiModelProperty(value = \"邮箱\") @TableField(\"email\") private String email; @ApiModelProperty(value = \"创建时间\") @TableField(value = \"create_time\", fill = FieldFill.INSERT) private Date createTime; @ApiModelProperty(value = \"更新时间\") @TableField(value = \"update_time\", fill = FieldFill.INSERT_UPDATE) private Date updateTime; @ApiModelProperty(value = \"乐观锁\") @TableField(\"version\") @Version private Integer version; @ApiModelProperty(value = \"逻辑删除\") @TableField(\"remove_logic\") private Integer removeLogic;&#125; 接着在 spring-dao 模块中添加 UserMapper 接口，继承 BaseMapper 1234@Mapperpublic interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; 接着在 spring-service 模块中添加一个业务实现类 UserServiceImpl，注入 UserMapper 并调用 123456789101112131415@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123; @Autowired private UserMapper userMapper; /** * 查询所有用户 */ @Override public Result queryAllList() &#123; return ResUtils.success(userMapper.selectList(null)); &#125;&#125; 然后在 spring-web 模块中创建一个 Controller，注入 UserService 并调用 12345678910111213141516@RestController@RequestMapping(\"/user\")public class UserController &#123; @Autowired private UserService userService; /** * 查询所有用户 */ @ApiOperation(\"查询所有用户\") @GetMapping(\"/query_all_list\") public Result queryAllList() &#123; return userService.queryAllList(); &#125;&#125; 在 spring-web 模块的 application.yml 中配置数据库基本信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576server: # 端口号 port: 8088 #项目名，如果不设定，默认是 / servlet: context-path: /layered# DataSource Configspring: application: name: layered datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatis-plus?serverTimezone=Asia/Shanghai&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;allowPublicKeyRetrieval=true username: root password: 123456 druid: db-type: com.alibaba.druid.pool.DruidDataSource initial-size: 5 min-idle: 5 max-active: 20 max-wait: 60000 time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 1 FROM DUAL test-while-idle: true test-on-borrow: false test-on-return: false # 打开PSCache pool-prepared-statements: true #配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入 #如果运行时报错 java.lang.ClassNotFoundException: org.apache.log4j.Priority #则导入 log4j 依赖即可，Maven 地址： https://mvnrepository.com/artifact/log4j/log4j filter: stat,wall,log4j,config #指定每个连接上PSCache的大小 max-pool-prepared-statement-per-connection-size: 20 #合并多个DruidDataSource的监控数据 use-global-data-source-stat: true #通过connectProperties属性来打开mergeSql功能；慢SQL记录 connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 serialization: write-dates-as-timestamps: false# ===== mybatis-plus相关配置 ===== #mybatis-plus: configuration: # 是否开启自动驼峰命名规则映射:从数据库列名到Java属性驼峰命名的类似映射 map-underscore-to-camel-case: true auto-mapping-behavior: full log-impl: org.apache.ibatis.logging.stdout.StdOutImpl type-aliases-package: com.ase.pojo.entity # xml扫描，多个目录用逗号或者分号分隔（告诉 Mapper 所对应的 XML 文件位置） mapper-locations: classpath*:mapper/*.xml global-config: # 逻辑删除配置 db-config: logic-delete-value: 1 # 逻辑已删除值(默认为 1) logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)#logging:# level:# com.ase.mybatis.autogenerator.mapper: debug# config: logger.xml# ===== 自定义swagger配置 ===== #swagger: enable: true application-name: $&#123;spring.application.name&#125; application-version: 1.0 application-description: springfox swagger 3.0 整合 Demo try-host: http://localhost:$&#123;server.port&#125; 调用接口，访问 http://localhost:8088/layered/abc/user/query_all_list 成功~","categories":[{"name":"框架","slug":"框架","permalink":"https://yugd.cn/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yugd.cn/tags/SpringBoot/"}]},{"title":"jdk8新特性--Method references","slug":"jdk8新特性--Method references 方法引用","date":"2021-09-14T01:00:00.000Z","updated":"2022-05-26T18:19:33.269Z","comments":true,"path":"posts/52957/","link":"","permalink":"https://yugd.cn/posts/52957/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Method references 方法引用 写在前面 什么是 Method references 方法引用 ？ 从使用的角度来讲方法引用的操作符是双冒号 “ :: ” 方法引用可以认为是 Lambda 表达式的一种特殊形式","text":"每天一篇面试小知识 本篇着重介绍一下 Method references 方法引用 写在前面 什么是 Method references 方法引用 ？ 从使用的角度来讲方法引用的操作符是双冒号 “ :: ” 方法引用可以认为是 Lambda 表达式的一种特殊形式 方法引用简介Lambda表达式可以让开发者自定义抽象方法的实现代码 方法引用则可以让开发者直接引用已存在的实现方法，作为 Lambda 表达式的 Lambda 体 (参数列表得一致) 方法引用的使用场景我们用 Lambda 表达式来实现匿名方法。但有些情况下，我们用 Lambda 表达式仅仅是调用一些已经存在的方法，除了调用动作外，没有其他任何多余的动作，在这种情况下，我们倾向于通过方法名来调用它，而Lambda表达式可以帮助我们实现这一要求，它使得 Lambda 在调用那些已经拥有方法名的方法的代码更简洁、更容易理解。 方法引用可以理解为Lambda表达式的另外一种表现形式 冗余的Lambda场景一个简单的函数式接口以应用 Lambda 表达式 (输出在控制台打印)： 12345678@FunctionalInterfacepublic interface Printable &#123; /** * 接收一个字符串参数，打印显示它 * @param str 字符串 */ public abstract void print(String str);&#125; 在 Printable 接口当中唯一的抽象方法 print 接收一个字符串参数，目的就是为了打印显示它。 Lambda 表达式来使用它： 12345678910public class PrintSimple &#123; public static void main(String[] args) &#123; printString(s -&gt; System.out.println(s)); &#125; private static void printString(Printable printable) &#123; printable.print(\"Hello, World!\"); &#125;&#125; 改进代码1234567891011public class PrintSimple2 &#123; public static void main(String[] args) &#123; printString(System.out::println); &#125; private static void printString(Printable data) &#123; data.print(\"Hello, World!\"); &#125;&#125; 双冒号 :: 写法，这被称为 “方法引用” 两种写法，完全等效 1234// Lambda表达式写法s -&gt; System.out.println(s);// 方法引用写法System.out::println 第一种语义是指：拿到参数之后经 Lambda 之手，继而传递给 System.out.println 方法去处理 第二种等效写法的语义是指:直接让 System.out 中的 println 方法来取代Lambda。两种写法的执行效果完全一 样，而第二种方法引用的写法复用了已有方案，更加简洁 方法引用的分类 类型 语法 对应的Lambda表达式 静态方法引用 类名::staticMethod (args) -&gt; 类名.staticMethod(args) 实例方法引用 inst::instMethod (args) -&gt; inst.instMethod(args) 对象方法引用 类名::instMethod (inst,args) -&gt; 类名.instMethod(args) 构建方法引用 类名::new (args) -&gt; new 类名(args) 方法引用的几种形式构造器引用语法是 Class::new，或者更一般的 Class&lt; T &gt;::new 1final Car car = Car.create( Car::new ); final List&lt; Car &gt; cars = Arrays.asList( car ); 静态方法引用语法是 Class::static_method 1cars.forEach( Car::collide ); 特定类的任意对象的方法引用语法是 Class::method 1cars.forEach( Car::repair ); 特定对象的方法引用语法是 instance::method 1final Car police = Car.create( Car::new ); cars.forEach( police::follow );","categories":[{"name":"jdk8新特性","slug":"jdk8新特性","permalink":"https://yugd.cn/categories/jdk8%E6%96%B0%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"方法引用","slug":"方法引用","permalink":"https://yugd.cn/tags/%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8/"}]},{"title":"jdk8新特性--Optional","slug":"jdk8新特性--optional类","date":"2021-09-12T01:00:00.000Z","updated":"2022-05-26T18:19:35.341Z","comments":true,"path":"posts/57459/","link":"","permalink":"https://yugd.cn/posts/57459/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Optional 类 写在前面 什么是 optional 类？ Optional 类是 Java8 新引进的一个主要用于解决的问题是 空指针异常（NullPointerException）的一个类。 Optional 类使得 Java 实现函数式编程，并且帮助在范式中实现。","text":"每天一篇面试小知识 本篇着重介绍一下 Optional 类 写在前面 什么是 optional 类？ Optional 类是 Java8 新引进的一个主要用于解决的问题是 空指针异常（NullPointerException）的一个类。 Optional 类使得 Java 实现函数式编程，并且帮助在范式中实现。 Optional 类简介Optional 是 JDK8 新增加的一个工具类，位于 java.util 包下。 Optional 类是一个可以为 null 的容器对象。如果值存在则isPresent()方法会返回 true，调用 get() 方法会返回该对象; Optional 是个容器：它可以保存类型 T 的值，或者仅仅保存 null。Optional 提供很多有用的方法，这样我们就不用显式进行空值检测; Optional 类的引入很好的解决空指针异常; Optional 类的使用Optional 类介绍JDK8 新增了 Optional 类， Optional 类是一个没有子类的工具类。我们可以把 Optional 类看作是一个容器。这个容器它有两种情况：①要么有值 ②要么为null。 Optional 类的由来在 Java 8 之前，任何访问对象方法或属性的调用都可能导致 NullPointerException 举个荔枝： 有一个 Person 类对象 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Person &#123; private String name; private Integer age; private String address; public Person(String name, Integer age, String address) &#123; this.name = name; this.age = age; this.address = address; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; @Override public String toString() &#123; return \"Person&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + \", address='\" + address + '\\'' + '&#125;'; &#125;&#125; 对 Person 为 null 的处理方式 1234567891011public class OptionalTest &#123; public static void main(String[] args) &#123; Person person = new Person(\"curry\", 30, \"Golden State Warriors\"); Person person2 = null; if (person2 != null) &#123; System.out.println(person2); &#125; else &#123; System.out.println(\"person2为空\"); &#125; &#125;&#125; 结果 1person为空 在 Java 8 之后，Optional 类的出现使得这一切发生了改变 举个荔枝： 1234567//创建 Optional 类，共有如下 3 种方式：//1.创建一个 Optional 实例Optional.of(T t);//2.创建一个空的 Optional 实例Optional.empty();//3.若 t 不为 null，创建 Optional实例，否则创建空实例Optional.ofNullable(T t); 12345678910111213141516171819public class OptionalTest2 &#123; public static void main(String[] args) &#123; //1.1 通过Optional.of() 方法,只能传入一个具体指,不能传入null,传入null报空指针异常 Optional&lt;String&gt; op1 = Optional.of(\"curry\");// Optional&lt;Object&gt; op2 = Optional.of(null); System.out.println(op1);//Optional[Lucy]// System.out.println(op2);//java.lang.NullPointerException //1.2 通过Optional.ofNullable()方法(可以传入具体值,也可以传入null,并不会报空指针异常) Optional&lt;String&gt; op3 = Optional.ofNullable(\"curry\"); Optional&lt;Object&gt; op4 = Optional.ofNullable(null); System.out.println(op3);//Optional[Lucy] System.out.println(op4);//Optional.empty //1.3 通过 Optional.empty() 方法创建一个空 Optional,存入的是null Optional&lt;Object&gt; op5 = Optional.empty(); System.out.println(op5);//Optional.empty &#125;&#125; 结果 1234Optional[curry]Optional[curry]Optional.emptyOptional.empty Optional 类常用方法私有构造在 Optional 类中，构造函数被私有访问修饰符修饰，也就意味着我们无法使用 new 关键字来创建对象 123private Optional() &#123; this.value = null;&#125; empty()使用 Optional 类的静态方法 empty() ，可以创建一个容器内值为 null 的 Optional 对象。使用该方法，得到的 Optional 类是存在的，只不过该类中的值为 null 1234567public class OptionalTest &#123; public static void main(String[] args) &#123; Optional&lt;User&gt; empty = Optional.empty(); System.out.println(empty != null); System.out.println(empty); &#125;&#125; of (T value)of(T value) 方法是 Optional 类创建容器的主要方法，使用该方法，可以创建一个泛型为 T 的 Optional 容器，并向容器内注入一个值对象 需要注意的是，使用 of(T value) 方法，参数不可以为 null，否则程序会报空指针异常 12345678public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); Optional&lt;User&gt; optionalUser1 = Optional.of(user1); User user2 = null; //Optional&lt;User&gt; optionalUser2 = Optional.of(user2); &#125;&#125; ofNullable (T value) ★ofNullable(T value) 方法和 of(T value) 方法唯一的区别在于，参数可以为 null，如果参数为 null，会调用 empty() 方法返回一个空的 Optional 对象，推荐此方法 12345678public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); User user2 = null; Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(user2); &#125;&#125; get()get() 方法，用于返回 Optional 容器中的值对象。但是如果 Optional 容器为一个空容器，即内部的值为 null，则会抛出 NoSuchElementException 异常 12345678910public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); optionalUser1.get(); User user2 = null; Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(user2); optionalUser2.get(); &#125;&#125; isPresent()isPresent() 方法，用于判断 Optional 容器内是否有值，有则返回 true，否则返回 false 12345678910public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); System.out.println(optionalUser1.isPresent()); User user2 = null; Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(user2); System.out.println(optionalUser2.isPresent()); &#125;&#125; ifPresent(Consumer&lt;? super T&gt; consumer)ifPresent(Consumer consumer) 方法，参数是一个消费型函数式接口，可以配合 Lambda 表达式使用。该方法的作用为：如果 Optional 容器中有值，则执行 Consumer 接口中的方法，否则不做其他任何操作。 12345678910public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); optionalUser1.ifPresent((o) -&gt; System.out.println(o)); User user2 = null; Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(user2); optionalUser2.ifPresent((o) -&gt; System.out.println(o)); &#125;&#125; filter(Predicate&lt;? super T&gt; predicate)filter(Predicate predicate) 方法用于过滤 Optional 容器中的值，如果 容器内的值符合 Predicate 函数所定义的接口，即返回 true，则返回原来的 Optional 对象，否则返回空的 Optional 容器对象 12345678910111213public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); user1.setUsername(\"zhangsan\"); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); System.out.println(optionalUser1.filter((o) -&gt; o.getUsername().equals(\"zhangsan\"))); User user2 = new User(); user2.setUsername(\"lisi\"); Optional&lt;User&gt; optionalUser2 = Optional.ofNullable(user2); System.out.println(optionalUser2.filter((o) -&gt; o.getUsername().equals(\"zhangsan\"))); &#125;&#125; map(Function&lt;? super T, ? extends U&gt; mapper)map(Function mapper) 方法，可以将 Optional 容器内的值替换为其他类型的值，具体的替换规则由 Function 函数定义 12345678public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); user1.setUsername(\"zhangsan\"); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); System.out.println(optionalUser1.map((o) -&gt; o.getUsername()).get()); &#125;&#125; flatMap(Function&lt;? super T, Optional&gt; mapper)该方法与 map(Function mapper) 方法类似，不过该方法要求在 Function 函数中返回 Optional 对象，并且返回的 Optional 对象不允许为 null 12345678public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); user1.setUsername(\"zhangsan\"); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); System.out.println(optionalUser1.flatMap((o) -&gt; Optional.ofNullable(o.getUsername())).get()); &#125;&#125; orElse(T other)orElse(T other) 方法和 get() 方法类似，不过比 get() 方法多了一层保险机制，如果 Optional 容器中的值为 null，则会返回 orElse(T other) 方法参数中的对象，该参数类型必须和 Optional 泛型类型一致 12345678public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); User user2 = optionalUser1.orElse(new User()); System.out.println(user1 == user2); &#125;&#125; orElseGet(Supplier&lt;? extends T&gt; other)该方法和功能类似，不过和 orElse(T other) 方法不同的是， Optional 容器中的值为 null时返回的对象通过生产型函数接口来创建并返回 12345678public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); User user2 = optionalUser1.orElseGet(() -&gt; new User()); System.out.println(user1 == user2); &#125;&#125; orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)该方法的逻辑和 orElse(T other)、orElseGet(Supplier other) 基本类似，不过当 Optional 容器的值为 null 时，会抛出生产型函数返回的异常对象 12345678public class OptionalTest &#123; public static void main(String[] args) &#123; User user1 = new User(); Optional&lt;User&gt; optionalUser1 = Optional.ofNullable(user1); User user2 = optionalUser1.orElseThrow(() -&gt; new Exception(\"抛出异常信息\")); System.out.println(user1 == user2); &#125;&#125; equals()判断其他对象是否等于Optional 123456789public class OptionalTest &#123; public static void main(String[] args) &#123; //equals(Object obj):判断其他对象是否等于Optional Optional&lt;String&gt; opt1 = Optional.of(\"Johnson\"); Optional&lt;String&gt; opt2 = Optional.of(\"Johnson\"); boolean flag = opt1.equals(opt2); System.out.println(flag);//true &#125;&#125;","categories":[{"name":"jdk8新特性","slug":"jdk8新特性","permalink":"https://yugd.cn/categories/jdk8%E6%96%B0%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"optional类","slug":"optional类","permalink":"https://yugd.cn/tags/optional%E7%B1%BB/"}]},{"title":"jdk8新特性--Stream","slug":"jdk8新特性--stream","date":"2021-09-11T14:58:58.000Z","updated":"2022-05-26T18:19:37.506Z","comments":true,"path":"posts/9553/","link":"","permalink":"https://yugd.cn/posts/9553/","excerpt":"每天一篇面试小知识 jdk1.8新特性知识点： Lambda 表达式、函数式接口、方法引用和构造器调用、Stream API、接口中的默认方法和静态方法、新时间日期 API 本篇着重介绍一下 stream 流 写在前面 什么是 stream 流？ Java8 中，Collection 新增了两个流方法，分别是 Stream() 和 parallelStream() Java8 中添加了一个新的接口类 Stream，相当于高级版的 Iterator，它可以通过 Lambda 表达式对集合进行大批量数据操作，或 者各种非常便利、高效的聚合数据操作。 Stream 将要处理的元素集合看作一种流，在流的过程中，借助 Stream API 对流中的元素进行操作，比如：筛选、排序、聚合等。 jdk8 为什么要引入 stream 流？ 在 Java8 之前，我们通常是通过 for 循环或者 Iterator 迭代来重新排序合并数据，又或者通过重新定义 Collections.sorts 的 Comparator 方法来实现，这两种方式对于大数据量系统来说，效率并不是很理想。 流不存储数据","text":"每天一篇面试小知识 jdk1.8新特性知识点： Lambda 表达式、函数式接口、方法引用和构造器调用、Stream API、接口中的默认方法和静态方法、新时间日期 API 本篇着重介绍一下 stream 流 写在前面 什么是 stream 流？ Java8 中，Collection 新增了两个流方法，分别是 Stream() 和 parallelStream() Java8 中添加了一个新的接口类 Stream，相当于高级版的 Iterator，它可以通过 Lambda 表达式对集合进行大批量数据操作，或 者各种非常便利、高效的聚合数据操作。 Stream 将要处理的元素集合看作一种流，在流的过程中，借助 Stream API 对流中的元素进行操作，比如：筛选、排序、聚合等。 jdk8 为什么要引入 stream 流？ 在 Java8 之前，我们通常是通过 for 循环或者 Iterator 迭代来重新排序合并数据，又或者通过重新定义 Collections.sorts 的 Comparator 方法来实现，这两种方式对于大数据量系统来说，效率并不是很理想。 流不存储数据 stream 概述Stream可以由数组或集合创建，对流的操作分为两种： 中间操作，每次返回一个新的流，可以有多个。 终端操作，每个流只能进行一次终端操作，终端操作结束后流无法再次使用。终端操作会产生一个新的集合或值。 另外，Stream有几个特性： stream 不存储数据，而是按照特定的规则对数据进行计算，一般会输出结果。 stream 不会改变数据源，通常情况下会产生一个新的集合或一个值。 stream 具有延迟执行特性，只有调用终端操作时，中间操作才会执行。 stream 是元素的集合，这点让 stream 看起来用些类似 Iterator stream 的创建通过集合数组创建 通过 java.util.Collection.stream() 方法用集合创建流 举个荔枝： 1234567891011121314public class StreamTest &#123; public static void main(String[] args) &#123; streamCreateTest(); &#125; static void streamCreateTest() &#123; List&lt;String&gt; list = Arrays.asList(\"a\", \"b\", \"c\"); // 创建一个顺序流 Stream&lt;String&gt; stream = list.stream(); // 创建一个并行流 Stream&lt;String&gt; parallelStream = list.parallelStream(); &#125;&#125; 使用 java.util.Arrays.stream(T[] array) 方法用数组创建流 举个荔枝： 1234567891011public class StreamTest &#123; public static void main(String[] args) &#123; streamCreateTest2(); &#125; static void streamCreateTest2() &#123; int[] array = &#123;1, 3, 5, 6, 8&#125;; IntStream stream = Arrays.stream(array); &#125;&#125; 使用 Stream 的静态方法：of()、iterate()、generate() 举个荔枝： 1234567891011121314151617public class StreamTest &#123; public static void main(String[] args) &#123; streamCreateTest3(); &#125; static void streamCreateTest3() &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3, 4, 5, 6); stream.forEach(System.out::println); Stream&lt;Integer&gt; stream2 = Stream.iterate(0, (x) -&gt; x + 3).limit(4); stream2.forEach(System.out::println); Stream&lt;Double&gt; stream3 = Stream.generate(Math::random).limit(3); stream3.forEach(System.out::println); &#125;&#125; stream 和 parallelStreamstream 是顺序流，由主线程按顺序对流执行操作 parallelStream 并行流就是一个把内容分成多个数据块，并用不不同的线程分别处理每个数据块的流。最后合并每个数据块的计算结果 如果流中的数据量足够大，并行流可以加快处速度。 除了直接创建并行流，还可以通过parallel()把顺序流转换成并行流 举个荔枝： 12345678910public class StreamTest &#123; public static void main(String[] args) &#123; System.out.println(\"parallelSum = \" + parallelSum(2)); &#125; public static long parallelSum(long n) &#123; return Stream.iterate(1L, i -&gt; i + 1).limit(n).parallel().reduce(0L, Long::sum); &#125;&#125; stream 的使用在使用 stream 之前，先看一下：Optional Optional类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。 123+--------------------+ +--------+ +--------+ +-----+ +---------+| stream of elements + -----&gt; | filter + --&gt; | sorted + --&gt; | map + --&gt; | collect |+--------------------+ +--------+ +--------+ +-----+ +---------+ stream（图示） stream–collect（图示） 遍历/匹配（foreach/find/match）Stream也是支持类似集合的遍历和匹配元素的，只是Stream中的元素是以Optional类型存在的。 举个荔枝： 12345678910111213141516171819202122public class StreamTest2 &#123; public static void main(String[] args) &#123; streamOperation(); &#125; static void streamOperation() &#123; List&lt;Integer&gt; list = Arrays.asList(7, 6, 9, 3, 8, 2, 1); // 遍历输出符合条件的元素 list.stream().filter(x -&gt; x &gt; 6).forEach(System.out::print); System.out.println(); // 匹配第一个 Optional&lt;Integer&gt; findFirst = list.stream().filter(x -&gt; x &gt; 6).findFirst(); // 匹配任意（适用于并行流） Optional&lt;Integer&gt; findAny = list.parallelStream().filter(x -&gt; x &gt; 6).findAny(); // 是否包含符合特定条件的元素 boolean anyMatch = list.stream().anyMatch(x -&gt; x &lt; 6); System.out.println(\"匹配第一个值：\" + findFirst.get()); System.out.println(\"匹配任意一个值：\" + findAny.get()); System.out.println(\"是否存在大于6的值：\" + anyMatch); &#125;&#125; 筛选（filter）筛选，是按照一定的规则校验流中的元素，将符合条件的元素提取到新的流中的操作。 举个荔枝： 筛选出Integer集合中大于7的元素，并打印出来 1234567891011public class StreamTest2 &#123; public static void main(String[] args) &#123; streamOperation2(); &#125; static void streamOperation2() &#123; List&lt;Integer&gt; list = Arrays.asList(6, 7, 3, 8, 1, 2, 9); Stream&lt;Integer&gt; stream = list.stream(); stream.filter(x -&gt; x &gt; 7).forEach(System.out::println); &#125;&#125; 聚合（max/min/count)max、min、count这些字眼在 mysql 中我们常用它们进行数据统计。 java stream 中也引入了这些概念和用法，极大地方便了我们对集合、数组的数据统计工作。 举个荔枝： 获取String集合中最长的元素 123456789101112public class StreamTest2 &#123; public static void main(String[] args) &#123; streamOperation3(); &#125; static void streamOperation3() &#123; List&lt;String&gt; list = Arrays.asList(\"adnm\", \"admmt\", \"pot\", \"xbangd\", \"weoujgsd\"); Optional&lt;String&gt; max = list.stream().max(Comparator.comparing(String::length)); System.out.println(\"最长的字符串：\" + max.get()); &#125;&#125; 再举个荔枝： 获取Integer集合中的最大值 12345678910111213141516public class StreamTest2 &#123; public static void main(String[] args) &#123; streamOperation4(); &#125; static void streamOperation4() &#123; List&lt;Integer&gt; list = Arrays.asList(7, 6, 9, 4, 11, 6); // 自然排序 Optional&lt;Integer&gt; max = list.stream().max(Integer::compareTo); // 自定义排序 Optional&lt;Integer&gt; max2 = list.stream().max((o1, o2) -&gt; o1.compareTo(o2)); System.out.println(\"自然排序的最大值：\" + max.get()); System.out.println(\"自定义排序的最大值：\" + max2.get()); &#125;&#125; 映射（map / flatMap）映射，可以将一个流的元素按照一定的映射规则映射到另一个流中 分为map和flatMap： map：接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 flatMap：接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。 举个荔枝： 英文字符串数组的元素全部改为大写、整数数组每个元素+3 12345678910111213141516public class StreamTest3 &#123; public static void main(String[] args) &#123; streamOperation(); &#125; static void streamOperation() &#123; String[] strArr = &#123; \"abcd\", \"bcdd\", \"defde\", \"fTr\" &#125;; List&lt;String&gt; strList = Arrays.stream(strArr).map(String::toUpperCase).collect(Collectors.toList()); List&lt;Integer&gt; intList = Arrays.asList(1, 3, 5, 7, 9, 11); List&lt;Integer&gt; intListNew = intList.stream().map(x -&gt; x + 3).collect(Collectors.toList()); System.out.println(\"每个元素大写：\" + strList); System.out.println(\"每个元素+3：\" + intListNew); &#125;&#125; 再举个荔枝： 将两个字符数组合并成一个新的字符数组 12345678910111213141516171819public class StreamTest3 &#123; public static void main(String[] args) &#123; streamOperation2(); &#125; static void streamOperation2() &#123; List&lt;String&gt; list = Arrays.asList(\"m,k,l,a\", \"1,3,5,7\"); List&lt;String&gt; listNew = list.stream().flatMap(s -&gt; &#123; // 将每个元素转换成一个stream String[] split = s.split(\",\"); Stream&lt;String&gt; s2 = Arrays.stream(split); return s2; &#125;).collect(Collectors.toList()); System.out.println(\"处理前的集合：\" + list); System.out.println(\"处理后的集合：\" + listNew); &#125;&#125; 归约（reduce）归约，也称缩减，顾名思义，是把一个流缩减成一个值，能实现对集合求和、求乘积和求最值操作 举个荔枝： 求Integer集合的元素之和、乘积和最大值 12345678910111213141516171819202122232425262728public class StreamTest3 &#123; public static void main(String[] args) &#123; streamOperation3(); &#125; static void streamOperation3() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 3, 2, 8, 11, 4); // 求和方式1 Optional&lt;Integer&gt; sum = list.stream().reduce((x, y) -&gt; x + y); // 求和方式2 Optional&lt;Integer&gt; sum2 = list.stream().reduce(Integer::sum); // 求和方式3 Integer sum3 = list.stream().reduce(0, Integer::sum); // 求乘积 Optional&lt;Integer&gt; product = list.stream().reduce((x, y) -&gt; x * y); // 求最大值方式1 Optional&lt;Integer&gt; max = list.stream().reduce((x, y) -&gt; x &gt; y ? x : y); // 求最大值写法2 Integer max2 = list.stream().reduce(1, Integer::max); System.out.println(\"list求和：\" + sum.get() + \",\" + sum2.get() + \",\" + sum3); System.out.println(\"list求积：\" + product.get()); System.out.println(\"list求和：\" + max.get() + \",\" + max2); &#125;&#125; 收集（collect）collect，收集，可以说是内容最繁多、功能最丰富的部分了。从字面上去理解，就是把一个流收集起来，最终可以是收集成一个值也可以收集成一个新的集合 collect主要依赖java.util.stream.Collectors类内置的静态方法 归集（toList/toSet/toMap）因为流不存储数据，那么在流中的数据完成处理后，需要将流中的数据重新归集到新的集合里 toList、toSet和toMap： 举个荔枝： 123456789101112131415161718192021222324public class StreamTest4 &#123; public static void main(String[] args) &#123; streamOperation(); &#125; static void streamOperation() &#123; List&lt;Integer&gt; list = Arrays.asList(1, 6, 3, 4, 6, 7, 9, 6, 20); List&lt;Integer&gt; listNew = list.stream().filter(x -&gt; x % 2 == 0).collect(Collectors.toList()); Set&lt;Integer&gt; set = list.stream().filter(x -&gt; x % 2 == 0).collect(Collectors.toSet()); List&lt;Person&gt; personList = new ArrayList&lt;Person&gt;(); personList.add(new Person(\"Tom\", 8900, 23, \"male\", \"New York\")); personList.add(new Person(\"Jack\", 7000, 25, \"male\", \"Washington\")); personList.add(new Person(\"Lily\", 7800, 21, \"female\", \"Washington\")); personList.add(new Person(\"Anni\", 8200, 24, \"female\", \"New York\")); Map&lt;?, Person&gt; map = personList.stream().filter(p -&gt; p.getSalary() &gt; 8000) .collect(Collectors.toMap(Person::getName, p -&gt; p)); System.out.println(\"toList:\" + listNew); System.out.println(\"toSet:\" + set); System.out.println(\"toMap:\" + map); &#125;&#125; 结果： 123toList:[6, 4, 6, 6, 20]toSet:[4, 20, 6]toMap:&#123;Tom=Person&#123;name='Tom', salary=8900, age=23, sex='male', area='New York'&#125;, Anni=Person&#123;name='Anni', salary=8200, age=24, sex='female', area='New York'&#125;&#125; 统计（count/averaging）Collectors提供了一系列用于数据统计的静态方法： 计数：count 平均值：averagingInt、averagingLong、averagingDouble 最值：maxBy、minBy 求和：summingInt、summingLong、summingDouble 统计以上所有：summarizingInt、summarizingLong、summarizingDouble 举个荔枝： 统计员工人数、平均工资、工资总额、最高工资 1234567891011121314151617181920212223242526272829public class StreamTest4 &#123; public static void main(String[] args) &#123; streamOperation2(); &#125; private static void streamOperation2() &#123; List&lt;Person&gt; personList = new ArrayList&lt;&gt;(); personList.add(new Person(\"Tom\", 8900, 23, \"male\", \"New York\")); personList.add(new Person(\"Jack\", 7000, 25, \"male\", \"Washington\")); personList.add(new Person(\"Lily\", 7800, 21, \"female\", \"Washington\")); // 求总数 Long count = personList.stream().collect(Collectors.counting()); // 求平均工资 Double average = personList.stream().collect(Collectors.averagingDouble(Person::getSalary)); // 求最高工资 Optional&lt;Integer&gt; max = personList.stream().map(Person::getSalary).collect(Collectors.maxBy(Integer::compare)); // 求工资之和 Integer sum = personList.stream().collect(Collectors.summingInt(Person::getSalary)); // 一次性统计所有信息 DoubleSummaryStatistics collect = personList.stream().collect(Collectors.summarizingDouble(Person::getSalary)); System.out.println(\"员工总数：\" + count); System.out.println(\"员工平均工资：\" + average); System.out.println(\"员工工资总和：\" + sum); System.out.println(\"员工工资所有统计：\" + collect); &#125;&#125; 结果： 1234员工总数：3员工平均工资：7900.0员工工资总和：23700员工工资所有统计：DoubleSummaryStatistics&#123;count=3, sum=23700.000000, min=7000.000000, average=7900.000000, max=8900.000000&#125; 分组（partitioningBy/groupingBy） 分区：将stream按条件分为两个Map，比如员工按薪资是否高于8000分为两部分。 分组：将集合分为多个Map，比如员工按性别分组。有单级分组和多级分组。 举个荔枝： 将员工按薪资是否高于8000分为两部分；将员工按性别和地区分组 1234567891011121314151617181920212223242526public class StreamTest4 &#123; public static void main(String[] args) &#123; streamOperation3(); &#125; private static void streamOperation3() &#123; List&lt;Person&gt; personList = new ArrayList&lt;Person&gt;(); personList.add(new Person(\"Tom\", 8900, \"male\", \"New York\")); personList.add(new Person(\"Jack\", 7000, \"male\", \"Washington\")); personList.add(new Person(\"Lily\", 7800, \"female\", \"Washington\")); personList.add(new Person(\"Anni\", 8200, \"female\", \"New York\")); personList.add(new Person(\"Owen\", 9500, \"male\", \"New York\")); personList.add(new Person(\"Alisa\", 7900, \"female\", \"New York\")); // 将员工按薪资是否高于8000分组 Map&lt;Boolean, List&lt;Person&gt;&gt; part = personList.stream().collect(Collectors.partitioningBy(x -&gt; x.getSalary() &gt; 8000)); // 将员工按性别分组 Map&lt;String, List&lt;Person&gt;&gt; group = personList.stream().collect(Collectors.groupingBy(Person::getSex)); // 将员工先按性别分组，再按地区分组 Map&lt;String, Map&lt;String, List&lt;Person&gt;&gt;&gt; group2 = personList.stream().collect(Collectors.groupingBy(Person::getSex, Collectors.groupingBy(Person::getArea))); System.out.println(\"员工按薪资是否大于8000分组情况：\" + part); System.out.println(\"员工按性别分组情况：\" + group); System.out.println(\"员工按性别、地区：\" + group2); &#125;&#125; 结果： 123员工按薪资是否大于8000分组情况：&#123;false=[Person&#123;name='Jack', salary=7000, age=0, sex='male', area='Washington'&#125;, Person&#123;name='Lily', salary=7800, age=0, sex='female', area='Washington'&#125;, Person&#123;name='Alisa', salary=7900, age=0, sex='female', area='New York'&#125;], true=[Person&#123;name='Tom', salary=8900, age=0, sex='male', area='New York'&#125;, Person&#123;name='Anni', salary=8200, age=0, sex='female', area='New York'&#125;, Person&#123;name='Owen', salary=9500, age=0, sex='male', area='New York'&#125;]&#125;员工按性别分组情况：&#123;female=[Person&#123;name='Lily', salary=7800, age=0, sex='female', area='Washington'&#125;, Person&#123;name='Anni', salary=8200, age=0, sex='female', area='New York'&#125;, Person&#123;name='Alisa', salary=7900, age=0, sex='female', area='New York'&#125;], male=[Person&#123;name='Tom', salary=8900, age=0, sex='male', area='New York'&#125;, Person&#123;name='Jack', salary=7000, age=0, sex='male', area='Washington'&#125;, Person&#123;name='Owen', salary=9500, age=0, sex='male', area='New York'&#125;]&#125;员工按性别、地区：&#123;female=&#123;New York=[Person&#123;name='Anni', salary=8200, age=0, sex='female', area='New York'&#125;, Person&#123;name='Alisa', salary=7900, age=0, sex='female', area='New York'&#125;], Washington=[Person&#123;name='Lily', salary=7800, age=0, sex='female', area='Washington'&#125;]&#125;, male=&#123;New York=[Person&#123;name='Tom', salary=8900, age=0, sex='male', area='New York'&#125;, Person&#123;name='Owen', salary=9500, age=0, sex='male', area='New York'&#125;], Washington=[Person&#123;name='Jack', salary=7000, age=0, sex='male', area='Washington'&#125;]&#125;&#125; 接合（joining）joining可以将stream中的元素用特定的连接符（没有的话，则直接连接）连接成一个字符串 举个荔枝： 12345678910111213141516171819public class StreamTest5 &#123; public static void main(String[] args) &#123; streamOperation(); &#125; static void streamOperation() &#123; List&lt;Person&gt; personList = new ArrayList&lt;&gt;(); personList.add(new Person(\"Tom\", 8900, 23, \"male\", \"New York\")); personList.add(new Person(\"Jack\", 7000, 25, \"male\", \"Washington\")); personList.add(new Person(\"Lily\", 7800, 21, \"female\", \"Washington\")); String names = personList.stream().map(p -&gt; p.getName()).collect(Collectors.joining(\",\")); System.out.println(\"所有员工的姓名：\" + names); List&lt;String&gt; list = Arrays.asList(\"A\", \"B\", \"C\"); String string = list.stream().collect(Collectors.joining(\"-\")); System.out.println(\"拼接后的字符串：\" + string); &#125;&#125; 结果： 12所有员工的姓名：Tom,Jack,Lily拼接后的字符串：A-B-C 归约（reduce）Collectors类提供的reducing方法，相比于stream本身的reduce方法，增加了对自定义归约的支持 举个荔枝： 123456789101112131415161718192021public class StreamTest5 &#123; public static void main(String[] args) &#123; streamOperation2(); &#125; static void streamOperation2() &#123; List&lt;Person&gt; personList = new ArrayList&lt;&gt;(); personList.add(new Person(\"Tom\", 8900, 23, \"male\", \"New York\")); personList.add(new Person(\"Jack\", 7000, 25, \"male\", \"Washington\")); personList.add(new Person(\"Lily\", 7800, 21, \"female\", \"Washington\")); // 每个员工减去起征点后的薪资之和 Integer sum = personList.stream().collect(Collectors.reducing(0, Person::getSalary, (i, j) -&gt; (i + j - 5000))); System.out.println(\"员工扣税薪资总和：\" + sum); // stream的reduce Optional&lt;Integer&gt; sum2 = personList.stream().map(Person::getSalary).reduce(Integer::sum); System.out.println(\"员工薪资总和：\" + sum2.get()); &#125;&#125; 结果： 12员工扣税薪资总和：8700员工薪资总和：23700 排序（sorted）有两种排序： sorted()：自然排序，流中元素需实现 Comparable 接口 sorted (Comparator com)：Comparator 排序器自定义排序 举个荔枝： 将员工按工资由高到低（工资一样则按年龄由大到小）排序 12345678910111213141516171819202122232425262728293031323334353637383940public class StreamTest5 &#123; public static void main(String[] args) &#123; streamOperation3(); &#125; static void streamOperation3() &#123; List&lt;Person&gt; personList = new ArrayList&lt;Person&gt;(); personList.add(new Person(\"Sherry\", 9000, 24, \"female\", \"New York\")); personList.add(new Person(\"Tom\", 8900, 22, \"male\", \"Washington\")); personList.add(new Person(\"Jack\", 9000, 25, \"male\", \"Washington\")); personList.add(new Person(\"Lily\", 8800, 26, \"male\", \"New York\")); personList.add(new Person(\"Alisa\", 9000, 26, \"female\", \"New York\")); // 按工资升序排序（自然排序） List&lt;String&gt; newList = personList.stream().sorted(Comparator.comparing(Person::getSalary)).map(Person::getName) .collect(Collectors.toList()); // 按工资倒序排序 List&lt;String&gt; newList2 = personList.stream().sorted(Comparator.comparing(Person::getSalary).reversed()) .map(Person::getName).collect(Collectors.toList()); // 先按工资再按年龄升序排序 List&lt;String&gt; newList3 = personList.stream() .sorted(Comparator.comparing(Person::getSalary).thenComparing(Person::getAge)).map(Person::getName) .collect(Collectors.toList()); // 先按工资再按年龄自定义排序（降序） List&lt;String&gt; newList4 = personList.stream().sorted((p1, p2) -&gt; &#123; if (p1.getSalary() == p2.getSalary()) &#123; return p2.getAge() - p1.getAge(); &#125; else &#123; return p2.getSalary() - p1.getSalary(); &#125; &#125;).map(Person::getName).collect(Collectors.toList()); System.out.println(\"按工资升序排序：\" + newList); System.out.println(\"按工资降序排序：\" + newList2); System.out.println(\"先按工资再按年龄升序排序：\" + newList3); System.out.println(\"先按工资再按年龄自定义降序排序：\" + newList4); &#125;&#125; 结果： 1234按工资升序排序：[Lily, Tom, Sherry, Jack, Alisa]按工资降序排序：[Sherry, Jack, Alisa, Tom, Lily]先按工资再按年龄升序排序：[Lily, Tom, Sherry, Jack, Alisa]先按工资再按年龄自定义降序排序：[Alisa, Jack, Sherry, Tom, Lily] 提取/组合流也可以进行合并、去重、限制、跳过等操作 去重 限制 跳过 举个荔枝： 123456789101112131415161718192021222324public class StreamTest5 &#123; public static void main(String[] args) &#123; streamOperation4(); &#125; static void streamOperation4() &#123; String[] arr1 = &#123; \"a\", \"b\", \"c\", \"d\" &#125;; String[] arr2 = &#123; \"d\", \"e\", \"f\", \"g\" &#125;; Stream&lt;String&gt; stream1 = Stream.of(arr1); Stream&lt;String&gt; stream2 = Stream.of(arr2); // concat:合并两个流 distinct：去重 List&lt;String&gt; newList = Stream.concat(stream1, stream2).distinct().collect(Collectors.toList()); // limit：限制从流中获得前n个数据 List&lt;Integer&gt; collect = Stream.iterate(1, x -&gt; x + 2).limit(10).collect(Collectors.toList()); // skip：跳过前n个数据 List&lt;Integer&gt; collect2 = Stream.iterate(1, x -&gt; x + 2).skip(1).limit(5).collect(Collectors.toList()); System.out.println(\"流合并：\" + newList); System.out.println(\"limit：\" + collect); System.out.println(\"skip：\" + collect2); &#125;&#125; 结果： 1234按工资升序排序：[Lily, Tom, Sherry, Jack, Alisa]按工资降序排序：[Sherry, Jack, Alisa, Tom, Lily]先按工资再按年龄升序排序：[Lily, Tom, Sherry, Jack, Alisa]先按工资再按年龄自定义降序排序：[Alisa, Jack, Sherry, Tom, Lily]","categories":[{"name":"jdk8新特性","slug":"jdk8新特性","permalink":"https://yugd.cn/categories/jdk8%E6%96%B0%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"stream","slug":"stream","permalink":"https://yugd.cn/tags/stream/"}]},{"title":"学习--Redis事务、锁机制","slug":"学习--Redis事务、锁机制","date":"2021-09-09T01:00:00.000Z","updated":"2022-05-26T18:19:24.988Z","comments":true,"path":"posts/32436/","link":"","permalink":"https://yugd.cn/posts/32436/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Redis 事务、锁机制 写在前面 Redis 事务、锁机制相较于 MySQL 有什么特别的吗？ 还真的是有挺大的区别，比如 … … 接下来一起来通过实践来探究其中的机制~","text":"每天一篇面试小知识 本篇着重介绍一下 Redis 事务、锁机制 写在前面 Redis 事务、锁机制相较于 MySQL 有什么特别的吗？ 还真的是有挺大的区别，比如 … … 接下来一起来通过实践来探究其中的机制~ Redis 事务机制Redis 事务定义Redis 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 Redis 事务的主要作用就是串联多个命令防止别的命令插队。 Redis 事务重要关键字Multi、Exec、Discard 图解 [Multi ~ Exec]： 此过程表示 redis 命令的组队成功，并且执行了组队队列中待执行的命令。 [Multi ~ Discard]： 此过程表示 redis 命令的组队成功，但是又取消了执行组队中的待执行的命令。 举个荔枝： 组队成功，成功提交 1234&gt;multi &gt;set key1 value1&gt;set key2 value2&gt;exec 组队成功，不提交 123456&gt;multi &gt;set a1 v1&gt;set a2 v2&gt;discard&gt;get a1 &gt;get a2 组队阶段报错，提交失败 12345&gt;multi &gt;set m1 v1&gt;set m2&gt;set m3 v3&gt;exec 组队成功，提交失败 12345&gt;multi&gt;set s1 v1&gt;incr s1&gt;set s2 v2&gt;exec Redis 事务的错误处理组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消。 如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。 Redis 事务三特性 单独的隔离操作 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念 队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行。 不保证原子性 事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。 Redis 与 MySQL 事务对比事务命令MySQL： Begin：显式的开启一个事务 Commit：提交事务，将对数据库进行的所有的修改变成永久性的 Rollback：结束用户的事务，并撤销现在正在进行的未提交的修改 Redis： Multi：标记事务的开始 Exec：执行事务的 commands 队列 Discard：结束事务，并清除 commands 队列 默认状态MySQL： mysql 会默认开启一个事务，且缺省设置是自动提交，即每成功执行一次 sql，一个事务就会马上 commit，所以不能 rollback Redis： redis 默认不会开启事务，即 command 会立即执行，而不会排队，并不支持 rollback 使用方式MySQL（包含两种方式）： 用Begin、Rollback、commit显式开启并控制一个 新的 Transaction 执行命令 set autocommit=0，用来禁止当前会话自动commit，控制 默认开启的事务 Redis： 用multi、exec、discard，显式开启并控制一个Transaction 实现原理MySQL： mysql 实现事务，是基于 undo/redo 日志 undo 记录修改前状态，rollback 基于 undo 日志实现 redo 记录修改后的状态，commit 基于 redo 日志实现 在 mysql 中无论是否开启事务，sql 都会被立即执行并返回执行结果，只是事务开启后执行后的状态只是记录在 redo 日志，执行 commit 之后，数据才会被写入磁盘 举个荔枝： 123int save = serviceOrderMapper.insertSelective(s);// save = 受影响的行数; save 将会被立即赋值（无论是否开启事务，只是结果或未被写入磁盘） Redis： redis 实现事务，是基于 commands 队列 如果没有开启事务，command 将会被立即执行并返回执行结果，并且直接写入磁盘 如果事务开启，command 不会被立即执行，而是排入队列，并返回排队状态（具体依赖于客户端自身实现）。调用 exec 才会执行 commands 队列 举个荔枝： 1boolean rSave = redisTemplate.opsForZSet().add(\"orderId\",orderId,System.currentTimeMillis()); 如果没有开启事务，操作被立即执行，rSave 将会被立即赋值（true / false） 如果开启事务，操作不会被立即执行，将会返回 null 值，而 rSave 的类型是boolean，所以将会抛出异常：java.lang.NullPointerException","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"redis","slug":"redis","permalink":"https://yugd.cn/tags/redis/"}]},{"title":"实践一下--Redis集群","slug":"面试--Redis集群","date":"2021-09-08T01:00:00.000Z","updated":"2022-05-26T18:17:37.536Z","comments":true,"path":"posts/26019/","link":"","permalink":"https://yugd.cn/posts/26019/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Redis 集群 (Redis Cluster) 写在前面 为什么需要 Redis 集群？ 这还用说，肯定是单实例有解决不掉的现实适用场景了呗！但是具体有哪些问题还是需要详细的总结一下，貌似 Redis 集群与其它集群模式还是有些区别滴~ 来，由练习模式过渡到实践模式吧，探寻一下 Redis 集群原理！","text":"每天一篇面试小知识 本篇着重介绍一下 Redis 集群 (Redis Cluster) 写在前面 为什么需要 Redis 集群？ 这还用说，肯定是单实例有解决不掉的现实适用场景了呗！但是具体有哪些问题还是需要详细的总结一下，貌似 Redis 集群与其它集群模式还是有些区别滴~ 来，由练习模式过渡到实践模式吧，探寻一下 Redis 集群原理！ Redis 集群介绍Redis 单实例缓存在某些场景下，单实例存 Redis 缓存会存在的几个问题 写并发 Redis 单实例读写分离可以解决读操作的负载均衡，但对于写操作，仍然是全部落在了 master 节点上面，在海量数据高并发场景，一个节点写数据容易出现瓶颈，造成 master 节点的压力上升。 海量数据的存储压力 单实例 Redis 本质上只有一台 master 作为存储，如果面对海量数据的存储，一台 redis 的服务器就应付不过来了，而且数据量太大意味着持久化成本高，严重时可能会阻塞服务器，造成服务请求成功率下降，降低服务的稳定性。 所以，针对以上的问题，redis 集群提供了较为完善的方案，解决了存储能力受到单机限制，写操作无法负载均衡的问题。投入集群的怀抱吧！ Redis 集群简单概述 Redis Cluster特点 多主多从，去中心化【从节点作为备用，复制主节点，不做读写操作，不提供服务】 不支持处理多个key【因为数据分散在多个节点，在数据量大高并发的情况下会影响性能】 支持动态扩容节点【Rerdis Cluster 最大的优点之一】 节点之间相互通信，相互选举，不再依赖 sentinel【准确来说是主节点之间相互“监督”，保证及时故障转移】 Redis Cluster 与其它集群模式的区别 相比较 sentinel 模式 多个 master 节点保证主要业务（比如 master 节点主要负责写）稳定性，不需要搭建多个 sentinel 实例监控一个 master 节点； 相比较一主多从的模式 不需要手动切换，具有自我故障检测，故障转移的特点； ★ 相比较其他两个模式而言，对数据进行分片（sharding），不同节点存储的数据是不一样的； ★ 从某种程度上来说，Sentinel模式主要针对高可用（HA），而Cluster模式是不仅针对大数据量，高并发，同时也支持HA； Redis 集群的概念介绍Redis 集群不支持那些需要同时处理多个键的 Redis 命令， 因为执行这些命令需要在多个 Redis 节点之间移动数据， 并且在高负载的情况下， 这些命令将降低 Redis 集群的性能， 并导致不可预测的错误。 Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。 Redis 集群提供了以下两个好处： 将数据自动切分（split）到多个节点的能力。 当集群中的一部分节点失效或者无法进行通讯时， 仍然可以继续处理命令请求的能力。 哈希槽（hash slot）Redis 集群使用一种称作一致性哈希的复合分区形式（组合了哈希分区和列表分袂的特征来计算键的归属实例），键的 CRC16 哈希值被称为哈希槽。 比如对于三个 Redis 节点，哈希槽的分配方式如下： 第一个节点拥有 0-5500 哈希槽； 第二节点拥有 5501-11000 哈希槽； 第三节点拥有剩余的 11001-16384 哈希槽； 一个键的对应的哈希槽通过计算键的 CRC16 哈希值，然后对16384进行取模得到：HASH_SLOT = CRC16 (key) modulo 16383，Redis 提供了 CLUSTER KEYSLOT 命令来执行哈希槽的计算； 举个荔枝 当我们创建一个 Cluster 时，系统会默认给我们分好片（你选择接受系统分配的配置），比如现在有 7000-7005 六个节点，其中我们分配 3 个主节点（7000-7002），3 个从节点（7003-7005） 其中 slots 系统已经指派给了：Master[1] 节点拥有 0-5500 哈希槽、Master[2] 节点拥有 5501-11000 哈希槽、Master[3] 节点拥有剩余的 11001-16384 哈希槽。 数据分片（data sharding）Redis 集群使用数据分片（sharding）而非一致性哈希（consistency hashing）来实现。 一个 Redis 集群包含 16384 个哈希槽（hash slot）， 数据库中的每个键都属于这 16384 个哈希槽的其中一个； 集群使用公式 CRC16（key） % 16384 来计算键 key 属于哪个槽， 其中 CRC16（key）语句用于计算键 key 的 CRC16 校验和 ； 集群中的每个节点负责处理一部分哈希槽； 举个荔枝 根据上述哈希槽来举个例子【一个集群可以有三个哈希槽 A、B、C】 节点 A 负责处理 0 号至 5500 号哈希槽。 节点 B 负责处理 5501 号至 11000 号哈希槽。 节点 C 负责处理 11001 号至 16384 号哈希槽。 这种将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点。 比如说：设置一个 key 1$ redisKey : set hash_name redisOne 按照 Redis Cluster 的哈希槽算法，CRC16 (‘hash_name’) %16384 = 2412 那么这个 key 就被分配到了节点 A 上。 同样的，当我连接 (A,B,C) 的任意一个节点想获取 hash_name 这个 key，都会转到节点 A 上。 再比如，如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以了。 增加一个D节点的结果可能如下： 节点 A 覆盖 1365-5460 节点 B 覆盖 6827-10922 节点 C 覆盖 12288-16383 节点 D 覆盖 0-1364,5461-6826,10923-1228 与此类似， 如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以了。 因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线。 Redis Cluster 模型 未完待续… …","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"redis","slug":"redis","permalink":"https://yugd.cn/tags/redis/"}]},{"title":"实践一下--Neo4j","slug":"实践--Neo4j","date":"2021-09-01T01:00:00.000Z","updated":"2022-05-26T18:18:41.536Z","comments":true,"path":"posts/3633/","link":"","permalink":"https://yugd.cn/posts/3633/","excerpt":"实践是检验真理的唯一标准 本篇着重介绍一下 Neo4j 写在前面 为啥要使用 Neo4j？ MySQL 不好用了吗？ No、No、No！因为最近的工作中遇到了一些知识图谱的工作，自然就用到了图数据库， NoSQL 数据库可以很好的展示节点之间的关联关系，对于一些图谱的关系操作是很好的选择哦～ Neo4j官网","text":"实践是检验真理的唯一标准 本篇着重介绍一下 Neo4j 写在前面 为啥要使用 Neo4j？ MySQL 不好用了吗？ No、No、No！因为最近的工作中遇到了一些知识图谱的工作，自然就用到了图数据库， NoSQL 数据库可以很好的展示节点之间的关联关系，对于一些图谱的关系操作是很好的选择哦～ Neo4j官网 Neo4j 介绍Neo4j 是什么 Neo4j 是图数据库中的佼佼者，采用 Java 编写，社区版已开源，商业版需收费。 Neo4j 是一个高性能的 NoSQL 图形数据库（Graph Database），它将结构化数据存储在网络上而不是表中。它是一个嵌入式的、基于磁盘的、具备完全的事务特性的 Java 持久化引擎，但是它将结构化数据存储在网络(从数学角度叫做图)上而不是表中。Neo4j 也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。Neo4j 拥有十分酷炫的可视化界面，这是一般图数据库所不具备的。 在一个图中包含两种基本的数据类型：Nodes（节点） 和 Relationships（关系）。Nodes 和 Relationships 包含 key / value 形式的属性。Nodes通过 Relationships 所定义的关系相连起来，形成关系型网络结构。 Neo4j 概览 在上述例子中，共有两类节点：City 和 Company，一类关系：(Company) -[belongTo]-&gt; (City)。 Neo4j 使用 [Cypher]AddCity的节点可以通过使用如下命令使用： 1234create (city: City&#123;name: &quot;上海市&quot;, area: &quot;6340.5平方千米&quot;, population: &quot;2487.09万人&quot;, alias: [&quot;沪&quot;, &quot;申&quot;]&#125;);create (city: City&#123;name: &quot;北京市&quot;, area: &quot;16410平方千米&quot;, population: &quot;2189.31万人&quot;, alias: [&quot;京&quot;, &quot;帝都&quot;]&#125;);create (city: City&#123;name: &quot;深圳市&quot;, area: &quot;1997.49平方千米&quot;, population: &quot;1756万人&quot;, alias: [&quot;深&quot;, &quot;鹏城&quot;]&#125;);create (city: City&#123;name: &quot;杭州市&quot;, area: &quot;16850平方千米&quot;, population: &quot;1193万人&quot;, alias: [&quot;杭&quot;]&#125;); 在上述语句中，create表示新建，小括号内是节点信息，节点的类型（label）是City，city是其别名，花括号内是该节点的属性，共有name、area、population、alias四个属性。注意：Neo4j支持列表这个数据类型，但不支持时间日期这个数据类型。 Company的节点可以通过使用如下命令使用： 1234567891011create (company: Company&#123;name: &quot;阿里&quot;&#125;);create (company: Company&#123;name: &quot;网易&quot;&#125;);create (company: Company&#123;name: &quot;百度&quot;&#125;);create (company: Company&#123;name: &quot;字节跳动&quot;&#125;);create (company: Company&#123;name: &quot;新浪&quot;&#125;);create (company: Company&#123;name: &quot;拼多多&quot;&#125;);create (company: Company&#123;name: &quot;B站&quot;&#125;);create (company: Company&#123;name: &quot;小红书&quot;&#125;);create (company: Company&#123;name: &quot;华为&quot;&#125;);create (company: Company&#123;name: &quot;腾讯&quot;&#125;);create (company: Company&#123;name: &quot;招商银行&quot;&#125;); 创建关系的命令如下： 1234567891011match (city: City&#123;name: &quot;杭州市&quot;&#125;), (company: Company&#123;name: &quot;阿里&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;杭州市&quot;&#125;), (company: Company&#123;name: &quot;网易&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;上海市&quot;&#125;), (company: Company&#123;name: &quot;拼多多&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;上海市&quot;&#125;), (company: Company&#123;name: &quot;B站&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;上海市&quot;&#125;), (company: Company&#123;name: &quot;小红书&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;北京市&quot;&#125;), (company: Company&#123;name: &quot;新浪&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;北京市&quot;&#125;), (company: Company&#123;name: &quot;百度&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;北京市&quot;&#125;), (company: Company&#123;name: &quot;字节跳动&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;深圳市&quot;&#125;), (company: Company&#123;name: &quot;华为&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;深圳市&quot;&#125;), (company: Company&#123;name: &quot;腾讯&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city);match (city: City&#123;name: &quot;深圳市&quot;&#125;), (company: Company&#123;name: &quot;招商银行&quot;&#125;) create (company) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city); 事实上，我们还可以用如下命令来实现关系的新建： 1create (company: Company&#123;name: &quot;阿里&quot;&#125;) -[r:belongTo&#123;name: &quot;所在城市&quot;&#125;]-&gt; (city:City&#123;name: &quot;杭州市&quot;&#125;); Update如果需要更新某个节点的属性，命令如下（比如将上海市节点的简称新增“魔都”这个名字）: 1234MATCH (city:City)WHERE city.name&#x3D;&quot;上海市&quot;SET city.alias&#x3D;[&quot;沪&quot;, &quot;申&quot;, &quot;魔都&quot;]RETURN city; DeleteCQL 的删除命令有 delete 和 remove，两者的区别为： delete 命令为删除节点、删除节点及相关节点和关系； remove 命令为删除节点或关系的标签、删除节点或关系的属性 我们以删除上海市节点的alias属性为例，命令如下： 123MATCH (city: City&#123;name: &quot;上海市&quot;&#125;)REMOVE city.aliasRETURN city; 注意，当我们在删除某个节点的时候，需要确定该节点无其他节点无关系相连，即该节点为孤立节点，否则，就会报错！ SelectCQL的查询语句是灵活、功能强大的。我们仅介绍简单的几个命令。 查询所有的节点： 1match (n) return (n); 查询所有节点的数量 1match (n) return count(n); 查询所有的Company节点 1match (n:Company) return (n); 查询名字为北京市的City节点 1match (n:City&#123;name: &quot;北京市&quot;&#125;) return (n); 查询招商银行与深圳市的关系 1match (a:Company&#123;name: &quot;招商银行&quot;&#125;) -[r]-&gt; (b:City&#123;name: &quot;深圳市&quot;&#125;) return type(r); 查询该图谱中杭州市下面的Company 1match (a:Company) -[r:belongTo]-&gt; (b:City&#123;name: &quot;杭州市&quot;&#125;) return (a); Springboot 集成 Neo4j SpringBoot 版本为 2.3.0.RELEASE 引入 Neo4j 的 POM 依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-neo4j&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 添加配置文件123spring.data.neo4j.uri=bolt://localhost:7687spring.data.neo4j.username=neo4jspring.data.neo4j.password=123456 创建 UserNode123456789101112131415161718//表示节点类型@NodeEntity(label=\"User\")@Datapublic class UserNode &#123; @Id private Long nodeId; @Property private String userId; @Property private String name; @Property private int age; &#125; 创建 Relation1234567891011121314//表示关系类型@RelationshipEntity(type=\"UserRelation\")@Datapublic class UserRelation &#123; @Id private Long id; @StartNode private UserNode startNode; @EndNode private UserNode endNode;&#125; 创建UserRepository1234567891011121314151617181920@Componentpublic interface UserRepository extends Neo4jRepository&lt;UserNode,Long&gt; &#123; /** * 查询所有节点 * @return */ @Query(\"MATCH (n:User) RETURN n \") List&lt;UserNode&gt; getUserNodeList(); /** * 创建节点 * @param userId * @param name * @param age * @return */ @Query(\"create (n:User&#123;userId:$userId,age:$age,name:$name&#125;) RETURN n \") List&lt;UserNode&gt; addUserNodeList(@Param(\"userId\") String userId,@Param(\"name\") String name, @Param(\"age\")int age);&#125; 创建 UserRelationRepository1234567891011121314151617181920212223@Componentpublic interface UserRelationRepository extends Neo4jRepository&lt;UserRelation,Long&gt; &#123; /** * 通过id 查询关系 * @param firstUserId * @param secondUserId * @return */ @Query(\"match p=(n:User)&lt;-[r:FRIEND]-&gt;(n1:User) where n.userId=$firstUserId and n1.userId=$secondUserId return p\") List&lt;UserRelation&gt; findUserRelationByEachId(@Param(\"firstUserId\") String firstUserId, @Param(\"secondUserId\") String secondUserId); /** * 添加关系 * @param firstUserId * @param secondUserId * @return */ @Query(\"match (fu:User),(su:User) where fu.userId=$firstUserId and su.userId=$secondUserId create p=(fu)-[r:FRIEND]-&gt;(su) return p\") List&lt;UserRelation&gt; addUserRelation(@Param(\"firstUserId\") String firstUserId, @Param(\"secondUserId\") String secondUserId);&#125; 创建 UserService123456789101112131415161718192021@Servicepublic class UserService &#123; @Autowired private UserRepository userRepository; @Autowired private UserRelationRepository userRelationRepository; public void addUserNode(UserNode userNode) &#123; userRepository.addUserNodeList(userNode.getUserId(),userNode.getName(), userNode.getAge()); &#125; public void addRelationship(String firstId,String secondId)&#123; userRelationRepository.addUserRelation(firstId,secondId); &#125; public void findUserRelationByEachId(String firstId,String secondId)&#123; userRelationRepository.findUserRelationByEachId(firstId, secondId); &#125;&#125; 创建 Neo4jController12345678910111213141516171819202122232425262728293031323334@RestControllerpublic class Neo4jController &#123; @Autowired private UserService userService; @RequestMapping(\"/saveUser\") public String saveUserNode(@RequestParam(\"user_id\") String userId, @RequestParam(\"user_name\") String userName) &#123; UserNode node = new UserNode(); node.setNodeId(1L); node.setUserId(userId); node.setName(userName); node.setAge(26); userService.addUserNode(node); return \"success\"; &#125; @RequestMapping(\"/addship\") public String saveShip(@RequestParam(\"user_id_first\") String userIdFirst, @RequestParam(\"user_id_second\") String userIdSecond)&#123; userService.addRelationship(userIdFirst,userIdSecond); return \"success\"; &#125; @RequestMapping(\"/findShip\") public String findShip()&#123; userService.findUserRelationByEachId(\"1\",\"2\"); return \"success\"; &#125;&#125; 启动类添加注解12345678@SpringBootApplication@EnableNeo4jRepositories(basePackages=\"com.ase.neo4j.repository\")@EntityScan(basePackages=\"com.ase.neo4j.entity\")public class Neo4jApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(Neo4jApplication.class, args); &#125;&#125; 启动测试分别添加两个 User，这里我测试数据为张三、李四，id 分别为 001，002 添加关系，将 UserId 为 001 和 002 两个节点添加 friend 的关系 访问路径：http://localhost:7474/browser/ ，成功~","categories":[{"name":"数据库","slug":"数据库","permalink":"https://yugd.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Neo4j","slug":"Neo4j","permalink":"https://yugd.cn/tags/Neo4j/"},{"name":"NoSQl","slug":"NoSQl","permalink":"https://yugd.cn/tags/NoSQl/"}]},{"title":"实践一下--Dubbo","slug":"面试--Dubbo","date":"2021-08-30T01:00:00.000Z","updated":"2022-05-26T18:16:58.097Z","comments":true,"path":"posts/44995/","link":"","permalink":"https://yugd.cn/posts/44995/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Dubbo 写在前面 什么是分布式系统？ 我个人觉得就是：分开部署的系统。 Dubbo官网","text":"每天一篇面试小知识 本篇着重介绍一下 Dubbo 写在前面 什么是分布式系统？ 我个人觉得就是：分开部署的系统。 Dubbo官网 为什么要使用分布式系统老式系统(单一应用架构)就是把一个系统，统一放到一个服务器当中然后每一个服务器上放一个系统，如果说要更新代码的话，每一个服务器上的系统都要重新去部署十分的麻烦。 而分布式系统就是将一个完整的系统拆分成多个不同的服务，然后在将每一个服务单独的放到一个服务器当中。 分布式系统中的相关概念衡量网站的性能指标 响应时间：指执行一个请求从开始到最后收到响应数据所花费的总体时间。 并发数：指系统同时能处理的请求数量。 并发连接数：指的是客户端向服务器发起请求，并建立了TCP连接。每秒钟服务器连接的总TCP数量 请求数：也称为 QPS (Query Per Second) 指每秒多少请求. 并发用户数：单位时间内有多少用户 吞吐量：指单位时间内系统能处理的请求数量。 QPS：Query Per Second 每秒查询数。 TPS：Transactions Per Second 每秒事务数。 一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。 一个页面的一次访问，只会形成一个TPS；但一次页面请求，可能产生多次对服务器的请求，就会有多个QPS QPS >= 并发连接数 >= TPS","categories":[{"name":"框架","slug":"框架","permalink":"https://yugd.cn/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"Dubbo","slug":"Dubbo","permalink":"https://yugd.cn/tags/Dubbo/"}]},{"title":"实践一下--跨域问题","slug":"实践--跨域问题","date":"2021-08-25T01:00:00.000Z","updated":"2022-05-26T18:18:28.506Z","comments":true,"path":"posts/27751/","link":"","permalink":"https://yugd.cn/posts/27751/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 跨域问题 写在前面 上文提到，目前项目都朝着前后端分离的方向发展，那前后端之间的数据通信便成为了不可避免的问题，这有 Axios 来帮助我们实现，但是今天要说的前后端之间的跨域问题。","text":"每天一篇面试小知识 本篇着重介绍一下 跨域问题 写在前面 上文提到，目前项目都朝着前后端分离的方向发展，那前后端之间的数据通信便成为了不可避免的问题，这有 Axios 来帮助我们实现，但是今天要说的前后端之间的跨域问题。 什么是跨域解释前端调用的后端接口不属于同一个域（域名或端口不同），就会产生跨域问题。 其实产生跨域问题的罪魁祸首是浏览器同源策略 浏览器同源策略同源策略是一个重要的安全策略，它用于限制一个 origin 的文档或者它加载的脚本如何能与另一个源的资源进行交互。它能帮助阻隔恶意文档，减少可能被攻击的媒介。 什么是同源？如果两个 URL 的 protocol、port (en-US) (如果有指定的话)和 host 都相同的话，则这两个 URL 是同源。这个方案也被称为“协议/主机/端口元组”，或者直接是 “元组”。（“元组” 是指一组项目构成的整体，双重/三重/四重/五重/等的通用形式）。 举个荔枝 与 URL http://store.company.com/dir/page.html 的源进行对比的示例： URL 结果 原因 http://store.company.com/dir2/other.html 同源 只有路径不同 http://store.company.com/dir/inner/another.html 同源 只有路径不同 https://store.company.com/secure.html 失败 协议不同 http://store.company.com:81/dir/etc.html 失败 端口不同 ( http:// 默认端口是80) http://news.company.com/dir/other.html 失败 主机不同（ IP 地址不同） 举个荔枝 访问：www.baidu.com 由下图可以看出，虽然 get 请求能发出去，有返回的结果，但是结果被浏览器拦截了 解决跨域为什么会发生跨域问题当协议、子域名、主域名、端口号中任意一个不相同时，都算作不同域，不同域之间的网络请求就会触发跨域问题。跨域并不是请求发不出去，请求能发出去，服务端能收到请求并正常返回结果，只是结果被浏览器拦截了 解决跨域问题的三种思路1、客户端浏览器解除跨域限制（×）【理论上可以但是不现实】 2、发送JSONP请求替代XHR请求（-）【并不能适用所有的请求方式，不推荐】 3、修改服务器端（√）【包括HTTP服务器和应用服务器，推荐】 客户端浏览器解除跨域限制浏览器会根据同源策略来判断一个请求是不是跨域请求。 非跨域请求，在请求头中会只包含请求的主机名。【host】 跨域请求，在请求头中会既包含要请求的主机名还包括当前的源主机名，如果这两者不一致，那就是跨域请求了。【host、origin】 浏览器对请求的分类在HTTP1.1 协议中的，请求方法分为 GET、POST、PUT、DELETE、HEAD、TRACE、OPTIONS、CONNECT 八种，浏览器根据这些请求方法和请求类型将请求划分为简单请求和非简单请求。 简单请求：浏览器先发送（执行）请求然后再判断是否跨域。 请求方法为 GET、POST、HEAD，请求头header中无自定义的请求头信息，请求类型Content-Type 为 text/plain、multipart/form-data、application/x-www-form-urlencoded 的请求都是简单请求。 非简单请求：浏览器先发送预检命令（OPTIONS方法），检查通过后才发送真正的数据请求。【”预检”请求】 预检命令会发送自定义头为 Access-Control-Request-Headers: content-type （访问控制请求头：内容类型）的请求到服务器，根据响应头的中的 “Access-Control-Allow-Headers”: “Content-Type” 判断服务器是否允许跨域访问。预检命令是可以缓存，服务器端设置 “Access-Control-Max-Age”: “3600”，这样后面发送同样的跨域请求就不需要先发送预检命令了。 前后端分离跨域Cross Origin Resource Share (CORS)【跨域源资源共享】 请求头主要包括 请求头 解释 Origin Origin头在跨域请求或预先请求中，标明发起跨域请求的源域名。 Access-Control-Request-Method Access-Control-Request-Method头用于表明跨域请求使用的实际HTTP方法 Access-Control-Request-Headers Access-Control-Request-Headers用于在预先请求时，告知服务器要发起的跨域请求中会携带的请求头信息 with-credentials 跨域请求携带cookie 响应头主要包括 响应头 解释 Access-Control-Allow-Origin Access-Control-Allow-Origin头中携带了服务器端验证后的允许的跨域请求域名，可以是一个具体的域名或是一个*（表示任意域名）。 Access-Control-Expose-Headers Access-Control-Expose-Headers头用于允许返回给跨域请求的响应头列表，在列表中的响应头的内容，才可以被浏览器访问。 Access-Control-Max-Age Access-Control-Max-Age用于告知浏览器可以将预先检查请求返回结果缓存的时间，在缓存有效期内，浏览器会使用缓存的预先检查结果判断是否发送跨域请求。 Access-Control-Allow-Methods Access-Control-Allow-Methods用于告知浏览器可以在实际发送跨域请求时，可以支持的请求方法，可以是一个具体的方法列表或是一个*（表示任意方法）。 SpringBoot 解决 CORS1、注解 @CrossOrigin （局部跨域） 在类上使用 @CrossOrigin 注解，表示该类的所有方法允许跨域 1234567891011@Controller@RequestMapping(\"/pass\")@CrossOrigin(originPatterns = \"*\", methods = &#123;GET, POST, PUT, DELETE&#125;)public class PassController &#123; @GetMapping(\"/\") @ResponseBody public Map&lt;String, Object&gt; findAll() &#123; //返回数据 return map; &#125;&#125; 在类上使用 @CrossOrigin 注解，以细粒度的去控制某一请求 API 是否支持跨域 123456789101112@Controller@RequestMapping(\"/pass\")public class PassController &#123; @GetMapping(\"/\") @ResponseBody //更小的解决跨域 设置只能某些地址访问 @CrossOrigin(originPatterns = \"http://localhost:8080\") public Map&lt;String, Object&gt; findAll() &#123; //返回数据 return map; &#125;&#125; 2、配置 CorsFilter (全局跨域)12345678910111213141516171819202122232425262728293031@SpringBootConfigurationpublic class WebGlobalConfig &#123; @Bean public CorsFilter corsFilter() &#123; //创建CorsConfiguration对象后添加配置 CorsConfiguration config = new CorsConfiguration(); //设置放行哪些原始域 config.addAllowedOrigin(\"*\"); //放行哪些原始请求头部信息 config.addAllowedHeader(\"*\"); //暴露哪些头部信息 config.addExposedHeader(\"*\"); //放行哪些请求方式 config.addAllowedMethod(\"GET\"); //get config.addAllowedMethod(\"PUT\"); //put config.addAllowedMethod(\"POST\"); //post config.addAllowedMethod(\"DELETE\"); //delete //corsConfig.addAllowedMethod(\"*\"); //放行全部请求 //是否发送Cookie config.setAllowCredentials(true); //2. 添加映射路径 UrlBasedCorsConfigurationSource corsConfigurationSource = new UrlBasedCorsConfigurationSource(); corsConfigurationSource.registerCorsConfiguration(\"/**\", config); //返回CorsFilter return new CorsFilter(corsConfigurationSource); &#125;&#125; 3、重写 WebMvcConfigurer（全局跨域）12345678910111213141516171819202122@SpringBootConfigurationpublic class CorsConfig implements WebMvcConfigurer &#123; //重写 WebMvcConfigurer下的 addCorsMappings方法 @Override public void addCorsMappings(CorsRegistry registry) &#123; //添加映射路径 registry.addMapping(\"/api/pass\") //addMapping后还可以继续配置 .allowedOrigins(\"http://localhost:8080\") //是否发送Cookie .allowCredentials(true) //设置放行哪些原始域 SpringBoot2.4.4下低版本使用.allowedOrigins(\"*\") .allowedOriginPatterns(\"*\") //放行哪些请求方式 .allowedMethods(new String[]&#123;\"GET\", \"POST\", \"PUT\", \"DELETE\"&#125;) //.allowedMethods(\"*\") //或者放行全部 //放行哪些原始请求头部信息 .allowedHeaders(\"*\") //暴露哪些原始请求头部信息 .exposedHeaders(\"*\"); &#125;&#125; 4、拦截器 Filter 实现123456789101112131415161718192021222324@Componentpublic class CorsFilter implements Filter &#123; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletResponse res = (HttpServletResponse) response; res.addHeader(\"Access-Control-Allow-Credentials\", \"true\"); res.addHeader(\"Access-Control-Allow-Origin\", \"*\"); res.addHeader(\"Access-Control-Allow-Methods\", \"GET, POST, DELETE, PUT\"); res.addHeader(\"Access-Control-Allow-Headers\", \"Content-Type,X-CAF-Authorization-Token,sessionToken,X-TOKEN\"); if (((HttpServletRequest) request).getMethod().equals(\"OPTIONS\")) &#123; response.getWriter().println(\"ok\"); return; &#125; chain.doFilter(request, response); &#125; @Override public void destroy() &#123; &#125; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125;&#125; 拓展一下Nginx 反向代理实现跨域打开 Nginx所在目录/conf/nginx.conf，将转发请求的配置粘贴到 http { ... } 中 123456789101112131415161718192021222324252627282930313233343536373839404142http &#123; ... server &#123; # 监听本地端口 80 listen 80; # 本地域名 server_name my-server.com; location / &#123; if ($request_method = 'OPTIONS') &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range'; add_header 'Access-Control-Max-Age' 1728000; add_header 'Content-Type' 'text/plain; charset=utf-8'; add_header 'Content-Length' 0; return 204; &#125; if ($request_method = 'POST') &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range'; add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range'; &#125; if ($request_method = 'GET') &#123; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range'; add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range'; &#125; # 将请求转发到指定的域名 proxy_pass https://www.baidu.com/; proxy_redirect off; &#125; &#125; ...&#125; 解释一下 my-server.com 是本地劫持的域名，www.baidu.com 是目标域名，我们请求 my-server.com 的时候，Nginx 就会将请求转发到 www.baidu.com 上。 访问成功~哈哈 年轻的我也能成为改变世界的动力！","categories":[{"name":"实践篇","slug":"实践篇","permalink":"https://yugd.cn/categories/%E5%AE%9E%E8%B7%B5%E7%AF%87/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://yugd.cn/tags/Web/"}]},{"title":"实用链接","slug":"实用链接","date":"2021-08-20T01:00:00.000Z","updated":"2022-05-26T18:13:28.030Z","comments":true,"path":"posts/53731/","link":"","permalink":"https://yugd.cn/posts/53731/","excerpt":"收集的各种优质的链接 写在前面 本篇博客是用于汇集各种编程相关的优质链接","text":"收集的各种优质的链接 写在前面 本篇博客是用于汇集各种编程相关的优质链接 一、使用教程篇1、全网最全的 postman 工具使用教程 2、SpringBoot教程 3、SpringBoot整合篇 二、算法提高篇1、LeetCode 最长公共前缀 2、LeetCode 罗马数字转整数 三、知识积累篇1、Redis 五种数据结构详解篇 2、Java 全栈知识体系篇 3、Java 一些过时方法与替换篇 4、for 循环优化篇 5、MQ 学习篇 6、POI 设置篇 7、IDEA 重构技巧篇 8、Lambda 表达式的应用篇 9、MySQL 基础语法篇 四、问题解决篇1、MybatisPlus 主键策略 2、SpringBoot–WebMvcConfigurer 3、Java-时间转换工具类 4、实现对象拷贝 五、体系架构篇1、淘宝技术架构演进 六、工作总结1、工作常用小技巧 2、工作常用小技巧2","categories":[{"name":"实践篇","slug":"实践篇","permalink":"https://yugd.cn/categories/%E5%AE%9E%E8%B7%B5%E7%AF%87/"}],"tags":[{"name":"链接","slug":"链接","permalink":"https://yugd.cn/tags/%E9%93%BE%E6%8E%A5/"}]},{"title":"实践一下--JWT","slug":"面试--JWT","date":"2021-08-17T13:00:00.000Z","updated":"2022-05-26T18:17:06.259Z","comments":true,"path":"posts/53148/","link":"","permalink":"https://yugd.cn/posts/53148/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 JWT 写在前面 目前大部分的项目都逐渐从单体架构向着前后端分离的方向发展 这个时候就涉及到前后端数据之间的交互，传输问题了， JWT 闪亮登场！","text":"每天一篇面试小知识 本篇着重介绍一下 JWT 写在前面 目前大部分的项目都逐渐从单体架构向着前后端分离的方向发展 这个时候就涉及到前后端数据之间的交互，传输问题了， JWT 闪亮登场！ JWT 是什么？基本概念 JWT全称是JSON Web Token，如果从字面上理解感觉是基于JSON格式用于网络传输的令牌。常见的场景如HTTP授权请求头参数和URI查询参数。 传统 Token 方式和 JWT传统 token 方式： 用户登录成功后，服务端生成一个随机 token 给用户，并且在服务端(数据库或缓存)中保存一份 token，以后用户再来访问时需携带 token，服务端接收到 token 之后，去数据库或缓存中进行校验 token 的是否超时、是否合法。 jwt 方式： 用户登录成功后，服务端通过 jwt 生成一个随机 token 给用户（服务端无需保留token），以后用户再来访问时需携带 token，服务端接收到 token之后，通过 jwt 对 token 进行校验是否超时、是否合法。 JWT 的结构简单的举个荔枝 在其紧凑形式中，JSON Web Tokens 由用点 ( .)分隔的三个部分组成，它们是： 标题（header）【令牌头部，记录了整个令牌的类型和签名算法】 有效载荷（payload）【令牌负荷，记录了保存的主体信息，比如你要保存的用户信息就可以放到这里】 签名（signature）【令牌签名，按照头部固定的签名算法对整个令牌进行签名，该签名的作用是：保证令牌不被伪造和篡改】 因此，JWT 通常如下所示。 1xxxxx.yyyyy.zzzzz =======&gt; 标题.有效载荷.签名 1、标题 标头通常由两部分组成：令牌的类型，即 JWT，以及正在使用的签名算法，例如 HMAC SHA256 或 RSA。 例如： 1234&#123; \"alg\": \"HS256\", \"typ\": \"JWT\"&#125; 然后，这个 JSON 被Base64Url编码以形成 JWT 的第一部分。 2、有效载荷 令牌的第二部分是负载，其中包含声明。声明是关于实体（通常是用户）和附加数据的声明。共有三种类型的声明：注册声明、公共声明和私人声明。 一个示例有效载荷可能是： 12345&#123; \"sub\": \"1234567890\", \"name\": \"John Doe\", \"admin\": true&#125; 然后对有效负载进行Base64Url编码以形成 JSON Web 令牌的第二部分。 3、签名 要创建签名部分，您必须获取编码的标头、编码的有效载荷、秘密、标头中指定的算法，并对其进行签名。 例如，如果要使用 HMAC SHA256 算法，则签名将通过以下方式创建： 1234HMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret) 签名用于验证消息在此过程中没有更改，并且在使用私钥签名的令牌的情况下，它还可以验证 JWT 的发送者是它所说的那个人。 4、放在一起 输出是三个由点分隔的 Base64-URL 字符串，可以在 HTML 和 HTTP 环境中轻松传递，同时与基于 XML 的标准（如 SAML）相比更加紧凑。 JWT 的原理JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。 12345&#123; \"姓名\": \"张三\", \"角色\": \"管理员\", \"到期时间\": \"2018年7月1日0点0分\" &#125; 以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名。 服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。 区别 session 存储在服务端占用服务器资源，而 JWT 存储在客户端 session 存储在 Cookie 中，存在伪造跨站请求伪造攻击的风险 session 只存在一台服务器上，那么下次请求就必须请求这台服务器，不利于分布式应用 存储在客户端的 JWT 比存储在服务端的 session 更具有扩展性 JWT的认证流程图 流程说明： 浏览器发起请求登陆，携带用户名和密码； 服务端验证身份，根据算法，将用户标识符打包生成 token; 服务器返回JWT信息给浏览器，JWT不包含敏感信息； 浏览器发起请求获取用户资料，把刚刚拿到的 token一起发送给服务器； 服务器发现数据中有 token，验明正身； 服务器返回该用户的用户资料； JSON 网络令牌如何工作每当用户想要访问受保护的路由或资源时，用户代理应该发送 JWT，通常在使用Bearer模式的Authorization标头中。标题的内容应如下所示： 1Authorization: Bearer &lt;token&gt; Authorization标头中的有效 JWT ，如果令牌在Authorization标头中发送，跨源资源共享 (CORS) 不会成为问题，因为它不使用 cookie。 JWT 的应用场景 Authorization (授权) 这是使用JWT的最常见场景。一旦用户登录，后续每个请求都将包含 JWT，允许用户访问该令牌允许的路由、服务和资源。单点登录是现在广泛使用的 JWT 的一个特性，因为它的开销很小，并且可以轻松地跨域使用。 Information Exchange (信息交换) 对于安全的在各方之间传输信息而言，JSON Web Tokens 无疑是一种很好的方式。因为 JWT 可以被签名，例如，用公钥/私钥对，你可以确定发送人就是它们所说的那个人。另外，由于签名是使用头和有效负载计算的，您还可以验证内容没有被篡改。 JWT 测试1、导入依赖123456&lt;!-- https://mvnrepository.com/artifact/com.auth0/java-jwt --&gt;&lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.14.0&lt;/version&gt;&lt;/dependency&gt; 2、生成token123456789101112131415161718192021222324252627282930/** * 常见的异常信息 * - SignatureVerificationException 签名不一致异常 * - TokenExpiredException 令牌过期异常 * - AlgorirhmMismatchExceotion 算法不匹配异常 * - InvalidClaimException 失效的payload异常 **/@Log4j2@SpringBootTest@DisplayName(\"JWTTest 接口测试\")public class JWTTest &#123; @Test @DisplayName(\"生成 token\") public void creatToken() &#123; HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"typ\", \"JWT\"); map.put(\"alg\", \"HS256\"); Calendar instance = Calendar.getInstance(); // 20秒后令牌token失效 instance.add(Calendar.SECOND, 5 * 60); String token = JWT.create() .withHeader(map) // header可以不写，因为默认值就是它 .withClaim(\"userId\", 21) //payload .withClaim(\"username\", \"tom\") .withExpiresAt(instance.getTime()) // 指定令牌的过期时间 .sign(Algorithm.HMAC256(\"jsonwebtoken\"));//签名 log.info(token); &#125;&#125; 生成结果 1token:eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJwYXNzd29yZCI6IjEyMzQ1NiIsIm5hbWUiOiJqYW1lcyIsImV4cCI6MTYzMDM1NDU4Mn0.ubecr4PGlovbRggmfZBgoOnThtsSyykLyrcMiAmOaqY 3、根据令牌和签名解析数据12345678910111213141516@Log4j2@SpringBootTest@DisplayName(\"JWTTest 接口测试\")public class JWTTest &#123; @Test @DisplayName(\"根据令牌和签名解析数据\") public void decryptionToken() &#123; // 通过签名生成验证对象 JWTVerifier jwtVerifier = JWT.require(Algorithm.HMAC256(\"jsonwebtoken\")).build(); String token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2Mjk3NDEwNjQsInVzZXJJZCI6MjEsInVzZXJuYW1lIjoidG9tIn0._spam3Ix5AvASN857eUOSFzDnVmZwk754lCbv8p4VfE\"; DecodedJWT verify = jwtVerifier.verify(token); log.info(verify.getClaim(\"userId\")); log.info(verify.getClaim(\"username\")); log.info(\"令牌过期时间：\" + verify.getExpiresAt()); &#125;&#125; 生成结果 123[ main] c.a.m.t.t.JWTTest : \"james\"[ main] c.a.m.t.t.JWTTest : \"123456\"[ main] c.a.m.t.t.JWTTest : 令牌过期时间：Tue Aug 31 04:16:22 CST 2021 4、常见的异常信息1234- SignatureVerificationException 签名不一致异常- TokenExpiredException 令牌过期异常- AlgorirhmMismatchExceotion 算法不匹配异常- InvalidClaimException 失效的payload异常 JWT + SpringBoot1、导入依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899&lt;!-- spring-boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt;&lt;!-- 去掉springboot默认配置 --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 引入log4j2依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--MyBatis-Plus代码生成器需要的依赖，开始--&gt; &lt;!-- lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- mysql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.49&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis-plus --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;!-- &lt;version&gt;3.2.0&lt;/version&gt;--&gt; &lt;version&gt;3.4.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 代码生成器 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Velocity --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!--MyBatis-Plus代码生成器需要的依赖，结束--&gt; &lt;!-- swagger --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.auth0/java-jwt --&gt; &lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.14.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 2、Mybatis-Plus 自动生成entity 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Data@EqualsAndHashCode(callSuper = false)@TableName(\"user\")@ApiModel(value=\"User对象\", description=\"InnoDB free: 10240 kB\")public class User implements Serializable &#123; private static final long serialVersionUID = 1L; @ApiModelProperty(value = \"主键ID\") @TableId(value = \"id\", type = IdType.AUTO) private Long id; @ApiModelProperty(value = \"姓名\") @TableField(\"name\") private String name; @ApiModelProperty(value = \"密码\") @TableField(\"password\") private String password; @ApiModelProperty(value = \"年龄\") @TableField(\"age\") private Integer age; @ApiModelProperty(value = \"邮箱\") @TableField(\"email\") private String email; @ApiModelProperty(value = \"创建时间\") @TableField(value = \"create_time\", fill = FieldFill.INSERT) private Date createTime; @ApiModelProperty(value = \"更新时间\") @TableField(value = \"update_time\", fill = FieldFill.INSERT_UPDATE) private Date updateTime; @ApiModelProperty(value = \"乐观锁\") @TableField(\"version\") @Version private Integer version; @ApiModelProperty(value = \"逻辑删除\") @TableField(\"remove_logic\") private Integer removeLogic;&#125; controller 1234567891011121314151617181920212223242526272829303132333435@Api(\"用户管理\")@RestController@RequestMapping(\"/abc/user\")public class UserController &#123; @Autowired private UserService userService; /** * 用户登录 */ @ApiOperation(\"用户登录\") @GetMapping(\"/login\") public Result login(@RequestParam(\"name\") String name, @RequestParam(\"password\") String password) &#123; return userService.login(name, password); &#125; /** * 查询所有用户 */ @ApiOperation(\"查询所有用户\") @GetMapping(\"/query_all_list\") public Result queryAllList() &#123; return userService.queryAllList(); &#125; /** * 验证 token 合法性 */ @ApiOperation(\"用户登录\") @PostMapping(\"/verify\") public Result verify(@RequestParam(\"token\") String token) &#123; return userService.verify(token); &#125;&#125; service 1234567891011121314151617public interface UserService extends IService&lt;User&gt; &#123; /** * 用户登录 */ Result login(String name, String password); /** * 验证 token 合法性 */ Result verify(String token); /** * 查询所有用户 */ Result queryAllList();&#125; serviceImpl 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Log4j2@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt; implements UserService &#123; @Autowired private UserMapper userMapper; /** * 用户登录 */ @Override public Result login(String name, String password) &#123; log.info(\"用户名：[&#123;&#125;]\", name); log.info(\"密码：[&#123;&#125;]\", password); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); try &#123; QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(\"name\", name).eq(\"password\", password); User userInfo = userMapper.selectOne(wrapper); // log.info(\"用户：[&#123;&#125;]\", userInfo.toString()); // 设置 payload 有效信息 Map&lt;String, String&gt; payload = new HashMap&lt;&gt;(); payload.put(\"name\", userInfo.getName()); payload.put(\"password\", userInfo.getPassword()); // 生成jwt令牌 String token = JwtUtils.creatToken(payload); map.put(\"name\", userInfo.getName()); map.put(\"password\", userInfo.getPassword()); map.put(\"token\", token); // 响应token return ResUtils.success(map); &#125; catch (Exception e) &#123; map.put(\"state\", false); map.put(\"msg\", e.getMessage()); return ResUtils.failure(map); &#125; &#125; /** * 验证 token 合法性 */ @Override public Result verify(String token) &#123; log.info(\"当前token为：[&#123;&#125;]\", token); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); try &#123; // 验证令牌 JwtUtils.verifyGetTokenInfo(token); map.put(\"state\", true); map.put(\"msg\", \"请求成功\"); return ResUtils.success(map); &#125; catch (SignatureVerificationException e) &#123; e.printStackTrace(); map.put(\"msg\", \"无效签名！\"); return ResUtils.failure(map); &#125; catch (TokenExpiredException e) &#123; e.printStackTrace(); map.put(\"msg\", \"token过期\"); return ResUtils.failure(map); &#125; catch (AlgorithmMismatchException e) &#123; e.printStackTrace(); map.put(\"msg\", \"算法不一致\"); return ResUtils.failure(map); &#125; catch (Exception e) &#123; e.printStackTrace(); map.put(\"msg\", \"token无效！\"); return ResUtils.failure(map); &#125; &#125; /** * 查询所有用户 */ @Override public Result queryAllList() &#123; return ResUtils.success(userMapper.selectList(null)); &#125;&#125; mapper 123public interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; mapper.xml 12345&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.ase.mybatis.abc.mapper.UserMapper\"&gt;&lt;/mapper&gt; 3、封装 JWT 工具类1234567891011121314151617181920212223242526272829303132333435public class JwtUtils &#123; /** * 设置加密的私钥 */ private static final String SING = \"jsonwebtoken\"; /** * 1、生成 token header.payload.singature 【加密后发送给客户端】 */ public static String creatToken(Map&lt;String, String&gt; map) &#123; Calendar instance = Calendar.getInstance(); // 默认7天过期 instance.add(Calendar.DATE, 7); //创建jwt builder JWTCreator.Builder builder = JWT.create(); // payload map.forEach((k, v) -&gt; &#123; builder.withClaim(k, v); &#125;); String token = builder.withExpiresAt(instance.getTime()) //指定令牌过期时间 .sign(Algorithm.HMAC256(SING)); // sign return token; &#125; /** * 2、验证 token 合法性, 并获取 token 信息方法 【客户端请求时 header 中携带, 如果客户端携带的 token 是合法的, 则获取有效载荷中的数据】 * @return */ public static DecodedJWT verifyGetTokenInfo(String token) &#123; return JWT.require(Algorithm.HMAC256(SING)).build().verify(token); &#125;&#125; 4、创建拦截器123456789101112131415161718192021222324252627282930313233343536373839404142434445public class JwtInterceptors implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); // 获取请求头中令牌 String token = request.getHeader(\"Authorization\"); // 要删除的字符串结束位置 int end; // 正规表达式 String regPattern = \"Bearer \"; Pattern pattern = Pattern.compile(regPattern, Pattern.CASE_INSENSITIVE); // 去掉原始字符串开头位置的指定字符 Matcher matcher = pattern.matcher(token); if (matcher.lookingAt()) &#123; end = matcher.end(); token = token.substring(end); &#125; System.out.println(token); try &#123; // 验证令牌 JwtUtils.verifyGetTokenInfo(token); map.put(\"state\", true); map.put(\"msg\", \"请求成功\"); return true; // 放行请求 &#125; catch (SignatureVerificationException e) &#123; e.printStackTrace(); map.put(\"msg\",\"无效签名！\"); &#125;catch (TokenExpiredException e)&#123; e.printStackTrace(); map.put(\"msg\",\"token过期\"); &#125;catch (AlgorithmMismatchException e)&#123; e.printStackTrace(); map.put(\"msg\",\"算法不一致\"); &#125;catch (Exception e)&#123; e.printStackTrace(); map.put(\"msg\",\"token无效！\"); &#125; map.put(\"state\",false); // 设置状态 // 将map以json的形式响应到前台 map --&gt; json (jackson) String json = new ObjectMapper().writeValueAsString(map); response.setContentType(\"application/json;charset=UTF-8\"); response.getWriter().println(json); return false; &#125;&#125; 5、定制拦截器规则1234567891011@Configurationpublic class InterceptorConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; //注册添加拦截器 JwtInterceptors registry.addInterceptor(new JwtInterceptors()) .addPathPatterns(\"/**\") // 其他接口token验证 【用于设置拦截器的过滤路径规则；addPathPatterns(\"/**\")对所有请求都拦截】 .excludePathPatterns(\"/abc/user/login\"); // 登录是所有用户都放行的 【用于设置不需要拦截的过滤规则】 &#125;&#125; 6、请求头验证token登录获取 token 编写脚本将 token 存在环境变量中，即时更新 请求携带 token 通过验证得到返回结果","categories":[{"name":"框架","slug":"框架","permalink":"https://yugd.cn/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"spring","slug":"spring","permalink":"https://yugd.cn/tags/spring/"}]},{"title":"实践一下--MyBatisPlus","slug":"实践--MyBatisPlus","date":"2021-08-14T13:00:00.000Z","updated":"2022-05-26T18:18:39.138Z","comments":true,"path":"posts/51171/","link":"","permalink":"https://yugd.cn/posts/51171/","excerpt":"实践是检验真理的唯一标准 本篇着重介绍一下 MyBatisPlus 写在前面 忙里偷闲，趁着有时间来写一篇关于 MybatisPlus 的学习笔记！ 其实官网上的 API 很全面，不会的就去官网上查一查~ MyBatisPlus官网","text":"实践是检验真理的唯一标准 本篇着重介绍一下 MyBatisPlus 写在前面 忙里偷闲，趁着有时间来写一篇关于 MybatisPlus 的学习笔记！ 其实官网上的 API 很全面，不会的就去官网上查一查~ MyBatisPlus官网 MyBatisPlus 简介特性 无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ） 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用 内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询 分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer 等多种数据库 内置性能分析插件：可输出 SQL 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询 内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作 框架结构 MyBatisPlus 快速入门简单的 Demo 实现数据库中创建 User 表12345678910111213141516171819DROP TABLE IF EXISTS user;CREATE TABLE user( id BIGINT(20) NOT NULL COMMENT &#39;主键ID&#39;, name VARCHAR(30) NULL DEFAULT NULL COMMENT &#39;姓名&#39;, age INT(11) NULL DEFAULT NULL COMMENT &#39;年龄&#39;, email VARCHAR(50) NULL DEFAULT NULL COMMENT &#39;邮箱&#39;, PRIMARY KEY (id));DELETE FROM user;INSERT INTO user (id, name, age, email) VALUES(1, &#39;Jone&#39;, 18, &#39;test1@baomidou.com&#39;),(2, &#39;Jack&#39;, 20, &#39;test2@baomidou.com&#39;),(3, &#39;Tom&#39;, 28, &#39;test3@baomidou.com&#39;),(4, &#39;Sandy&#39;, 21, &#39;test4@baomidou.com&#39;),(5, &#39;Billie&#39;, 24, &#39;test5@baomidou.com&#39;); 添加 mybatis-plus 依赖12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt;&lt;/dependency&gt; 注意引入了mybatisplus就不要再引入mybatis的启动器了 编写 application.yml 文件123456789101112spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatis-plus?serverTimezone=Asia/Shanghai&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;allowPublicKeyRetrieval=true username: root password: root mybatis-plus: configuration: map-underscore-to-camel-case: true auto-mapping-behavior: full log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 创建实体类12345678910111213@Data@AllArgsConstructor@NoArgsConstructor@ToStringpublic class User &#123; //主键自增 @TableId(type = IdType.AUTO) private Long id; private String name; private Integer age; private String email;&#125; 创建 Mapper 接口123@Repositorypublic interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; 添加扫描注解123456789@SpringBootApplication@MapperScan(\"com.ase.mybatis.mapper\") //更加的灵活public class MybatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MybatisApplication.class, args); &#125;&#125; 编写测试类123456789101112131415161718192021222324252627@Log4j2@SpringBootTest@DisplayName(\"MybatisPlus 接口测试\")public class MybatisPlusTest &#123; @Autowired private UserMapper userMapper; @Test @DisplayName(\"测试查询全部\") void queryAllList() &#123; List&lt;User&gt; userList = userMapper.selectList(null); userList.forEach(user -&gt; log.info(user)); &#125; @Test @DisplayName(\"测试插入一条数据\") void saveUserOne() &#123; User user = new User(); user.setName(\"Tom\"); user.setAge(23); user.setEmail(\"tom@163.com\"); //插入的条数 int insert = userMapper.insert(user); log.info(insert); &#125;&#125; service接口12public interface UserService extends IService&lt;User&gt; &#123;&#125; service实现类12345678910/** * service实现类 继承mybatisplus提供通用的service基类 * ServiceImpl&lt;UserMapper, User&gt; * 2个泛型 ： * 第一个是Mapper接口 * 第二个是对应实体类 */@Servicepublic class UserServiceImpl extends ServiceImpl&lt;UserMapper, User&gt;implements UserService &#123;&#125; 常用注解@TableName【映射数据库的表名，数据库表名为user】 描述：用来将实体对象与数据库表名完成映射 修饰范围：作用在类上 常见属性： value：string类型，指定映射的表名 @TableId【数据库插入的id值默认为：全局的唯一id】 描述：主键主键 修饰范围:用在属性上 常见属性： value：String类型，指定实体类中与表对应的主键列名 type：枚举类型，指定主键生成策略 123456789101112131415161718//数据库ID自增AUTO(0),NONE(1),//用户输入IDINPUT(2),ASSIGN_ID(3),ASSIGN_UUID(4),//后面3个被淘汰了/** @deprecated */@DeprecatedID_WORKER(3),/** @deprecated */@DeprecatedID_WORKER_STR(3),/** @deprecated */@DeprecatedUUID(4); AUTO 默认就是数据库⾃增，开发者⽆需赋值，会主动回填。但是数据库的主键要有自增长 ASSIGN_ID mybatisplus ⾃动赋值，雪花算法 全局ID生成策略 在全局配置文件中，就不需要在每个pojo的主键上配置了 1234mybatis-plus: global-config: db-config: id-type: auto @TableField 描述字段注解（非主键） 修饰范围:用在属性上 @Version【标记乐观锁，通过 version 字段来保证数据的安全性，当修改数据的时候，会以 version 作为条件，当条件成立的时候才会修改成功】 举个荔枝： version = 1 线程 1：update … set version = 2 where version = 1 线程2 ：update … set version = 2 where version = 1 这样就只有一个线程会执行 乐观锁实现方式： 取出记录时，获取当前 version 更新时，带上这个 version 执行更新时， set version = newVersion where version = oldVersion 如果 version 不对，就更新失败 123456789101112@Data@NoArgsConstructor@AllArgsConstructorpublic class User &#123; @TableId(type =IdType.AUTO) private Long id; private String name; private Integer age; private String email; @Version private int version;&#125; 注册配置类 123456789@Configurationpublic class MyBatisPlusConfig &#123; @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() &#123; MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor()); return interceptor; &#125;&#125; @EnumValue【通用枚举类注解，将数据库字段映射成实体类的枚举类型成员变量】 123456789101112public enum StatusEnum &#123; SUCCESS(200,\"成功\"), FAILURE(300,\"失败\"); @EnumValue private Integer code; private String msg; StatusEnum(Integer code, String msg) &#123; this.code = code; this.msg = msg; &#125;&#125; 123456789101112@Data@NoArgsConstructor@AllArgsConstructorpublic class User &#123; @TableId(type =IdType.AUTO) private Long id; private String name; private Integer age; private String email; private Integer version; private StatusEnum status;&#125; application.yml 12mybatis-plus: type-enums-package: com.example.mybatisplus.enums @TableLogic【映射逻辑删除】 属性 类型 必须指定 默认值 描述 value String 否 “” 逻辑未删除值 delval String 否 “” 逻辑删除值 物理删除【在删除的时候直接将数据库的数据从数据库删除掉】 逻辑删除【在逻辑层面控制删除，通常会在表里加入对应的逻辑删除标识字段，deleted，默认是有效的值为0，当用户删除时将数据修改为1.查询是只查询deleted=0的】 1234567891011121314@Data@NoArgsConstructor@AllArgsConstructorpublic class User &#123; @TableId(type =IdType.AUTO) private Long id; private String name; private AgeEnum age; private String email; private Integer version; private StatusEnum status; @TableLogic private Integer deleted;&#125; application.yml 添加配置 12345678mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl type-enums-package: com.example.mybatisplus.enums global-config: db-config: logic-not-delete-value: 0 logic-delete-value: 1 查询不会查询 deleted 为 1 的数据 @OrderBy【内置 SQL 默认指定排序，优先级低于 wrapper 条件查询】 属性 类型 必须指定 默认值 描述 isDesc boolean 否 true 是否倒序查询 delval String 否 Short.MAX_VALUE 数字越小越靠前 条件构造器wrapper【条件构造器】 Wrapper ： 条件构造抽象类，最顶端父类 AbstractWrapper ： 用于查询条件封装，生成 sql 的 where 条件 QueryWrapper ： Entity 对象封装操作类，不是用lambda语法 UpdateWrapper ： Update 条件封装，用于Entity对象更新操作 AbstractLambdaWrapper ： Lambda 语法使用 Wrapper统一处理解析 lambda 获取 column。 LambdaQueryWrapper ：看名称也能明白就是用于Lambda语法使用的查询Wrapper LambdaUpdateWrapper ： Lambda 更新封装Wrapper 函数名 说明 例子 eq 等于 = eq(“name”, “老王”)—&gt;name = ‘老王’ ne 不等于 &lt;&gt; 例: ne(“name”, “老王”)—&gt;name &lt;&gt; ‘老王’ gt 大于 &gt; gt(“age”, 18)—&gt;age &gt; 18 ge 大于等于 &gt;= ge(“age”, 18)—&gt;age &gt;= 18 lt 小于 &lt; lt(“age”, 18)—&gt;age &lt; 18 le 小于等于 &lt;= le(“age”, 18)—&gt;age &lt;= 18 between BETWEEN 值1 AND 值2 between(“age”, 18, 30)—&gt;age between 18 and 30 notBetween NOT BETWEEN 值1 AND 值2 notBetween(“age”, 18, 30)—&gt;age not between 18 and 30 like LIKE ‘%值%’ like(“name”, “王”)—&gt;name like ‘%王%’ notLike NOT LIKE ‘%值%’ notLike(“name”, “王”)—&gt;name not like ‘%王%’ likeLeft LIKE ‘%值’ likeLeft(“name”, “王”)—&gt;name like ‘%王’ likeRight LIKE ‘值%’ likeRight(“name”, “王”)—&gt;name like ‘王%’ isNul 字段 IS NULL isNull(“name”)—&gt;name is null isNotNull 字段 IS NOT NULL isNotNull(“name”)—&gt;name is not null in 字段 IN (value.get(0), value.get(1), …) in(“age”,{1,2,3})—&gt;age in (1,2,3) in 字段 IN (v0, v1, …) in(“age”, 1, 2, 3)—&gt;age in (1,2,3) notIn 字段 NOT IN (value.get(0), value.get(1), …) notIn(“age”,{1,2,3})—&gt;age not in (1,2,3) notIn 字段 NOT IN (v0, v1, …) age not in (1,2,3) inSql 字段 IN ( sql语句 ) inSql( “ age “, “1 ,2,3,4,5,6”)—&gt;age in (1,2,3,4,5,6) ， inSql(“id”, “select id from table where id &lt; 3”)—&gt;id in (select id from table where id groupBy 分组：GROUP BY 字段, … groupBy(“id”, “name”)—&gt;group by id,name orderByAsc 排序：ORDER BY 字段, … ASC orderByAsc(“id”, “name”)—&gt;order by id ASC,name ASC orderByDesc 排序：ORDER BY 字段, … DESC orderByDesc(“id”, “name”)—&gt;order by id DESC,name DESC orderBy 排序：ORDER BY 字段, … orderBy(true, true, “id”, “name”)—&gt;order by id ASC,name ASC having HAVING ( sql语句 ) having(“sum(age) &gt; 10”)—&gt;having sum(age) &gt; 10 or 拼接 OR 注意事项:主动调用or表示紧接着下一个方法不是用and连接!(不调用or则默认为使用and连接) eq(“id”,1).or().eq(“name”,“老王”)—&gt;id = 1 or name = ‘老王’ and AND 嵌套 and(i -&gt; i.eq(“name”, “李白”).ne(“status”, “活着”))—&gt;and (name = ‘李白’ and status &lt;&gt; ‘活着’) nested 正常嵌套 不带 AND 或者 OR nested(i -&gt; i.eq(“name”, “李白”).ne(“status”, “活着”))—&gt;(name = ‘李白’ and status &lt;&gt; ‘活着’) last 无视优化规则直接拼接到 sql 的最后 注意事项: 只能调用一次,多次调用以最后一次为准 有sql注入的风险,请谨慎使用 last(“limit 1”) exists 拼接 EXISTS ( sql语句 ) exists(“select id from table where age = 1”)—&gt;exists (select id from table where age = 1) notExists 拼接 NOT EXISTS ( sql语句 ) notExists(“select id from table where age = 1”)—&gt;not exists (select id from table where age = 1) QueryWrapperselect【设置查询字段】 123select(String... sqlSelect)select(Predicate&lt;TableFieldInfo&gt; predicate)select(Class&lt;T&gt; entityClass, Predicate&lt;TableFieldInfo&gt; predicate) 例：select(“id”, “name”, “age”) 例:：select(i -&gt; i.getProperty().startsWith(“test”)) UpdateWrapperset 12set(String column, Object val)set(boolean condition, String column, Object val) 例: set(“name”, “老李头”) 例: set(“name”, “”)—&gt;数据库字段值变为空字符串 例: set(“name”, null)—&gt;数据库字段值变为null Select12345678910111213141516171819202122// 根据 ID 查询T selectById(Serializable id);// 根据 entity 条件，查询一条记录T selectOne(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);// 查询（根据ID 批量查询）List&lt;T&gt; selectBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList);// 根据 entity 条件，查询全部记录List&lt;T&gt; selectList(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);// 查询（根据 columnMap 条件）List&lt;T&gt; selectByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap);// 根据 Wrapper 条件，查询全部记录List&lt;Map&lt;String, Object&gt;&gt; selectMaps(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);// 根据 Wrapper 条件，查询全部记录。注意： 只返回第一个字段的值List&lt;Object&gt; selectObjs(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);// 根据 entity 条件，查询全部记录（并翻页）IPage&lt;T&gt; selectPage(IPage&lt;T&gt; page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);// 根据 Wrapper 条件，查询全部记录（并翻页）IPage&lt;Map&lt;String, Object&gt;&gt; selectMapsPage(IPage&lt;T&gt; page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);// 根据 Wrapper 条件，查询总记录数Integer selectCount(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); 查询所有不加条件123//不加任何条件全部查询List&lt;User&gt; users = mapper.selectList(null);users.forEach(System.out::println); 查询单条记录注意：seletOne返回的是一条实体记录，当出现多条时会报错 123QueryWrapper wrapper = new QueryWrapper();wrapper.eq(\"id\",7);System.out.println(mapper.selectOne(wrapper)); 通过id查询1234//查询单个idUser user = mapper.selectById(1);//批量操作查询多个idList&lt;User&gt; users = mapper.selectBatchIds(Arrays.asList(7, 8, 9)); 通过map查询map只能做等值判断，逻辑判断需要使用wrapper 1234//Map 只能做等值判断，逻辑判断需要使用 Wrapper 来处理Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();map.put(\"id\",7);mapper.selectByMap(map).forEach(System.out::println); 注意：map中的key对应的是数据库中的列名。例如数据库user_id，实体类是userId，这时map的key需要填写user_id 单条件查询1234//查询name为cb的用户QueryWrapper wrapper=new QueryWrapper();wrapper.eq(\"name\",\"cb\");System.out.println(mapper.selectList(wrapper)); 多条件查询12345678//多条件查询//查询name为cb,age为18的用户QueryWrapper wrapper=new QueryWrapper();Map&lt;String,Object&gt; map=new HashMap&lt;&gt;();map.put(\"name\",\"cb\");map.put(\"age\",18);wrapper.allEq(map);System.out.println(mapper.selectList(wrapper)); 12345wrapper.gt(\"age\",18); //大于wrapper.ne(\"name\",\"cb\"); //等于wrapper.ge(\"age\",18); //大于等于wrapper.lt(\"age\",18); //小于wrapper.le(\"age\",18); //小于等于 模糊查询123456789101112//模糊查询QueryWrapper wrapper=new QueryWrapper();//相对于 like '%b%'wrapper.like(\"name\",\"b\");//相当于 like '%b'wrapper.likeLeft(\"name\",\"b\");//相当于 like 'b%'wrapper.likeRight(\"name\",\"b\");System.out.println(mapper.selectList(wrapper)); 子查询12wrapper.inSql(\"id\",\"select id from user where id &lt; 10\");wrapper.inSql(\"age\",\"select age from user where age &gt; 3\"); 排序123wrapper.orderByDesc(\"age\");wrapper.orderByAsc(\"age\");wrapper.having(\"id &gt; 8\"); 查询数量返回的是有几条数据 123QueryWrapper wrapper = new QueryWrapper();wrapper.eq(\"id\",7);System.out.println(mapper.selectCount(wrapper)); 将查询结果封装到map返回map而不是原来的对象 123QueryWrapper wrapper = new QueryWrapper();wrapper.eq(\"id\",7);mapper.selectMaps(wrapper).forEach(System.out::println); 分页查询配置 12345678910@Configurationpublic class MyBatisPlusConfig &#123; // 最新版 @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() &#123; MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.H2)); return interceptor; &#125;&#125; mapper方法返回page对象1234567891011//分页查询//第一个参数是页数//第二个参数每页的条数Page&lt;User&gt; page=new Page&lt;&gt;(1,5);Page&lt;User&gt; result = mapper.selectPage(page, null);//每页条数System.out.println(result.getSize());//总数System.out.println(result.getTotal());//查询结果result.getRecords().forEach(System.out::println); 12345678getCurrent 当前页getRecords 每页数据list集合getSize 每页显示记录数getTotal 总记录数getPages 总页数hasNext 是否有下一页hasPrevious 是否有上一页 mapper方法返回map集合12Page&lt;Map&lt;String,Object&gt;&gt; page = new Page&lt;&gt;(1,2);mapper.selectMapsPage(page,null).getRecords().forEach(System.out::println); service方法返回page对象123456789IPage&lt;User&gt; ipage=new Page&lt;&gt;(1,2);IPage&lt;User&gt; page = userService.page(ipage);List&lt;User&gt; records = page.getRecords();System.out.println(records);//总共数据的条数System.out.println(page.getTotal());//总共数据的页数System.out.println(page.getPages()); xml自定义分页UserMapper12345678910111213@Repositorypublic interface UserMapper extends BaseMapper&lt;User&gt; &#123; /** * &lt;p&gt; * 查询 : 根据年龄查询用户列表，分页显示 * &lt;/p&gt; * * @param page 分页对象,xml中可以从里面进行取值,传递参数 Page 即自动分页,必须放在第一位(你可以继承Page实现自己的分页对象) * @param age 年龄 * @return 分页对象 */ IPage&lt;User&gt; getByAge(IPage iPage,Integer age);&#125; UserMapper.xml 等同于编写一个普通 list 查询，mybatis-plus 自动分页 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.blb.mybatisplus2.mapper.UserMapper\"&gt; &lt;select id=\"getByAge\" resultType=\"User\"&gt; select * from user1 where age=#&#123;age&#125; &lt;/select&gt;&lt;/mapper&gt; UserServiceImpl.java 调用分页方法 123456@Testvoid xmlPage()&#123; IPage&lt;User&gt; byAge = userMapper.getByAge(new Page(1, 2), 18); List&lt;User&gt; records = byAge.getRecords(); System.out.println(records);&#125; 自定义sql（多表关联）多表数据库123456create table product( category int , count int , description varchar(20), userid bigint(100))charset &#x3D;utf8 ProductVO12345678910@Data@NoArgsConstructor@AllArgsConstructorpublic class ProductVO &#123; private Integer category; private Integer count; private String description; private Integer userId; private String userName;&#125; mapper接口12345@Repositorypublic interface UserMapper extends BaseMapper&lt;User&gt; &#123; @Select(\"select p.*,u.name username from product p,user u where u.id=p.userid and u.id=#&#123;id&#125;\") List&lt;ProductVO&gt; productList(@Param(\"id\") Integer id);&#125; 执行 SQL 分析打印p6spy 依赖引入12345&lt;dependency&gt; &lt;groupId&gt;p6spy&lt;/groupId&gt; &lt;artifactId&gt;p6spy&lt;/artifactId&gt; &lt;version&gt;3.9.1&lt;/version&gt;&lt;/dependency&gt; application.yml 配置123456789101112131415161718spring: datasource: driver-class-name: com.p6spy.engine.spy.P6SpyDriver #com.mysql.cj.jdbc.Driver url: jdbc:p6spy:mysql://localhost:3306/db?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC username: root password: rootmybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl map-underscore-to-camel-case: true type-enums-package: com.blb.mybatisplus2.enums global-config: db-config: logic-not-delete-value: 0 logic-delete-value: 1 id-type: auto type-aliases-package: com.ase.mybatis.entity mapper-locations: classpath:/mapper/*.xml spy.properties 配置：123456789101112131415161718192021222324#3.2.1以上使用modulelist=com.baomidou.mybatisplus.extension.p6spy.MybatisPlusLogFactory,com.p6spy.engine.outage.P6OutageFactory#3.2.1以下使用或者不配置#modulelist=com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory# 自定义日志打印logMessageFormat=com.baomidou.mybatisplus.extension.p6spy.P6SpyLogger#日志输出到控制台appender=com.baomidou.mybatisplus.extension.p6spy.StdoutLogger# 使用日志系统记录 sql#appender=com.p6spy.engine.spy.appender.Slf4JLogger# 设置 p6spy driver 代理deregisterdrivers=true# 取消JDBC URL前缀useprefix=true# 配置记录 Log 例外,可去掉的结果集有error,info,batch,debug,statement,commit,rollback,result,resultset.excludecategories=info,debug,result,commit,resultset# 日期格式dateformat=yyyy-MM-dd HH:mm:ss# 实际驱动可多个#driverlist=org.h2.Driver# 是否开启慢SQL记录outagedetection=true# 慢SQL记录标准 2 秒outagedetectioninterval=2 MyBatisPlus 代码生成器【根据数据表自动生成实体类、Mapper、Service、ServiceImpl、Controller】 导入依赖pom.xml 导入 MyBatis Plus Generator 12345678910&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt;&lt;/dependency&gt; Velocity（默认）、Freemarker、Beetl 运行main方法1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Main &#123; public static void main(String[] args) &#123; //创建generator对象 AutoGenerator autoGenerator = new AutoGenerator(); //数据源 DataSourceConfig dataSourceConfig = new DataSourceConfig(); dataSourceConfig.setDbType(DbType.MYSQL); dataSourceConfig.setUrl(\"jdbc:mysql://localhost:3306/db?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC\"); dataSourceConfig.setUsername(\"root\"); dataSourceConfig.setPassword(\"root\"); dataSourceConfig.setDriverName(\"com.mysql.cj.jdbc.Driver\"); autoGenerator.setDataSource(dataSourceConfig); //全局配置 GlobalConfig globalConfig = new GlobalConfig(); //当前项目的绝对路径 globalConfig.setOutputDir(System.getProperty(\"user.dir\")+\"/src/main/java\"); globalConfig.setOpen(false); globalConfig.setAuthor(\"dyk\"); //去掉默认生成接口名字的I globalConfig.setServiceName(\"%sService\"); autoGenerator.setGlobalConfig(globalConfig); //包信息 PackageConfig packageConfig = new PackageConfig(); packageConfig.setParent(\"com.blb.mybatisplus\"); //packageConfig.setModuleName(\"generator\"); packageConfig.setController(\"controller\"); packageConfig.setService(\"service\"); packageConfig.setServiceImpl(\"service.impl\"); packageConfig.setMapper(\"mapper\"); packageConfig.setEntity(\"entity\"); autoGenerator.setPackageInfo(packageConfig); //配置策略 StrategyConfig strategyConfig = new StrategyConfig(); strategyConfig.setEntityLombokModel(true); strategyConfig.setRestControllerStyle(true); //生成部分数据库里面的表对应的实体类 strategyConfig.setInclude(\"user\",\"product\"); strategyConfig.setNaming(NamingStrategy.underline_to_camel); strategyConfig.setColumnNaming(NamingStrategy.underline_to_camel); autoGenerator.setStrategy(strategyConfig); autoGenerator.execute(); &#125;&#125; 完整版123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class Main1 &#123; public static void main(String[] args) &#123; // 代码生成器 AutoGenerator autoGenerator = new AutoGenerator(); // 全局配置 GlobalConfig gc = new GlobalConfig(); //获得当前项目的路径 String projectPath = System.getProperty(\"user.dir\"); //设置生成路径 gc.setOutputDir(projectPath + \"/src/main/java\"); //作者 gc.setAuthor(\"dyk\"); //代码生成后是不是要打开文件所在的文件夹 gc.setOpen(false); //生成实体属性 Swagger2 注解 // gc.setSwagger2(true); //会在mapper.xml生成一个基础的&lt;ResultMap&gt; 映射所有的字段 gc.setBaseResultMap(true); //同文件生成覆盖 gc.setFileOverride(true); //实体类名直接用表名 %s=表名 gc.setEntityName(\"%s\"); //mapper接口名 gc.setMapperName(\"%sMapper\"); //mapper.xml文件名 gc.setXmlName(\"%sMapper\"); //业务逻辑接口名 gc.setServiceName(\"%sService\"); //业务逻辑实现类名 gc.setServiceImplName(\"%sServiceImpl\"); //将全局配置设置到 AutoGenerator autoGenerator.setGlobalConfig(gc); //数据源 DataSourceConfig dsc = new DataSourceConfig(); //设置数据库类型 dsc.setDbType(DbType.MYSQL); //连接的url dsc.setUrl(\"jdbc:mysql://localhost:3306/db3?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC\"); //数据库用户名 dsc.setUsername(\"root\"); //数据库密码 dsc.setPassword(\"123456\"); //数据库驱动 dsc.setDriverName(\"com.mysql.cj.jdbc.Driver\"); //将数据源配置设置到 AutoGenerator autoGenerator.setDataSource(dsc); //包信息 PackageConfig pc = new PackageConfig(); //包名 pc.setParent(\"com.blb\"); //设置模块名// pc.setModuleName(\"generator\"); pc.setController(\"controller\"); pc.setService(\"service\"); pc.setServiceImpl(\"service.impl\"); pc.setMapper(\"mapper\"); pc.setEntity(\"entity\"); autoGenerator.setPackageInfo(pc); //配置策略 StrategyConfig strategyConfig = new StrategyConfig(); //表名的生成策略:下划线转驼峰 strategyConfig.setNaming(NamingStrategy.underline_to_camel); //列名的生成策略：下划线转驼峰 strategyConfig.setColumnNaming(NamingStrategy.underline_to_camel); //支持lombok注解 strategyConfig.setEntityLombokModel(true); //在controller类上是否生成@Restcontroller strategyConfig.setRestControllerStyle(true); //生成部分数据库里面的表对应的实体类，生成的表名 strategyConfig.setInclude(\"user\",\"product\"); //按前缀生成表 //strategyConfig.setLikeTable(\"tbl_\"); //设置表替换前缀 //strategyConfig.setTablePrefix(\"tbl_\"); autoGenerator.setStrategy(strategyConfig); // 自定义配置 InjectionConfig cfg = new InjectionConfig() &#123; @Override public void initMap() &#123; // to do nothing &#125; &#125;; // 模板引擎是 velocity String templatePath = \"/templates/mapper.xml.vm\"; // 自定义输出配置 List&lt;FileOutConfig&gt; focList = new ArrayList&lt;&gt;(); // 自定义配置会被优先输出 focList.add(new FileOutConfig(templatePath) &#123; @Override public String outputFile(TableInfo tableInfo) &#123; // 自定义输出文件名 ， 如果你 Entity 设置了前后缀、此处注意 xml 的名称会跟着发生变化！！ return projectPath + \"/src/main/resources/mapper/\" + pc.getModuleName() + \"/\" + tableInfo.getEntityName() + \"Mapper\" + StringPool.DOT_XML; &#125; &#125;); cfg.setFileOutConfigList(focList); autoGenerator.setCfg(cfg); // 配置模板 TemplateConfig templateConfig = new TemplateConfig(); //让已有的xml生成置空 templateConfig.setXml(null); autoGenerator.setTemplate(templateConfig); //执行生成 autoGenerator.execute(); &#125;&#125;","categories":[{"name":"框架","slug":"框架","permalink":"https://yugd.cn/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://yugd.cn/tags/MyBatis/"}]},{"title":"每日一面--数据库连接池","slug":"面试--数据连接池","date":"2021-08-13T13:00:00.000Z","updated":"2022-05-26T18:16:44.013Z","comments":true,"path":"posts/38677/","link":"","permalink":"https://yugd.cn/posts/38677/","excerpt":"每天一篇面试小知识 本篇着重介绍一下数据库连接池 写在前面 平时在使用 SpringBoot 框架结合 MyBatis 的时候有注意到数据库连接池吗？ 还真的没有过呀，还不是因为平时做的练习项目都是只注重使用而忽略了其更深层次的原理。 哎！拖欠的知识终究是要花时间补回来的，顺便回顾一下吧！","text":"每天一篇面试小知识 本篇着重介绍一下数据库连接池 写在前面 平时在使用 SpringBoot 框架结合 MyBatis 的时候有注意到数据库连接池吗？ 还真的没有过呀，还不是因为平时做的练习项目都是只注重使用而忽略了其更深层次的原理。 哎！拖欠的知识终究是要花时间补回来的，顺便回顾一下吧！ 什么是数据库连接池？官方：数据库连接池（Connection pooling）是程序启动时建立足够的数据库连接，并将这些连接组成一个连接池，由程序动态地对池中的连接进行申请，使用，释放。 个人理解：就像是 Java 中的线程池一样，创建数据库连接是一个很耗时的操作，也容易对数据库造成安全隐患。所以在程序初始化的时候集中创建数据库连接池，负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个。 为什么要使用连接池？ 数据库连接是一种关键的有限的昂贵的资源，在多用户的网页应用程序中体现得尤为突出。 一个数据库连接对象均对应一个物理数据库连接，每次操作都打开一个物理连接，使用完都关闭连接，这样造成系统的 性能低下。 触类旁通的参照 Java 中的线程池，在一个“池”里放了好多半成品的数据库联接对象，由应用程序动态地对池中的连接进行申请、使用和释放。对于多于连接池中连接数的并发请求，应该在请求队列中排队等待。并且应用程序可以根据池中连接的使用率，动态增加或减少池中的连接数。 好处： 连接池技术尽可能多地重用了消耗内存地资源，大大节省了内存，提高了服务器地服务效率，能够支持更多的客户服务。通过使用连接池，将大大提高程序运行效率， 与传统的连接机制区别不使用连接池流程举个荔枝：执行一个 SQL 命令，如果不使用连接池，需要经过哪些流程【MySQL 为例】 不使用数据库连接池的步骤： TCP 建立连接的三次握手 MySQL 认证的三次握手 真正的 SQ L执行 MySQL 的关闭 TCP 的四次握手关闭 优点：实现简单 缺点： 网络 IO 较多 数据库的负载较高 响应时间较长及 QPS 较低 应用频繁的创建连接和关闭连接，导致临时对象较多，GC 频繁 在关闭连接后，会出现大量 TIME_WAIT 的TCP 状态（在2个MSL之后关闭） 使用连接池流程举个荔枝：执行一个 SQL 命令，如果使用连接池，只需要经过哪些流程【MySQL 为例】 使用数据库连接池的步骤： 第一次访问的时候，需要建立连接 之后的访问，均会复用之前创建的连接，直接执行 SQL 语句。 优点： 较少了网络开销 系统的性能会有一个实质的提升 没了麻烦的 TIME_WAIT 状态 连接池解决现状问题的原理 Connection连接对象 操作特点 创建时 连接对象不再由自己创建，而是系统启动的时候已经创建一定数量的连接， 并且放在连接池中 使用时 直接从连接池中去获取一个已经创建好的连接对象即可 关闭时 不是真的关闭连接对象，而是将连接对象再放回到连接池中，供下一个用户使用 数据库连接池的工作原理三部分组成 连接池的建立 连接池中连接的使用管理 连接池的关闭 举个荔枝：使用连接池【MySQL 为例】 系统在启动时初始化连接池； 向连接池请求可用的数据库连接； 如果没有获取到可用的数据库连接，并且连接池中连接的数量小于最大连接数，则按照规定的步长给连接池中添加连接，然后再获取，如果连接池中的数量已经到了最大连接数还没有获取到可用的连接，则等待其他请求释放了连接后再获取； 使用获取到的数据库连接请求数据库； 将数据库连接放回连接池，供其他连接使用； 连接池主要参数使用连接池时，要配置一下参数 最小连接数【是连接池一直保持的数据库连接,所以如果应用程序对数据库连接的使用量不大,将会有大量的数据库连接资源被浪费】 最大连接数【是连接池能申请的最大连接数,如果数据库连接请求超过次数,后面的数据库连接请求将被加入到等待队列中,这会影响以后的数据库操作】 最大空闲时间【如果一个连接对象长时间没有人使用，设置多久回收这个对象，默认是不回收】 获取连接超时时间【如果连接池中没有连接对象，设置用户等待的最长时间是多久，单位是毫秒。如果超过这个时间就抛出异常】 超时重试连接次数 连接池需要注意的点 并发问题 事务处理 连接池的分配与释放 连接池的配置与维护 数据库对比第一、二代连接池 数据库连接池 最新版本 发布时间 C3P0 c3p0-0.9.5.2 on 9 Dec 2015 DBCP 2.2.0 27 December 2017 Druid 0.11.0 Dec 4 2017 HikariCP 2.7.6 2018-01-14 Druid连接池Druid 简介 Druid是阿里巴巴开发的号称为监控而生的数据库连接池，在功能、性能、扩展性方面，都超过其他数据库连接池。Druid已经在阿里巴巴部署了超过600个应用，经过一年多生产环境大规模部署的严苛考验。如：一年一度的双十一活动，每年春运的抢火车票。 Druid 是一个阿里开源的连接池组件 加⼊了日志监控，不需要额外的界面开发 Druid 常用的配置参数 参数 缺省值 说明 url 连接字符串 username 用户名 password 密码 driverClassName 驱动类名，会自动根据URL识别，这一项可以不配置 initialSize 0 初始连接数 maxActive 8 最大连接池数量 minIdle 最小连接池数量 maxWait 最长等待时间，单位毫秒 Druid 连接池运行原理 连接池初始化的时候按照 initialSize 创建多个连接【默认 0 个】 有 DB 操作访问的时候，就从里面取一个 【类似线程池的 task 任务】 如果当前正在使用的连接 = maxActive ,就会进入等待，没有到 maxActive 拿一个空闲连接，没有空闲就创建一个新连接，等待超过 maxWati 则会报错【最大连接池数量为阈值来决定是否创建新的连接或者报错】 使用完毕还回去等待其它人用，不会物理销毁【持续存在】 每一个 connection 在连接池里都有空闲时长的，允许最大空闲时长：minEvictableldleTimeMillis，多久检测一次：timeBetweenEvictionRunsMillis maxActive 如何配置：理论上应该设置成最大并发数 只要连接被前端业务拿到就算不空闲了，这个时候如果说长时间占有连接，连接数是不会崩溃，连接池主动关闭是使用中的连接，属于一个高级功能 123removeAbandoned=“true”removeAbandonedTimeout=“60”logAbandoned=“true” Druid 连接池 SpringBoot 集成导入依赖1234567891011121314151617181920&lt;!-- mysql --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.49&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mybatis-plus --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt;&lt;/dependency&gt; 编写配置文件123456789101112131415161718192021222324252627282930spring: datasource: druid: username: root password: root url: jdbc:mysql://localhost:3306/mybatis-plus?useUnicode=true&amp;characterEncoding=UTF-8 db-type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver initial-size: 5 min-idle: 5 max-active: 20 max-wait: 60000 time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 1 FROM DUAL test-while-idle: true test-on-borrow: false test-on-return: false # 打开PSCache pool-prepared-statements: true #配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入 #如果运行时报错 java.lang.ClassNotFoundException: org.apache.log4j.Priority #则导入 log4j 依赖即可，Maven 地址： https://mvnrepository.com/artifact/log4j/log4j filter: stat,wall,log4j,config #指定每个连接上PSCache的大小 max-pool-prepared-statement-per-connection-size: 20 #合并多个DruidDataSource的监控数据 use-global-data-source-stat: true #通过connectProperties属性来打开mergeSql功能；慢SQL记录 connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 编写配置类Druid数据源监控 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configurationpublic class DruidConfig &#123; @ConfigurationProperties(prefix = \"spring.datasource\") @Bean public DataSource druidDataSource()&#123; return new DruidDataSource(); &#125; //因为Springboot内置了servlet容器，所以没有web.xml，替代方法就是将ServletRegistrationBean注册进去 //加入后台监控 //这里其实就相当于servlet的web.xml @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean&lt;StatViewServlet&gt; bean = new ServletRegistrationBean&lt;&gt;(new StatViewServlet(),\"/druid/*\"); //后台需要有人登录，进行配置 //bean.addUrlMappings(); 这个可以添加映射，我们在构造里已经写了 //设置一些初始化参数 Map&lt;String,String&gt; initParas = new HashMap&lt;String,String&gt;(); initParas.put(\"loginUsername\",\"admin\");//它这个账户密码是固定的 initParas.put(\"loginPassword\",\"123456\"); //允许谁能防伪 initParas.put(\"allow\",\"\");//这个值为空或没有就允许所有人访问，ip白名单 //initParas.put(\"allow\",\"localhost\");//只允许本机访问，多个ip用逗号,隔开 //initParas.put(\"deny\",\"\");//ip黑名单，拒绝谁访问 deny和allow同时存在优先deny initParas.put(\"resetEnable\",\"false\");//禁用HTML页面的Reset按钮 bean.setInitParameters(initParas); return bean; &#125; //再配置一个过滤器，Servlet按上面的方式注册Filter也只能这样 @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); //可以设置也可以获取,设置一个阿里巴巴的过滤器 bean.setFilter(new WebStatFilter()); bean.addUrlPatterns(\"/*\"); //可以过滤和排除哪些东西 Map&lt;String,String&gt; initParams = new HashMap&lt;String,String&gt;(); //把不需要监控的过滤掉,这些不进行统计 initParams.put(\"exclusions\",\"*.js,*.css,/druid/*\"); bean.setInitParameters(initParams); return bean; &#125; 启动项目访问 URL：http://localhost:8080/druid/login.html 就会到Druid的监控登录界面 输入我们配置的登录用户名和密码进行登录即可访问 PSCache PreparedStatement Cache 【准备语句缓存】 就要从 MySQL 的 SQL 执⾏行行过程来讲 名词解释 连接器【进⾏行行数据库连接，⽤用户名密码验证】 查询缓存【key-value， key 是 SQL， value 就是结果集】 123456testOnBorrow: falsetestOnReturn: falsepoolPreparedStatements: falsequery_cache_type : DEMAND //默认的SQL都不不使⽤用查询缓存mysql&gt; select SQL_CACHE * from student where id=1; //声明使⽤用 分析器 词法分析【SQL的关键词进⾏行行识别】 语法分析【对语法进⾏行行分析 “use near”】 优化器器【决定我们SQL使⽤用那个⼈人索引】 执⾏器【会判断你是否对这个表有查询/更更新权限】 存储引擎【获取数据的具体⽂文件地址】","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"druid","slug":"druid","permalink":"https://yugd.cn/tags/druid/"}]},{"title":"实践一下--Log日志","slug":"实践--log日志","date":"2021-08-07T01:00:00.000Z","updated":"2022-05-26T18:18:36.019Z","comments":true,"path":"posts/8859/","link":"","permalink":"https://yugd.cn/posts/8859/","excerpt":"实践是检验真理的唯一标准 本篇着重介绍一下 log 日志 写在前面 我们平时在写代码的过程中通常利用 debug 来进行程序的调试。 但是当程序已经部署上线之后，再出现故障我们不可能利用 debug 来找寻错误具体出在哪里。 这时候如果我们在开发的时候随手打印了日志，会很容易的快速定位到出错代码的位置。","text":"实践是检验真理的唯一标准 本篇着重介绍一下 log 日志 写在前面 我们平时在写代码的过程中通常利用 debug 来进行程序的调试。 但是当程序已经部署上线之后，再出现故障我们不可能利用 debug 来找寻错误具体出在哪里。 这时候如果我们在开发的时候随手打印了日志，会很容易的快速定位到出错代码的位置。 日志框架比较常用的日志框架 slf4j log4j logback log4j2 slf4jslf4j是对所有日志框架制定的一种规范、标准、接口，并不是一个框架的具体的实现，因为接口并不能独立使用，需要和具体的日志框架实现配合使用（如log4j、logback）。 log4jlog4j是apache实现的一个开源日志组件。通过使用log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件、甚至是套接口服务器、NT的事件记录器、UNIX Syslog守护进程等； 我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。 logbacklogback同样是由log4j的作者设计完成的，拥有更好的特性，用来取代log4j的一个日志框架，是slf4j的原生实现，所以logback与slf4j的结合最好。 log4j2Log4j2是log4j 1.x和logback的改进版，采用了一些新技术（无锁异步、等等），使得日志的吞吐量、性能比log4j 1.x提高10倍，并解决了一些死锁的bug，而且配置更加简单灵活。 Slf4jSlf4j 的优势 解耦客户端 Slf4j 只是一种接口，它本身并不关心底层使用什么日志实现方案，所以它支持各种日志实现方案。简单的说，只要我们在类库中使用 Slf4j 打日志，那么底层使用什么日志实现方案是由使用者决定的，依靠的是配置文件和jar库。 提高效率 Slf4j 打印日志使用{}占位符，这样就不会有字符串拼接操作，减少了无用 String 对象的数量，节省了内存，也提高了效率，同时编码更加方便。 log级别Slf4j 有四个级别的log level供选择，从上到下级别由低到高。 debug：对程序调试有用的信息 info：了解程序运行状态有用的信息 warn：可能会导致错误的警告信息 error：程序运行出现错误的信息 Slf4j 的结构图： Slf4j 的应用1、通过创建LoggerFactory实例 首先引入slf4j包： slf4j-simple 是 slf4 j的一种日志系统实现，目前最新版本是1.7.7 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt;&lt;/dependency&gt; 假如后期改变log实现系统，所有调用log4j的代码都需要进行修改，假如一开始都使用slf4j.Logger，后期将无需修改代码，通过修改配置文件即可切换日志系统。 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloController &#123; private static Logger logger = LoggerFactory.getLogger(Log4jApplication.class); //相关逻辑代码&#125; 2、通过 @Slf4j 的方式 在pom文件中添加依赖，引入lombok 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 类添加注解 1234567891011// 通过注解 @Slf4j 的方式@Slf4jpublic class HelloController &#123; @RequestMapping(\"/say/&#123;name&#125;\") public String sayHello(@PathVariable(\"name\") String name) &#123; //LOGGER.info(\"hello,&#123;&#125;\",name); log.info(\"使用注解的方式日志服务：sayHello:&#123;&#125;\" + name); return \"hello \" + name; &#125;&#125; LogbackLogback，一个“可靠、通用、快速而又灵活的Java日志框架”。 logback当前分成三个模块：logback-core，logback- classic和logback-access。 logback-core是其它两个模块的基础模块。logback-classic是log4j的一个改良版本。 此外logback-classic完整实现SLF4J API使你可以很方便地更换成其它日志系统如log4j或JDK Logging。 logback-access访问模块与Servlet容器集成提供通过Http来访问日志的功能。 logback 的应用在resources下创建 logback-spring.xml 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration debug=\"false\"&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name=\"LOG_HOME\" value=\"/home\" /&gt; &lt;!--控制台日志，控制台输出 --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度,%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--文件日志，按照每天生成日志文件 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt; &lt;logger name=\"org.hibernate.type.descriptor.sql.BasicBinder\" level=\"TRACE\" /&gt; &lt;logger name=\"org.hibernate.type.descriptor.sql.BasicExtractor\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.SQL\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.engine.QueryParameters\" level=\"DEBUG\" /&gt; &lt;logger name=\"org.hibernate.engine.query.HQLQueryPlan\" level=\"DEBUG\" /&gt; &lt;!--myibatis log configure--&gt; &lt;logger name=\"com.apache.ibatis\" level=\"TRACE\"/&gt; &lt;logger name=\"java.sql.Connection\" level=\"DEBUG\"/&gt; &lt;logger name=\"java.sql.Statement\" level=\"DEBUG\"/&gt; &lt;logger name=\"java.sql.PreparedStatement\" level=\"DEBUG\"/&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;appender-ref ref=\"FILE\"/&gt; &lt;/root&gt;&lt;/configuration&gt; 详细配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt;&lt;!-- scan:当此属性设置为true时，配置文档如果发生改变，将会被重新加载，默认值为true --&gt;&lt;!-- scanPeriod:设置监测配置文档是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。 当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt;&lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;&lt;configuration scan=\"true\" scanPeriod=\"10 seconds\"&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义后，可以使“$&#123;&#125;”来使用变量。 --&gt; &lt;property name=\"log.path\" value=\"D:/log/\" /&gt; &lt;!--0. 日志格式和颜色渲染 --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\" /&gt; &lt;conversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\" /&gt; &lt;conversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\" /&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"$&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(---)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;&#125;\"/&gt; &lt;!--1. 输出到控制台--&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;Pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/Pattern&gt; &lt;!-- 设置字符集 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--2. 输出到文档--&gt; &lt;!-- 2.1 level为 DEBUG 日志，时间滚动输出 --&gt; &lt;appender name=\"DEBUG_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_debug.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/web-debug-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录debug级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.2 level为 INFO 日志，时间滚动输出 --&gt; &lt;appender name=\"INFO_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_info.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/web-info-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录info级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.3 level为 WARN 日志，时间滚动输出 --&gt; &lt;appender name=\"WARN_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_warn.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/web-warn-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录warn级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.4 level为 ERROR 日志，时间滚动输出 --&gt; &lt;appender name=\"ERROR_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_error.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/web-error-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录ERROR级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- &lt;logger&gt;用来设置某一个包或者具体的某一个类的日志打印级别、 以及指定&lt;appender&gt;。&lt;logger&gt;仅有一个name属性， 一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前logger将会继承上级的级别。 addtivity:是否向上级logger传递打印信息。默认是true。 &lt;logger name=\"org.springframework.web\" level=\"info\"/&gt; &lt;logger name=\"org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor\" level=\"INFO\"/&gt; --&gt; &lt;!-- 使用mybatis的时候，sql语句是debug下才会打印，而这里我们只配置了info，所以想要查看sql语句的话，有以下两种操作： 第一种把&lt;root level=\"info\"&gt;改成&lt;root level=\"DEBUG\"&gt;这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种就是单独给dao下目录配置debug模式，代码如下，这样配置sql语句会打印，其他还是正常info级别： 【logging.level.org.mybatis=debug logging.level.dao=debug】 --&gt; &lt;!-- root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 不能设置为INHERITED或者同义词NULL。默认是DEBUG 可以包含零个或多个元素，标识这个appender将会添加到这个logger。 --&gt; &lt;!-- 4. 最终的策略 --&gt; &lt;!-- 4.1 开发环境:打印控制台--&gt; &lt;springProfile name=\"dev\"&gt; &lt;logger name=\"com.cms\" level=\"info\"/&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"DEBUG_FILE\" /&gt; &lt;appender-ref ref=\"INFO_FILE\" /&gt; &lt;appender-ref ref=\"WARN_FILE\" /&gt; &lt;appender-ref ref=\"ERROR_FILE\" /&gt; &lt;/root&gt; &lt;/springProfile&gt; &lt;!-- 4.2 生产环境:输出到文档--&gt; &lt;springProfile name=\"pro\"&gt; &lt;logger name=\"com.cms\" level=\"warn\"/&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"ERROR_FILE\" /&gt; &lt;appender-ref ref=\"WARN_FILE\" /&gt; &lt;/root&gt; &lt;/springProfile&gt;&lt;/configuration&gt; 注意 不同的 model 只需要修改一下 第10 行路径即可 1&lt;property name=\"log.path\" value=\"D:/log/\" /&gt;","categories":[{"name":"实践篇","slug":"实践篇","permalink":"https://yugd.cn/categories/%E5%AE%9E%E8%B7%B5%E7%AF%87/"}],"tags":[{"name":"log","slug":"log","permalink":"https://yugd.cn/tags/log/"},{"name":"日志","slug":"日志","permalink":"https://yugd.cn/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"实践一下--SpringBoot配置","slug":"实践--SpringBoot配置文件","date":"2021-08-06T13:58:58.000Z","updated":"2022-05-26T18:14:40.573Z","comments":true,"path":"posts/63189/","link":"","permalink":"https://yugd.cn/posts/63189/","excerpt":"实践是检验真理的唯一标准 本篇着重介绍一下 SpringBoot配置 写在前面 首先我们得知道为什么要使用SpringBoot，其优点有哪些？ 比如说： 简化依赖【在 pom 文件中添加相关依赖即可】 简化配置【一个普通的类，只需要 @Bean 注解即可成为一个 Bean 让 Spring 去管理】（√） 简化部署【Spring Boot 内嵌了 tomcat，我们只需要将项目打成 jar 包】 简化监控【可以引入 spring-boot-start-actuator 依赖，直接使用 REST 方式来获取进程的运行期性能参数】","text":"实践是检验真理的唯一标准 本篇着重介绍一下 SpringBoot配置 写在前面 首先我们得知道为什么要使用SpringBoot，其优点有哪些？ 比如说： 简化依赖【在 pom 文件中添加相关依赖即可】 简化配置【一个普通的类，只需要 @Bean 注解即可成为一个 Bean 让 Spring 去管理】（√） 简化部署【Spring Boot 内嵌了 tomcat，我们只需要将项目打成 jar 包】 简化监控【可以引入 spring-boot-start-actuator 依赖，直接使用 REST 方式来获取进程的运行期性能参数】 SpringBoot 默认配置文件 SpringBoot使用默认的全局的配置文件：application.properties/application.yml 配置文件名固定是是application 12345application.properties 语法结构: key=valueapplication.yml 语法结构: key：空格 value 个人更加的偏向于使用 yml 的形式，注意 key 后面的空格 SpringBoot 配置文件的位置springboot启动会扫描以下位置的application.properties/application.yml文件作为其默认配置文件： 优先级1：项目路径下的 config 文件夹配置文件 优先级2：项目路径下配置文件 优先级3：资源路径下的 config 文件夹配置文件 优先级4：资源路径下配置文件（√） 注意 优先级由高到底，高优先级的配置会覆盖低优先级的配置； 当两个配置文件同时存在的时候，相同的配置会优先加载properties配置文件，多余的配置的会互补配置； SpringBoot 多环境切换实际开发中，我们针对不同的应用场景，可能有不同的环境，不同的配置文件 profile就是Spring对不同环境提供不同配置功能的支持，可以通过激活不同的环境版本，实现快速切换环境 涉及两种实现方式： 方式一：多配置文件我们再编写配置文件时，文件名可以是application-{profile}.properties/yml，用来指定多个不同的环境版本； application.yml 【代表主环境】 12345# /src/main/resources/application.yml# 默认使用配置spring: profiles: active: dev application-dev.yml 【代表开发环境配置】 1234# /src/main/resources/application-dev.ymlserver: # 端口号 port: 8001 application-test.yml 【代表测试环境配置】 1234# /src/main/resources/application-test.ymlserver: # 端口号 port: 8002 如果未加指定，它默认使用application.yml主配置文件； 方式二：一个配置文件【yaml的多文档块，不建议】123456789101112131415161718server: port: 8080#选择要激活那个环境块spring: profiles: active: prod ---server: port: 8081spring: profiles: dev #配置环境名称dev---server: port: 8082spring: profiles: prod #配置环境名称prod SpringBoot 加载指定的配置文件通过@configurationProperties注解默认从全局配置文件中获取值 此时配置文件名必须为application才能被spring认出 其实我们可以通过@PropertySource指定加载的配置文件，可以自定义文件名 SpringBoot 配置类注解Spring Boot 推荐使用 java 配置完全代替 XML 配置，java 配置是通过 @Configration 和 @Bean 注解实现的。二者作用如下： @Configration 注解：声明当前类是一个配置类，相当于 Spring 中的一个 XML 文件 @ComponentScan：作用就是根据定义的扫描路径，把符合扫描规则的类装配到spring容器中 @Bean 注解：作用在方法上，声明当前方法的返回值是一个 Bean @Bean 和 @Autowired 做了两件完全不同的事情： @Bean 告诉 Spring：“这是这个类的一个实例，请保留它，并在我请求时将它还给我”。 @Autowired 说：“请给我一个这个类的实例，例如，一个我之前用@Bean注释创建的实例”。 常用注解 @ConditionalOnBean：当容器里有指定Bean的条件下 @ConditionalOnMissingBean：当容器里没有指定 Bean 的情况下 @ConditionalOnMissingClass：当容器里没有指定类的情况下、 @ConditionalOnProperty：指定的属性是否有指定的值 @EnableConfigurationProperties的作用: 使 @ConfigurationProperties 注解的类生效。 @Scope(“prototype”) 表示每次获得 bean 都会生成一个新的对象【多例】 @AutoConfigureAfter 在加载配置的类之后再加载当前类 自定义涉及注解： @EnableConfigurationProperties()【启用配置属性，指定配置类的路径或者具体类】 @ConfigurationProperties()【配置属性，去寻找配置文件】 @Configuration()【配置，声明这是一个配置类】 @Component()【组件，声明这是一个组件】 @Data()【lombok插件，生成 get 、set】 一、引入 SpringBoot properties 内容处理器依赖 12345 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 二、编写配置类 12345678@ConfigurationProperties(prefix = \"mall.thread\")@Component@Datapublic class ThreadPoolConfigProperties &#123; private Integer coreSize; private Integer maxSize; private Integer keepAliveTime;&#125; 三、properties 文件中可以联想到 1234#配置线程池mall.thread.coreSize=20mall.thread.maxSize=200mall.thread.keepAliveTime=10 四、在类中使用 12345678910111213141516@EnableConfigurationProperties(ThreadPoolConfigProperties.class)@Configurationpublic class MyThreadConfig &#123; @Bean public ThreadPoolExecutor threadPoolExecutor(ThreadPoolConfigProperties pool) &#123; return new ThreadPoolExecutor( pool.getCoreSize(), pool.getMaxSize(), pool.getKeepAliveTime(), TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(100000), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy() ); &#125;&#125;","categories":[{"name":"实践篇","slug":"实践篇","permalink":"https://yugd.cn/categories/%E5%AE%9E%E8%B7%B5%E7%AF%87/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yugd.cn/tags/SpringBoot/"}]},{"title":"每日一面--MySQL 索引","slug":"面试--MySQL索引","date":"2021-08-05T13:58:58.000Z","updated":"2022-05-26T18:17:23.043Z","comments":true,"path":"posts/41767/","link":"","permalink":"https://yugd.cn/posts/41767/","excerpt":"每天一篇面试小知识 本篇着重介绍一下基于 MySQL 索引 写在前面 面试的时候经常会问到如何在大量数据查询的时候提示效率，能想到的首先一定是建立索引，那具体说说？ 索引是对数据库表中一列或多列的值进行排序的一种结构。 MySQL 索引的建立对于 MySQL 的高效运行是很重要的，索引可以大大提高MySQL的检索速度。","text":"每天一篇面试小知识 本篇着重介绍一下基于 MySQL 索引 写在前面 面试的时候经常会问到如何在大量数据查询的时候提示效率，能想到的首先一定是建立索引，那具体说说？ 索引是对数据库表中一列或多列的值进行排序的一种结构。 MySQL 索引的建立对于 MySQL 的高效运行是很重要的，索引可以大大提高MySQL的检索速度。 MySQL 索引介绍索引是一个单独的、存储在磁盘上的数据库结构，它们包含着对数据表里所有记录的引用指针。使用索引用于快速找出在某个或多个列中有一特定值的行，所有 MySQL 列类型都可以被索引，对相关列使用索引是提高查询操作速度的最佳途径。 创建索引时，需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)，而不是在select的字段中，实际上，索引也是一张“表”，该表保存了主键与索引字段，并指向实体表的记录，虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件，建立索引会占用磁盘空间的索引文件。 说白了索引就是用来提高速度的，但是就需要维护索引造成资源的浪费，所以合理的创建索引是必要的。 MySQL 索引的优缺点优点 索引大大减小了服务器需要扫描的数据量，从而大大加快数据的检索速度，这也是创建索引的最主要的原因。 索引可以帮助服务器避免排序和创建临时表 索引可以将随机IO变成顺序IO 索引对于 InnoDB（对索引支持行级锁）非常重要，因为它可以让查询锁更少的元组，提高了表访问并发性 关于 InnoDB、索引和锁：InnoDB 在二级索引上使用共享锁（读锁），但访问主键索引需要排他锁（写锁） 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 缺点 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加 索引需要占物理空间，除了数据表占用数据空间之外，每一个索引还要占用一定的物理空间，如果需要建立聚簇索引，那么需要占用 的空间会更大 对表中的数据进行增、删、改的时候，索引也要动态的维护，这就降低了整数的维护速度 如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。 对于非常小的表，大部分情况下简单的全表扫描更高效； MySQL 索引存储结构索引结构 B-Tree索引B树的特征： 关键字集合分布在整颗树中； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束； 其搜索性能等价于在关键字全集内做一次二分查找； 自动层次控制； B+Tree索引B+树的特征： 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 不可能在非叶子结点命中； 非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 每一个叶子节点都包含指向下一个叶子节点的指针，从而方便叶子节点的范围遍历。 更适合文件索引系统； B-Tree索引InnoDB 使用的是B+Tree。 B+Tree：每一个叶子节点都包含指向下一个叶子节点的指针，从而方便叶子节点的范围遍历。 B-Tree 通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同，很适合查找范围数据。 B-Tree 可以对&lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN，以及不以通配符开始的 LIKE 使用索引。 HASH哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。 Hash 索引仅仅能满足”=”,“IN”和”&lt;=&gt;”查询，不能使用范围查询。也不支持任何范围查询，例如WHERE price &gt; 100。 由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和 Hash 运算前完全一样。 存储引擎索引是占据物理空间的，在不同的存储引擎中，索引存在的文件也不同。存储引擎是基于表的。 存储引擎为MyISAM： *.frm：与表相关的元数据信息都存放在 frm 文件，包括表结构的定义信息等 *.MYD：MyISAM DATA，用于存储 MyISAM 表的数据 *.MYI：MyISAM INDEX，用于存储 MyISAM 表的索引相关信息 存储引擎为InnoDB： *.frm：与表相关的元数据信息都存放在 frm 文件，包括表结构的定义信息等 *.ibd：InnoDB DATA，表数据和索引的文件。该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据 MySQL 索引分类MySQL 的索引有两种分类方式：逻辑分类和物理分类。 逻辑分类按功能划分 主键索引：一张表只能有一个主键索引，不允许重复、不允许为 NULL； 唯一索引：数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。 普通索引：一张表可以创建多个普通索引，一个普通索引可以包含多个字段，允许数据重复，允许 NULL 值插入； 全文索引：它查找的是文本中的关键词，主要用于全文检索。（篇幅较长，下文有独立主题说明） 按列数划分 单例索引：一个索引只包含一个列，一个表可以有多个单例索引。 组合索引：一个组合索引包含两个或两个以上的列。查询的时候遵循 mysql 组合索引的 “最左前缀”原则，即使用 where 时条件要按照建立索引的时候字段的排列方式放置索引才会生效。 物理分类聚簇索引和非聚簇索引（辅助索引或二级索引） 聚簇是为了提高某个属性(或属性组)的查询速度，把这个或这些属性(称为聚簇码)上具有相同值的元组集中存放在连续的物理块。 聚簇索引（clustered index）不是单独的一种索引类型，而是一种数据存储方式。这种存储方式是依靠B+树来实现的，根据表的主键构造一棵B+树且B+树叶子节点存放的都是表的行记录数据时，方可称该主键索引为聚簇索引。聚簇索引也可理解为将数据存储与索引放到了一块，找到索引也就找到了数据。 非聚簇索引：数据和索引是分开的，B+树叶子节点存放的不是数据表的行记录。 虽然 InnoDB 和 MyISAM 存储引擎都默认使用 B+ 树结构存储索引，但是只有 InnoDB 的主键索引才是聚簇索引，InnoDB 中的辅助索引以及 MyISAM 使用的都是非聚簇索引。每张表最多只能拥有一个聚簇索引。 聚簇索引优缺点优点： 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快 聚簇索引对于主键的排序查找和范围查找速度非常快 缺点： 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键（主键列不要选没有意义的自增列，选经常查询的条件列才好，不然无法体现其主键索引性能） 更新主键的代价很高，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。 InnoDB 和 MyISAM 索引实现InnoDB 索引实现聚簇索引（主键索引） InnoDB使用B+TREE存储数据，除了主键索引为聚簇索引，其它索引均为非聚簇索引。 一个表中只能存在一个聚簇索引（主键索引），但可以存在多个非聚簇索引。 InnoDB表的索引和数据是存储在一起的，.idb表数据和索引的文件 叶子节点包含了完整的数据记录，这就是聚簇索引。因为InnoDB的数据文件（.idb）按主键聚集，所以InnoDB必须有主键（MyISAM可以没有），如果没有显示指定主键，则选取首个为唯一且非空的列作为主键索引，如果还没具备，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 非聚簇索引（辅助索引或二级索引）在聚簇索引之外创建的索引（不是根据主键创建的）称之为辅助索引，辅助索引访问数据总是需要二次查找。辅助索引叶子节点存储的不再是行数据记录，而是主键值。首先通过辅助索引找到主键值，然后到主键索引树中通过主键值找到数据行。 拓展：InnoDB 索引优化 InnoDB 中主键不宜定义太大，因为辅助索引也会包含主键列，如果主键定义的比较大，其他索引也将很大。如果想在表上定义 、很多索引，则争取尽量把主键定义得小一些。InnoDB 不会压缩索引。 InnoDB 中尽量不使用非单调字段作主键（不使用多列），因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 MyISAM 索引实现 MyISAM也使用B+Tree作为索引结构，但具体实现方式却与InnoDB截然不同。MyISAM使用的都是非聚簇索引。 MyISAM表的索引和数据是分开存储的，.MYD表数据文件 .MYI表索引文件 MyISAM 主键索引叶子节点的存放的是数据记录的地址。也就是说索引和行数据记录是没有保存在一起的，所以MyISAM的主键索引是非聚簇索引。 MyISAM 辅助索引在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。 MyISAM辅助索引也是非聚簇索引。 InnoDB 和 MyISAM 的索引检索过程InnoDB辅助索引的访问需要两次索引查找，第一次从辅助索引树找到主键值，第二次根据主键值到主键索引树中找到对应的行数据。 MyISM使用的是非聚簇索引，表数据存储在独立的地方，这两棵（主键和辅助键）B+树的叶子节点都使用一个地址指向真正的表数据。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。 聚簇索引和非聚簇索引的区别 聚簇索引的叶子节点存放的是数据行（主键值也是行内数据），支持覆盖索引；而非聚簇索引的叶子节点存放的是主键值或指向数据行的指针。 由于叶子节点(数据页)只能按照一棵B+树排序，故一张表只能有一个聚簇索引。辅助索引的存在不影响聚簇索引中数据的组织，所以一张表可以有多个辅助索引。 MySQL 索引失效的几种情况1、前导模糊查询不能利用索引(like ‘%XX’或者like ‘%XX%’) 2、如果是组合索引的话，如果不按照索引的顺序进行查找，比如直接使用第三个位置上的索引而忽略第一二个位置上的索引时，则会进行全表查询 3、条件中有or 4、索引无法存储null值，所以where的判断条件如果对字段进行了null值判断，将导致数据库放弃索引而进行全表查询 5、应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 6、in 和 not in 也要慎用，否则会导致全表扫描 7、应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描 8、应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"MySQL","slug":"MySQL","permalink":"https://yugd.cn/tags/MySQL/"}]},{"title":"每日一面--Thread Pool","slug":"面试--线程池","date":"2021-07-27T13:58:58.000Z","updated":"2022-05-26T18:16:51.699Z","comments":true,"path":"posts/5574/","link":"","permalink":"https://yugd.cn/posts/5574/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Thread Pool 写在前面 什么是线程池？ 线程池是用来放置线程的池子。嗯，大概是这么回事吧！","text":"每天一篇面试小知识 本篇着重介绍一下 Thread Pool 写在前面 什么是线程池？ 线程池是用来放置线程的池子。嗯，大概是这么回事吧！ 关于线程池线程池（ThreadPool）是一种基于池化思想管理和使用线程的机制。它是将多个线程预先存储在一个“池子”内，当有任务出现时可以避免重新创建和销毁线程所带来性能开销，只需要从“池子”内取出相应的线程执行对应的任务即可。 里巴巴在其《Java开发手册》中也强制规定：线程资源必须通过线程池提供，不允许在应用中自行显式创建线程 线程池的好处 降低资源消耗【通过重复利用已创建的线程去降低线程的创建和销毁】 提高响应速度【当任务达到时，任务可以不需要等到线程创建就能立即执行，重复利用线程】 线程池的作用 线程池是为突然大量爆发的线程设计的，通过有限的几个固定线程为大量的操作服务，减少了创建和销毁线程所需的时间，从而提高效率。 如果一个线程的时间非常长，就没必要使用线程池了，况且我们还不能控制线程池中线程的开始、挂起、和中止。 线程池的使用线程池的创建方法总共有 7 种，但总体来说可分为 2 类： 一类是通过 ThreadPoolExecutor 创建的线程池； 另一个类是通过 Executors 创建的线程池。 线程池的创建方式总共包含以下 7 种（其中 6 种是通过 Executors 创建的，1 种是通过 ThreadPoolExecutor 创建的）： Executors.newFixedThreadPool：创建一个固定大小的线程池，可控制并发的线程数，超出的线程会在队列中等待； Executors.newCachedThreadPool：创建一个可缓存的线程池，若线程数超过处理所需，缓存一段时间后会回收，若线程数不够，则新建线程； Executors.newSingleThreadExecutor：创建单个线程数的线程池，它可以保证先进先出的执行顺序； Executors.newScheduledThreadPool：创建一个可以执行延迟任务的线程池； Executors.newSingleThreadScheduledExecutor：创建一个单线程的可以执行延迟任务的线程池； Executors.newWorkStealingPool：创建一个抢占式执行的线程池（任务执行顺序不确定）【JDK 1.8 添加】。 ThreadPoolExecutor：最原始的创建线程池的方式，它包含了 7 个参数可供设置，重点介绍。 线程池内部原理 线程池工作流程1、当execute方法提交一个任务时，如果线程池中线程数小于corePoolSize,那么不管线程池中是否有空闲的线程，都会创建一个新的线程来执行任务。 2、当execute方法提交一个任务时，线程池中的线程数已经达到了corePoolSize,且此时没有空闲的线程，那么则会将任务存储到workQueue中。 3、如果execute提交任务时线程池中的线程数已经到达了corePoolSize,并且workQueue已满，那么则会创建新的线程来执行任务，但总线程数应该小于maximumPoolSize。 4、如果线程池中的线程执行完了当前的任务，则会尝试从workQueue中取出第一个任务来执行。如果workQueue为空则会阻塞线程。 5、如果execute提交任务时，线程池中的线程数达到了maximumPoolSize，且workQueue已满，此时会执行拒绝策略来拒绝接受任务。 6、如果线程池中的线程数超过了corePoolSize，那么空闲时间超过keepAliveTime的线程会被销毁，但程池中线程个数会保持为corePoolSize。 7、如果线程池存在空闲的线程，并且设置了allowCoreThreadTimeOut为true。那么空闲时间超过keepAliveTime的线程都会被销毁。 线程池七个参数分别为： corePoolSize【核心线程数】 线程池维护的最小线程数量，核心线程创建后不会被回收。 maximumPoolSize【最大线程数】 线程池允许创建的最大线程数量。 keepAliveTime【空闲线程存活时间】 当一个可被回收的线程的空闲时间大于keepAliveTime，就会被回收。 可被回收的线程： 设置 allowCoreThreadTimeout=true 的核心线程。 大于核心线程数的线程（非核心线程）。 unit【时间单位】 keepAliveTime的时间单位，常用【 TimeUnit.MILLISECONDS 毫秒 】 workQueue【工作队列】 存放待执行任务的队列。核心线程数 &lt; 提交的任务数 &lt; 最大线程数 它仅仅用来存放被execute()方法提交的 Runnable 任务。 threadFactory【线程工厂】 创建线程的工厂，可以设定线程名、线程编号。 handler【拒绝策略】 当线程池线程数已满，并且工作队列达到限制。需要实现 RejectedExecutionHandler 接口。 线程池的创建12345678910111213141516public static void myThreadPoolExecutor() &#123; // 创建线程池 ThreadPoolExecutor threadPool = new ThreadPoolExecutor(5, 10, 100, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(10)); // 执行任务 for (int i = 0; i &lt; 10; i++) &#123; final int index = i; threadPool.execute(() -&gt; &#123; System.out.println(index + \" 被执行,线程名:\" + Thread.currentThread().getName()); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125;&#125;","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"java","slug":"java","permalink":"https://yugd.cn/tags/java/"}]},{"title":"每日一面--MyBatis","slug":"面试--MyBatis","date":"2021-07-23T00:58:58.000Z","updated":"2022-05-26T18:17:17.003Z","comments":true,"path":"posts/56080/","link":"","permalink":"https://yugd.cn/posts/56080/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 MyBatis 写在前面 用久了 MyBatis 的逆向工程，原生的写法有点生疏了，趁着想起来赶紧复习一下！","text":"每天一篇面试小知识 本篇着重介绍一下 MyBatis 写在前面 用久了 MyBatis 的逆向工程，原生的写法有点生疏了，趁着想起来赶紧复习一下！ 关于 MyBatis什么是 MyBatis？Mybatis是一个半自动化的持久层框架，一般我们都分为三层，控制层，业务层，持久层，所谓的持久层就是专门负责写入数据库的层次。 MyBatis 为什么说他是半自动化？Hibernate 和 JPA 我们可以称为全自动化，所谓的全自动化就是他给我们直接省去了大量的 jdbc 代码，就连sql 语句我们都不用写，所以我们称他为全自动化，而Mybatis之所以称为半自动化就是虽然帮我省去了 jdbc 的一些重复代码，但是 sql 语句仍然需要我们自己写。 MyBatis 的优点是什么？MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架； MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集； MyBatis可以使用简单的XML或注解用于配置和原始映射，将接口和 Java 的 POJO（Plain Old Java Objects，普通的Java对象）映射成数据库中的记录； 并且mybatis还给我们提供了很多第三方插件（分页插件 / 逆向工程）； MyBatis有哪些缺点？ 编写 SQL 语句时工作量很大，尤其是字段多、关联表多时，更是如此。 SQL 语句依赖于数据库，导致数据库移植性差，不能更换数据库。 框架还是比较简陋，功能尚有缺失，虽然简化了数据绑定代码，但是整个底层数据库查询实际还是要自己写的，工作量也比较大，而且不太容易适应快速数据库修改。 二级缓存机制不佳。 如何选择？面对这些持久化框架我们应该如何来进行选择呢？ 选型上都会拿 MyBatis 和 JPA 两个持久层框架一起使用，JPA 用来简单查询和新增修改是非常方便的，并且支持一对多关系。然后复杂的查询语句用 MyBatis 来完成。、 MyBatis 常用标签和注解了解一下MyBatis的常用标签有很多，比如 &lt;sql id=&quot;&quot;&gt;：预定义可以复用的sql语句 &lt;include refid=&quot;&quot;&gt;：根据id引用定义的sql语句 &lt;trim&gt;：空白补全，配合&lt;if&gt;标签使用 &lt;if test=&quot;&quot;&gt;：条件判断，该语句返回的true，则该标签内的语句就生效 &lt;bind name=&quot;&quot; value=&quot;&quot;&gt;：创建一个变量，并且可以绑定到上下文 前言1234&lt;resultMap id=\"BaseResultMap\" type=\"com.entity.User\" &gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"INTEGER\" /&gt; &lt;result column=\"name\" property=\"name\" jdbcType=\"VARCHAR\" /&gt;&lt;/resultMap&gt; 顶级标签1、sql作用：【可被其他语句引用的可重用语句块】 1234567&lt;sql id=\"valid\"&gt; where id = 1 &lt;/sql&gt; &lt;!-- 引用 sql --&gt;&lt;select id = 'queryUser' resultMap=\"BaseResultMap\"&gt; select * from user &lt;include refid = 'valid'&gt;&lt;/include&gt;&lt;/select&gt; 2、insert作用：【映射插入语句】 1234&lt;insert id=\"insert\" parameterType=\"com.entity.User\" &gt; insert into user (id, name) values (#&#123;id,jdbcType=INTEGER&#125;, #&#123;name,jdbcType=VARCHAR&#125;)&lt;/insert&gt; 3、update作用：【映射更新语句】 123456&lt;update id=\"updateUser\"&gt; update User set name = #&#123;name&#125;, sex= #&#123;sex&#125; where id = #&#123;id&#125;&lt;/update&gt; 4、delete作用：【映射删除语句】 123&lt;delete id=\"deleteUser\"&gt; delete from User where id = #&#123;id&#125;&lt;/delete&gt; 动态sql标签常用标签：&lt; if &gt;、&lt; where &gt;、&lt; trim &gt;、&lt; foreach &gt; 1、if作用：【where 语句的条件动态拼接】 1234567&lt;select id=\"findUserByName\" resultType=\"User\"&gt; SELECT * FROM User WHERE valid = 1 &lt;if test=\"name!= null\"&gt; AND name like #&#123;name&#125; &lt;/if&gt;&lt;/select&gt; 2、choose (when, otherwise)作用：【多条件分支，相当于Java中的switch语句】 1234567891011121314&lt;select id=\"findUser\" resultType=\"User\"&gt; SELECT * FROM User WHERE age = 26 &lt;choose&gt; &lt;when test=\"name!= null\"&gt; AND name like #&#123;name&#125; &lt;/when&gt; &lt;when test=\"sex!= null \"&gt; AND sex like #&#123;sex&#125; &lt;/when&gt; &lt;otherwise&gt; AND valid = 1 &lt;/otherwise&gt; &lt;/choose&gt;&lt;/select&gt; choose 有点像 Java 中的 switch 语句。choose执行过程中按顺序判断 when 中的条件出否成立，如果有一个成立，则 choose 结束。当 choose 中所有 when 的条件都不满则时，则执行 otherwise 中的 sql。 3、trim (where, set)作用：【用于添加 SQL 语句的前缀或者后缀】 12345678&lt;trim prefix=\"WHERE\" prefixOverrides=\"AND | OR \"&gt; ...&lt;/trim&gt; &lt;!-- set 元素会动态前置 SET 关键字，同时也会删掉无关的逗号 --&gt;&lt;trim prefix=\"SET\" suffixOverrides=\",\"&gt; ...&lt;/trim&gt; 所以可利用 &lt; trim &gt; 来代替 &lt; where &gt; 的功能 prefix：指定sql语句拼接的前缀 subfix：指定sql语句拼接的后缀 prefixOverrides：指定sql语句前面要去除的关键字或字符，如AND 逗号 括号等 suffixOverrides：指定sql语句后面要去除的关键字或字符 4、foreach作用：【用于在 SQL 语句中迭代一个集合，可用在构建 in 条件中】 12345678&lt;select id=\"selectUser\" resultType=\"User\"&gt; SELECT * FROM User WHERE ID in &lt;foreach item=\"item\" index=\"index\" collection=\"list\" open=\"(\" separator=\",\" close=\")\"&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/select&gt; collection=”要遍历的集合” item = “可以在元素体内使用的集合项” index = “索引” open = “开始字符串” separator = “分隔符” close = “结束字符串” 5、bind作用：【标签表示在表达式以外创建一个变量，并将其绑定到当前的上下文】 12345&lt;select id=\"selectUser\" resultType=\"user\"&gt; &lt;bind name=\"pattern\" value=\"'%' + _parameter.getTitle() + '%'\" /&gt; SELECT * FROM User WHERE name LIKE #&#123;pattern&#125;&lt;/select&gt; MyBatis 使用1、MyBatis 中的 resultType 和 resultMapresultType 用于返回值只有一个字段的类型，resultMap 用于返回值有多个字段的类型。至于结果是 List 还是一个，则在 Mapper 中定义返回值是List还是单个。 使用 resultType： 123&lt;select id=\"count\" resultType=\"java.lang.Integer\"&gt; SELECT count(*) FROM USER &lt;/select&gt; 使用 resultMap： 12345678910&lt;resultMap type=\"com.entity.Blog\" id=\"BlogResult\"&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"title\" property=\"title\"/&gt; &lt;result column=\"content\" property=\"content\"/&gt; &lt;result column=\"owner\" property=\"owner\"/&gt; &lt;/resultMap&gt; &lt;select id=\"selectBlog\" parameterType=\"int\" resultMap=\"BlogResult\"&gt; select * from t_blog where id = #&#123;id&#125; &lt;/select&gt; 2、xml中的timestamp比较转义字符表 转义 符号 &amp;lt; &lt; &amp;gt; &gt; &amp;amp; &amp; &amp;apos; ’ &amp;quot; “ 3、MyBatis 批量插入123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.mapper.UserMapper\"&gt; &lt;insert id=\"insertForeach\" parameterType=\"java.util.List\" useGeneratedKeys=\"false\"&gt; insert into user ( id,name ) values &lt;foreach collection=\"list\" item=\"item\" index=\"index\" separator=\",\"&gt; ( #&#123;item.id&#125;, #&#123;item.name&#125; ) &lt;/foreach&gt; &lt;/insert&gt; &lt;/mapper&gt; 4、MyBatis 传递多个参数方法一:使用map接口传递参数map是一个键值对应的集合，使用者要通过阅读它的键，才能明了其作用；其次，使用map不能限定其传递的数据类型，因此业务性质不强，可读性差。 1public List&lt;Role&gt; findRolesByMap(Map&lt;String, Object&gt; parameterMap); 123&lt;select id=\"findRolesByMap\" parameterType=\"map\" resultType=\"role\"&gt; select id, role_name as roleName, note from t_role where role_name like concat('%', #&#123;roleName&#125;, '%') and note like concat('%', #&#123;note&#125;, '%')&lt;/select&gt; 方法二:使用注解传递多个参数注解 @Param 可以通过它去定义映射器的参数名称 1public List&lt;Role&gt; findRolesByAnnotation(@Param(\"roleName\") String rolename, @Param(\"note\") String note); 123&lt;select id=\"findRolesByAnnotation\" resultType=\"role\"&gt; select id, role_name as roleName, note from t_role where role_name like concat('%', #&#123;roleName&#125;, '%') and note like concat('%', #&#123;note&#125;, '%')&lt;/select&gt; 方法三:通过Java Bean传递多个参数1public List&lt;Role&gt; findRolesByBean(RoleParams roleParam); 123&lt;select id=\"findRolesByBean\" parameterType=\"com.entity.RoleParams\" resultType=\"role\"&gt; select id, role_name as roleName, note from t_role where role_name like concat('%', #&#123;roleName&#125;, '%') and note like concat('%', #&#123;note&#125;, '%')&lt;/select&gt; 方法四:混合使用 不指定 parameterType ，需要指定具体的属性。 1public List&lt;Role&gt; findByMix(@Param(\"params\") RoleParams roleParams, @Param(\"page\") PageParam PageParam); 1234&lt;select id=\"findByMix\" resultType=\"role\"&gt; select id, role_name as roleName, note from t_role where role_name like concat('%', #&#123;params.roleName&#125;, '%') and note like concat('%', #&#123;params.note&#125;, '%') limit #&#123;page.start&#125;, #&#123;page.limit&#125;&lt;/select&gt; 当 n≤5 时，使用 @Param 注解传递多个参数； 当 n＞5 时，建议使用 Java Bean 方式； 5、数据库字段名和实体类属性名不一致的问题（驼峰匹配）场景查询数据的时候，查不到 userName 的信息，原因：数据库的字段名是 user_name POJO中的属性名字是userName两端不一致，造成mybatis无法填充对应的字段信息。修改方法：在sql语句中使用别名。 解决方案一开启驼峰匹配：相当于去掉数据库名字中的下划线，然后在与java中的属性名进行对应。 数据库中的 user_name 和 java 属性中的 userName 是一样的。 1mybatis.configuration.map-underscore-to-camel-case=true 解决方案二resultType 类指定返回值的类型，这样 Mybatis 会帮我们自动映射属性，即只有当类的属性名和字段名相同时，才存在映射关系。 123&lt;select id=\"getUserList\" resultType=\"com.entity.User\"&gt; select * from user;&lt;/select&gt; 如果我们属性名和字段名不同那么我们就需要用 resultMap 来重新映射。 12345678&lt;resultMap id=\"UserMapper\" type=\"com.ariverh.pojo.User\"&gt; &lt;result property=\"id\" column=\"id\"/&gt; &lt;result property=\"userName\" column=\"name\"/&gt;&lt;/resultMap&gt;&lt;select id=\"getUserList\" resultMap=\"UserMapper\"&gt; select id,name as userName from user;&lt;/select&gt; MyBatis缓存机制了解一下缓存机制减轻数据库压力，提高数据库性能 mybatis 的缓存分为两级：一级缓存、二级缓存 namespace 指定的是对应的 mapper 接口 一级缓存：一级缓存为 sqlsesson 缓存，缓存的数据只在 SqlSession 内有效。在操作数据库的时候需要先创建 SqlSession 会话对象，在对象中有一个 HashMap 用于存储缓存数据，此 HashMap 是当前会话对象私有的，别的 SqlSession 会话对象无法访问。 具体流程第一次执行 select 完毕会将查到的数据写入 SqlSession 内的 HashMap 中缓存起来 第二次执行 select 会从缓存中查数据，如果 select 同传参数一样，那么就能从缓存中返回数据，不用去数据库了，从而提高了效率。 注意1、如果 SqlSession 执行了 DML 操作（insert、update、delete），并 commit 了，那么 mybatis 就会清空当前 SqlSession 缓存中的所有缓存数据，这样可以保证缓存中的存的数据永远和数据库中一致，避免出现差异 2、当一个 SqlSession 结束后那么他里面的一级缓存也就不存在了， mybatis 默认是开启一级缓存，不需要配置 3、 mybatis 的缓存是基于 [namespace:sql语句:参数] 来进行缓存的，意思就是， SqlSession 的 HashMap 存储缓存数据时，是使用 [namespace:sql:参数] 作为 key ，查询返回的语句作为 value 保存的 4、一级缓存只在数据库会话内部共享。 二级缓存：前言在上文中提到的一级缓存中，其最大的共享范围就是一个 SqlSession 内部，如果多个 SqlSession 之间需要共享缓存，则需要使用到二级缓存。 具体流程二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。 当开启缓存后，数据的查询执行的流程就是 二级缓存 -&gt; 一级缓存 -&gt; 数据库。 总结 MyBatis的二级缓存相对于一级缓存来说，实现了SqlSession之间缓存数据的共享，同时粒度更加的细，能够到namespace级别，通过Cache接口实现类不同的组合，对Cache的可控性也更强。 MyBatis在多表查询时，极大可能会出现脏数据，有设计上的缺陷，安全使用二级缓存的条件比较苛刻。 在分布式环境下，由于默认的MyBatis Cache实现都是基于本地的，分布式环境下必然会出现读取到脏数据，需要使用集中式缓存将MyBatis的Cache接口实现，有一定的开发成本，直接使用Redis、Memcached等分布式缓存可能成本更低，安全性也更高。 MyBatis 面试一下MyBatis 中#{}和${}区别#{} 是预编译处理，像传进来的数据会加个” “（#将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号） ${} 就是字符串替换。直接替换掉占位符。$方式一般用于传入数据库对象。 所以为了防止 SQL 注入，能用 #{} 的不要去用 ${} 如果非要用 ${} 的话，那要注意防止 SQL 注入问题，可以手动判定传入的变量，进行过滤，一般 SQL 注入会输入很长的一条 SQL 语句","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://yugd.cn/tags/MyBatis/"}]},{"title":"每日一面--CurrentHashMap","slug":"面试--currentHashMap","date":"2021-07-22T02:58:58.000Z","updated":"2022-05-26T18:16:53.702Z","comments":true,"path":"posts/55120/","link":"","permalink":"https://yugd.cn/posts/55120/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 CurrentHashMap 写在前面 使用 HashMap 如何保证线程安全？ 答：1、使用锁（Synchronize） ​ 2、使用 CurrentHashMap 详细的说一下 CurrentHashMap 吧 好嘞~","text":"每天一篇面试小知识 本篇着重介绍一下 CurrentHashMap 写在前面 使用 HashMap 如何保证线程安全？ 答：1、使用锁（Synchronize） ​ 2、使用 CurrentHashMap 详细的说一下 CurrentHashMap 吧 好嘞~ 哈希表1.介绍哈希表就是一种以 键-值(key-indexed) 存储数据的结构，我们只要输入待查找的值即key，即可查找到其对应的值。 哈希的思路很简单，如果所有的键都是整数，那么就可以使用一个简单的无序数组来实现：将键作为索引，值即为其对应的值，这样就可以快速访问任意键的值。这是对于简单的键的情况，我们将其扩展到可以处理更加复杂的类型的键。 2.链式哈希表链式哈希表从根本上说是由一组链表构成。每个链表都可以看做是一个“桶”，我们将所有的元素通过散列的方式放到具体的不同的桶中。 插入元素时，首先将其键传入一个哈希函数（该过程称为哈希键），函数通过散列的方式告知元素属于哪个“桶”，然后在相应的链表头插入元素。查找或删除元素时，用同们的方式先找到元素的“桶”，然后遍历相应的链表，直到发现我们想要的元素。因为每个“桶”都是一个链表，所以链式哈希表并不限制包含元素的个数。然而，如果表变得太大，它的性能将会降低。 哈希表的链表式结构 3.应用场景 缓存技术（比如redis、memcached）的核心其实就是在内存中维护一张巨大的哈希表，还有HashMap、CurrentHashMap… … ConcurrentHashMap与HashMap等的区别1.HashMapHashMap 是线程不安全的，在多线程环境下，使用 HasHmap 进行 put 操作会引起死循环，导致 CPU 利用率接近 100%，所以在并发情况下不能使用 HashMap。 2.HashTableHashTable和HashMap的实现原理几乎一样，差别无非是 HashTable 不允许 key 和 value 为 null HashTable 是线程安全的 但是HashTable线程安全的策略实现代价却太大了，简单粗暴，get/put 所有相关操作都是s ynchronized 的，这相当于给整个哈希表加了一把大锁。 多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。 3.ConcurrentHashMapConcurrentHashMap 是为了解决 HashMap 在并发环境下不安全而诞生的。其大量的利用了 volatile，final，CAS 等 lock-free 技术来减少锁竞争对于性能的影响。 ConcurrentHashMap 避免了对全局加锁改成了局部加锁操作 JDK1.7 版本的 CurrentHashMap 的实现原理在JDK1.7中ConcurrentHashMap采用了数组+Segment+分段锁的方式实现。 1.Segment(分段锁)ConcurrentHashMap 中的分段锁称为 Segment，它即类似于 HashMap 的结构，即内部拥有一个 Entry 数组，数组中的每个元素又是一个链表,同时又是一个 ReentrantLock（Segment继承了ReentrantLock）。 2.内部结构ConcurrentHashMap 使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。如下图是ConcurrentHashMap的内部结构图： Segment 默认是16，按理说最多同时支持16个线程并发读写，但是是操作不同的 Segment，初始化时也可以指定 Segment 数量，每一个 Segment 都会有一把锁，保证线程安全。 该结构的优劣势坏处：是这一种结构的带来的副作用是 Hash 的过程要比普通的 HashMap 要长。 好处：是写操作的时候可以只对元素所在的 Segment 进行加锁即可，不会影响到其他的 Segment，在最理想的情况下，ConcurrentHashMap 可以最高同时支持 Segment 数量大小的写操作(刚好这些写操作都非常平均地分布在所有的Segment上)。 JDK1.8 版本的 CurrentHashMap 的实现原理1.NodeNode：保存 key，value 及 key 的 hash 值的数据结构。其中 value 和 next 都用 volatile 修饰，保证并发的可见性。 2.TableTable：默认为null，初始化发生在第一次插入操作，默认大小为16的数组，用来存储 Node 节点数据，扩容时大小总是 2 的幂次方。 1234567class Node implements Map.Entry &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; ... ...&#125; 2.实现方式JDK1.8 的 currentHashMap参考了 1.8HashMap 的实现方式,采用了数组+链表+红黑树的实现方式。其中大量的使用CAS操作。CAS (compare and swap) JDK8 中彻底放弃了 Segment 转而采用的是 Node，其设计思想也不再是 JDK1.7 中的分段锁思想。 红黑树是一种性能非常好的二叉查找树，其查找性能为 O(logN)，早期完全采用链表结构时 Map 的查找时间复杂度为 O(N)。 3.原理图 JDK8 中 currentHashMap 原理图 总结版本对比JDK1.7版本：ReentrantLock + Segment + HashEntry， JDK1.8版本：Synchronized + CAS + Node + 红黑树 原理对比（1.8 于 1.7）1.数据结构：取消了 Segment 分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。 2.保证线程安全机制：JDK1.7 采用 segment 的分段锁机制实现线程安全，其中 segment 继承自 ReentrantLock。JDK1.8 采用 CAS + Synchronized 保证线程安全。 3.锁的粒度：原来是对需要进行数据操作的 Segment 加锁，现调整为对每个数组元素加锁（Node）。 4.链表转化为红黑树：定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。 5.查询时间复杂度：从原来的遍历链表 O(n)，变成遍历红黑树 O(logN)。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"currentHashMap","slug":"currentHashMap","permalink":"https://yugd.cn/tags/currentHashMap/"}]},{"title":"每日一面--Redis和MySQL数据一致性问题","slug":"面试--Redis和MySQL数据一致性问题","date":"2021-07-22T00:58:58.000Z","updated":"2022-05-26T18:17:35.850Z","comments":true,"path":"posts/60188/","link":"","permalink":"https://yugd.cn/posts/60188/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Redis 和 MySQL 数据一致性问题 写在前面 对于Web来说，用户量和访问量增一定程度上推动项目技术和架构的更迭和进步。 当页面并发量和访问量并不多，MySQL足以支撑自己逻辑业务的发展。其实可以不加缓存，最多对静态页面进行缓存即可。 什么时候需要缓存？ 页面的并发量显著增多，数据库有些压力，并且有些数据更新频率较低反复被查询或者查询速度较慢。 对高命中的对象存到 Key-Value 形式的 Redis 中，那么，如果数据被命中，那么可以不经过效率很低的 DB。从高效的 Redis 中查找到数据。 虽然还能通过静态页面缓存页面、cdn加速、甚至负载均衡这些方法提高系统并发量，但是本片博客只是针对 Redis 缓存做讨论","text":"每天一篇面试小知识 本篇着重介绍一下 Redis 和 MySQL 数据一致性问题 写在前面 对于Web来说，用户量和访问量增一定程度上推动项目技术和架构的更迭和进步。 当页面并发量和访问量并不多，MySQL足以支撑自己逻辑业务的发展。其实可以不加缓存，最多对静态页面进行缓存即可。 什么时候需要缓存？ 页面的并发量显著增多，数据库有些压力，并且有些数据更新频率较低反复被查询或者查询速度较慢。 对高命中的对象存到 Key-Value 形式的 Redis 中，那么，如果数据被命中，那么可以不经过效率很低的 DB。从高效的 Redis 中查找到数据。 虽然还能通过静态页面缓存页面、cdn加速、甚至负载均衡这些方法提高系统并发量，但是本片博客只是针对 Redis 缓存做讨论 Redis 缓存的应用不使用缓存的时候 缓存适用的高并发场景缓存适用于高并发的场景，提升服务容量。 主要是将从经常被访问的数据或者查询成本较高从慢的介质中存到比较快的介质中，比如从硬盘—&gt;内存。 大多数关系数据库是基于硬盘读写的，其效率和资源有限，而 redis 是基于内存的，其读写速度差别差别很大。当并发过高关系数据库性能达到瓶颈时候，就可以策略性将常访问数据放到 redis 提高系统吞吐和并发量。 常用网站为什么会响应慢？对于常用网站和场景，关系数据库主要可能慢在两个地方： 读写IO性能较差 一个数据可能通过较大量计算得到 所以使用缓存能够减少磁盘IO次数和关系数据库的计算次数 体现： 基于内存，读写较快 使用哈希算法直接定位结果不需要计算 Redis 缓存需要注意的问题缓存使用不当会带来很多问题，所以需要对一些细节进行认真考量和设计。 最难的数据一致性！ 是否用缓存项目不能为了用缓存而用缓存，缓存并一定适合所有场景！ 如果对数据一致性要求极高，又或者数据频繁更改而查询并不多，又或者根本没并发量的、查询简单的不一定需要缓存，还可能浪费资源使得项目变得臃肿难维护。 过期策略选择缓存装的是相对热点和常用的数据，redis 资源也是有限，需要选择一个合理的策略让缓存过期删除，根据时间来的 FIFO 是最好实现的。且 redis 在全局 key 支持过期策略。 并且过期时间也要根据系统情况合理设置，如果硬件好点当前可以稍微久一点，但是过期时间过久或者过短可能都不太好，过短可能缓存命中率不高，而过久很可能造成很多冷门数据存储在Redis中不释放。 Redis 缓存数据一致性问题读数据read：从 redis 中读取，如果 redis 中没有，那么就从 MySQL 中获取更新 redis 缓存。 写数据 【先更新数据库，再更新缓存(普通低并发)】 先更新数据库信息，再更新Redis缓存。这是常规做法，缓存基于数据库，取自数据库。 但是其中可能遇到一些问题，例如上述如果更新缓存失败(宕机等其他状况)，将会使得数据库和 redis 数据不一致。造成 DB 新数据，缓存旧数据 写数据 【先删除缓存，再写入数据库(低并发优化)】 这种情况能够有效避免【先更新数据库，再更新缓存】中防止写入 redis 失败的问题。将缓存删除进行更新。理想是让下次访问 redis 为空去 mysql 取得最新值到缓存中。但是这种情况仅限于低并发的场景中而不适用高并发场景! 存在的问题 我们在【先更新数据库，再更新缓存】讨论过如果更新库成功，缓存更新失败会导致脏数据。我们理想是删除缓存让下一个线程访问适合更新缓存。问题是：如果这下一个线程来的太早呢？ 因为在多线的情况下，无法保证那条线程优先执行。 将会出现 redis 缓存数据和 mysql 不一致 高并发下依然会造成缓存是旧数据，DB 是新数据 写数据【延时双删策略】 能过缓解在【先删除缓存，再写入数据库】中在更新MySQL过程中有读的线程进入造成Redis缓存与MySQL数据不一致。 方法就是 删除缓存-&gt;更新缓存-&gt;延时【几百ms，可异步】再次删除缓存 存在的问题 第二次删除错误、多写多读高并发情况下对MySQL访问的压力等等，当然你可以选择用MQ等消息队列异步解决。 写数据【直接操作缓存，定期写入sql(适合高并发)】 直接操作缓存，将缓存定期写入sql。 因为 redis 这种非关系数据库又基于内存操作 KV 相比传统关系型要快很多！ 异步更新缓存(基于订阅 binlog 的同步机制) 技术整体思路： MySQL binlog 增量订阅消费 + 消息队列 + 增量数据更新到 redis 读Redis：热数据基本都在 redis 写MySQL：增删改都是操作 mysql 更新Redis数据：mysql 的数据操作 binlog，来更新到 redis 数据操作主要分为两大块： 一个是全量(将全部数据一次写入到 redis) 一个是增量（实时更新）","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"redis","slug":"redis","permalink":"https://yugd.cn/tags/redis/"}]},{"title":"每日一面--Spring 循环依赖以及三级缓存","slug":"面试--Spring 循环依赖及三级缓存","date":"2021-07-21T01:00:00.000Z","updated":"2022-05-26T18:17:43.212Z","comments":true,"path":"posts/52633/","link":"","permalink":"https://yugd.cn/posts/52633/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Spring 循环依赖以及三级缓存 写在前面 什么是循环依赖？ 简单的说就是 A 依赖 B，B 依赖 A 这样就构成了循环依赖。 具体说一说 spring 是如何解决循环依赖的吧 让我好好想一想……","text":"每天一篇面试小知识 本篇着重介绍一下 Spring 循环依赖以及三级缓存 写在前面 什么是循环依赖？ 简单的说就是 A 依赖 B，B 依赖 A 这样就构成了循环依赖。 具体说一说 spring 是如何解决循环依赖的吧 让我好好想一想…… 什么是循环依赖所谓的循环依赖是指，A 依赖 B，B 又依赖 A，它们之间形成了循环依赖。或者是 A 依赖 B，B 依赖 C，C 又依赖 A，形成了循环依赖。更或者是自己依赖自己。 举个图解荔枝： 举个代码荔枝： 123456789101112131415public class BeanB &#123; private BeanA beanA; public void setBeanA(BeanA beanA) &#123; this.beanA = beanA; &#125; &#125;public class BeanA &#123; private BeanB beanB; public void setBeanB(BeanB beanB) &#123; this.beanB = beanB; &#125;&#125; 配置文件： 1234567&lt;bean id=\"beanA\" class=\"com.ase.BeanA\"&gt; &lt;property name=\"beanB\" ref=\"beanB\"/&gt;&lt;/bean&gt;&lt;bean id=\"beanB\" class=\"com.ase.BeanB\"&gt; &lt;property name=\"beanA\" ref=\"beanA\"/&gt;&lt;/bean&gt; 按照上面的例子，Spring 启动后，读取如上的配置文件，会按顺序先实例化 A，但是创建的时候又发现它依赖了 B，接着就去实例化 B ，同样又发现它依赖了 A ，从而导致了无限循环，淦！ 尝试思考 Spring 实例化对象分两步： 第一步，会先创建一个原始对象，只是没有设置属性，可以理解为”半成品”—— 官方叫 A 对象的早期引用（EarlyBeanReference）； 第二步，当实例化 B 的时候发现依赖了 A， B 就会把这个“半成品”设置进去先完成实例化，既然 B 完成了实例化，所以 A 就可以获得 B 的引用，也完成实例化了，这其实就是 Spring 解决循环依赖的思想； 循环依赖发生的时机Bean 实例化主要分为三步，如图： 问题出现在：第一步和第二步的过程中，也就是填充属性 / 方法的过程中 Spring 如何解决的 Spring 为了解决单例的循环依赖问题，使用了 三级缓存 ，递归调用时发现 Bean 还在创建中即为循环依赖 单例模式的 Bean 保存在如下的数据结构中： 1234567891011121314/**一级缓存，用于存放完全初始化好的 bean，从该缓存中取出的 bean 可以直接使用*/private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);/** 二级缓存：存放原始的 bean 对象（尚未填充属性），用于解决循环依赖 */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);/** 三级级缓存：存放 bean 工厂对象，用于解决循环依赖 */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);/**bean 的获取过程：先从一级获取，失败再从二级、三级里面获取创建中状态：是指对象已经 new 出来了但是所有的属性均为 null 等待被 init*/ 一级缓存：singletonObjects，存放完全实例化属性赋值完成的 Bean，直接可以使用。 二级缓存：earlySingletonObjects，存放早期 Bean 的引用，尚未属性装配的 Bean 三级缓存：singletonFactories，三级缓存，存放实例化完成的 Bean工厂。 循环依赖的解决流程图 A、B 相互依赖检测循环依赖的过程如下： A 创建过程中需要 B，于是 A 将自己放到三级缓里面 ，去实例化 B B 实例化的时候发现需要 A，于是 B 先查一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，找到了 然后把三级缓存里面的这个 A 放到二级缓存里面，并删除三级缓存里面的 A B 顺利初始化完毕，将自己放到一级缓存里面（此时B里面的A依然是创建中状态） 然后回来接着创建 A，此时 B 已经创建结束，直接从一级缓存里面拿到 B ，然后完成创建，并将自己放到一级缓存里面 如此一来便解决了循环依赖的问题 总结 先让最底层对象完成初始化，通过三级缓存与二级缓存提前曝光创建中的 Bean，让其他 Bean 率先完成初始化。 注意Spring 还是有一些无法解决的循环依赖！ 使用构造器注入其他 Bean 的实例，这个就没办法了，要手动改代码。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"Spring","slug":"Spring","permalink":"https://yugd.cn/tags/Spring/"}]},{"title":"每日一面--Redis 五种数据结构详解","slug":"面试--Redis 5 种数据结构详解","date":"2021-07-21T00:08:08.000Z","updated":"2022-05-26T18:17:30.216Z","comments":true,"path":"posts/48441/","link":"","permalink":"https://yugd.cn/posts/48441/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Redis 的五种数据结构 写在前面 Redis 是基于 C 语言编写的开源非关系型内存数据库，可以用作数据库、缓存、消息中间件。 Redis 的五种数据结构详解，包括这五种的数据结构的底层原理实现。 Redis 键的类型总是 string Redis–基本语句","text":"每天一篇面试小知识 本篇着重介绍一下 Redis 的五种数据结构 写在前面 Redis 是基于 C 语言编写的开源非关系型内存数据库，可以用作数据库、缓存、消息中间件。 Redis 的五种数据结构详解，包括这五种的数据结构的底层原理实现。 Redis 键的类型总是 string Redis–基本语句 Redis核心对象在Redis中有一个「核心的对象」叫做 redisObject ，是用来表示所有的 key 和 value 的，用 redisObject 结构体来表示String、Hash、List、Set、ZSet五种数据类型。 在redisObject中「type表示属于哪种数据类型，encoding表示该数据的存储方式」，也就是底层的实现的该数据类型的数据结构。 Redis的五种数据结构 String：字符串类型 List：列表类型 Set：无序集合类型 ZSet：有序集合类型 Hash：哈希表类型 String 类型 可以存储字符串、整数或者浮点数（如果存储的是整数或者浮点数，还能执行自增或者自减操作）。 String 类型是二进制安全的，存储大小是由上限的 512 M。 redis 中的字符串（SDS）和 c 语言中的字符串类型却是有明显的区别，字符串不是根据某种特殊的标志位来（C语言的\\0）解析的。 下面重点解释一下Redis底层定义了自己的一种数据结构 简单动态字符串（SDS）SDS 的定义 12345678910typedef char *sds;struct sdshdr &#123; // buf 已占用长度 int len; // buf 剩余可用长度 int free; // 实际保存字符串数据的地方 char buf[];&#125;; SDS 遵循 C语言以空字符串为结尾的惯例。保存空字符串的 1 字节将不会被计算到 SDS 的 len 属性里面，并且为空字符串额外分配 1 字节的空间。 redis 使用 len 属性来判断字符串是否结束。 （了解）空间预分配 and 惰性空间释放 数据结构 内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。 当字符串长度小于 1M 时，扩容都是加倍现有的空间（ len = free ），如果超过 1M，扩容时一次 只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。 List 类型单键多值 Redis 的列表类型和许多程序语言中的列表类型类似，可以有序地存储多个字符串。 支持从列表的左端和右端推入或弹出元素。 它的底层实际是个双向链表，对两端的操作性能很高。 数据结构它将所有的元素紧挨着一起存储，分配的是一块连续的内存。 当数据量比较多的时候才会改成 quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间。 Redis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指 针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 Set 类型字典 又称 符号表（symbol table），是一种用于保存键值对（key-value pairs）的抽象数据结构。 字典中，一个键（key）和一个值（value）进行关联，关联的的键值称之为键值对。 Set 是 string 类型的无序集合。它底层其实是一个 value 为 null 的 hash 表，所 以添加，删除，查找的复杂度都是 O(1)。 ZSet 类型有序集合 zset 与普通集合 set 非常相似，是一个没有重复元素的字符串集合。 不同之处是有序集合的每个成员都关联了一个评分（score）用来从低到高进行排序。 跳跃表跳表，是基于链表实现的一种类似“二分”的算法。它可以快速的实现增，删，改，查操作。 支持平均 O(logN) 、最坏 O(N) 复杂度的几点查找，还可以通过顺序性操作来批量处理节点。 其性能能够和平衡树相媲美，且实现起来比平衡树更加的简单。 一个 skipList 节点最高可以达到 64 层，一个“跳表”中最多可以存储 2^64 个元素，每个节点都是一个 skiplistNode（跳表节点） skipList 结构体 12345678910typedf struct zskiplist&#123; //头节点 struct zskiplistNode *header; //尾节点 struct zskiplistNode *tail; // 跳表中的元素个数 unsigned long length; //表内节点的最大层数 int level;&#125;zskiplist; skiplist 结构 链表想要查询某个节点的数据需要从 head 节点进行遍历，但是随着节点的增多其查询效率也就越低。 为了提高查询效率，我们给该单链表加多级索引，将会改善查询效率。 每隔一个节点就提取出来一个元素到上一层，把这一层称作索引，其中的 down 指针指向原始链表。 利用生成的索引进行范围确定，在进行向下查询，当数据量增大到一定程度的时候，效率将会有显著的提升。 注意 跳跃表以有序的方式在层次化的链表中保存元素，效率和平衡树媲美：查找、删除、添加等操作都可以在对数期望时间下完成。跳跃表体现了“空间换时间”的思想。 Hash 类型一个 hash 类型的 key 最多可以存储 2^32-1（约 40 亿个）字段 / 值。 hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 数据结构 Hash 类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。 当存储的数据量较少的时，hash 采用 ziplist 作为底层存储结构： 哈希对象保存的所有键值对（键和值）的字符串长度总和小于 64 个字节。 哈希对象保存的键值对数量要小于 512 个。 当无法满足上述条件时，hash 就会采用第二种方式来存储数据，也就是 dict（字典结构）。 未完待续……","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"redis","slug":"redis","permalink":"https://yugd.cn/tags/redis/"}]},{"title":"每日一面--MySQL 存储引擎","slug":"面试--MySQL 存储引擎","date":"2021-07-19T13:58:58.000Z","updated":"2022-05-26T18:17:19.174Z","comments":true,"path":"posts/9027/","link":"","permalink":"https://yugd.cn/posts/9027/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 MySQL 存储引擎 写在前面 本文依照数据库 5.7 来描述滴~ 明确一点： 数据库实例（instance）才是真正用于操作数据库文件的。 MySQL 是一个单进程、多线程架构的数据库； 在集群的情况下，一个数据库对应对个数据库实例。","text":"每天一篇面试小知识 本篇着重介绍一下 MySQL 存储引擎 写在前面 本文依照数据库 5.7 来描述滴~ 明确一点： 数据库实例（instance）才是真正用于操作数据库文件的。 MySQL 是一个单进程、多线程架构的数据库； 在集群的情况下，一个数据库对应对个数据库实例。 MySQL数据库：由一个个文件组成（二进制） 数据库实例：执行类似于（Insert、Update、Delete）来更改数据库的内容 ACID Atomicity（原子性） Consistency（一致性） Isolation（隔离性） Durability（持久性） MySQL 存储引擎对比 特点 MyISAM InnoDB Memory 批量插入的速度 高 低 高 事务安全 - 支持 - 全文索引 支持 不支持 不支持 锁机制 表锁 行锁 表锁 存储限制 256 TB 64 T RAM B 树索引 支持 支持 支持 哈希索引 不支持 不支持 支持 集群索引 - 支持 - 数据缓存 - 支持 支持 索引缓存 支持 支持 支持 数据可压缩 支持 - - 空间使用 低 高 N/A 内存使用 低 高 中 支持外键 不支持 支持 不支持 MySQL 存储引擎MySQL 插件式存储引擎概念MySQL 存储引擎（核心） 存储引擎是基于表的，而不是数据库 MySQL 默认存储引擎 使用下面的语句可以修改数据库临时的默认存储引擎 1SET default_storage_engine &#x3D; &lt;存储引擎名&gt; 但是当再次重启客户端时，默认存储引擎仍然是 InnoDB 表锁概念行锁和表锁在mysql 的 InnoDB引擎支持行锁，与Oracle不同，mysql的行锁是通过索引加载的，即是行锁是加在索引响应的行上的，要是对应的SQL语句没有走索引，则会全表扫描， 行锁则无法实现，取而代之的是表锁。 表锁：不会出现死锁，发生锁冲突几率高，并发低。 行锁：会出现死锁，发生锁冲突几率低，并发高。 锁冲突：例如说事务A将某几行上锁后，事务B又对其上锁，锁不能共存否则会出现锁冲突。（但是共享锁可以共存，共享锁和排它锁不能共存，排它锁和排他锁也不可以） 死锁：例如说两个事务，事务A锁住了1-5行，同时事务B锁住了6-10行，此时事务A请求锁住6-10行，就会阻塞直到事务B施放6-10行的锁，而随后事务B又请求锁住1-5行，事务B也阻塞直到事务A释放1-5行的锁。死锁发生时，会产生 Deadlock 错误。 锁是对表操作的，所以自然锁住全表的表锁就不会出现死锁 行锁的类型行锁分 共享锁 和 排它锁 共享锁： 又称读锁，当一个事务对某几行上读锁时，允许其他事务对这几行进行读操作，但不允许其进行写操作，也不允许其他事务给这几行上排它锁，但允许上读锁。 排它锁： 又称写锁，当一个事务对某几个上写锁时，不允许其他事务写，但允许读。更不允许其他事务给这几行上任何锁。包括写锁。 举个荔枝： 上共享锁的写法：lock in share mode 1select math from results where math &gt; 60 lock in share mode； 上排它锁的写法：for update 1select math from results where math &gt; 60 for update 行锁的实现 行锁必须有索引才能实现，否则会自动锁全表，那么就不是行锁了。 两个事务不能锁同一个索引，例如： 1234567# 事务A先执行：select math from results where math &gt; 60 for update; # 事务B再执行：select math from results where math &lt; 60 for update；# 这样的话，事务 B 是会阻塞的。如果事务 B 把 math 索引换成其他索引就不会阻塞，# 但注意，换成其他索引锁住的行不能和 math 索引锁住的行有重复。 InnoDB 存储引擎5.8版本后的默认存储引擎 优势 支持事务的安装 灾难恢复型好 使用行级锁 实现了缓冲处理 支持外键 适合大型的数据库网站 MyISAM 存储引擎5.8版本的默认存储引擎 优势 支持全文索引 劣势 不支持事务 不支持行锁 组成MYD 和 MYI 其缓冲池中只存索引文件，而不是缓冲数据文件； MYD：用来存放数据文件（Date） MYI：用来存放索引文件（Index） 5.0 版本前：默认支持表的大小为 4 GB； 5.0 版本时：默认支持表的大小为 256 TB； Memory 存储引擎将表中的数据存放在内存当中，一旦数据库重新启动或者崩溃，则表中的数据都将消失。 适合用于存储临时数据的临时表。 默认使用的是哈希索引而不是 B+ 树索引； 只支持表锁，不支持 text 和 blob 列类型。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"MySQL 存储引擎","slug":"MySQL-存储引擎","permalink":"https://yugd.cn/tags/MySQL-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"}]},{"title":"每日一面--Maven依赖冲突","slug":"面试--Maven","date":"2021-07-17T13:58:58.000Z","updated":"2022-05-26T18:17:13.543Z","comments":true,"path":"posts/33896/","link":"","permalink":"https://yugd.cn/posts/33896/","excerpt":"每天一篇面试小知识 本篇着重介绍一下关于 Maven 的依赖冲突 ： 写在前面 之前在使用 maven 的时候还真的没有特意的留意过关于依赖冲突的问题。 这不，面试中被问到还有点猝不及防！ 来吧，一起来回顾一遍~","text":"每天一篇面试小知识 本篇着重介绍一下关于 Maven 的依赖冲突 ： 写在前面 之前在使用 maven 的时候还真的没有特意的留意过关于依赖冲突的问题。 这不，面试中被问到还有点猝不及防！ 来吧，一起来回顾一遍~ Maven 是什么？Maven 翻译为”专家”、”内行”，是 Apache 下的一个纯 Java 开发的开源项目。基于项目对象模型（缩写：POM）概念，Maven利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。 Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。 Maven 也可被用于构建和管理各种项目，例如 C#，Ruby，Scala 和其他语言编写的项目。Maven 曾是 Jakarta 项目的子项目，现为由 Apache 软件基金会主持的独立 Apache 项目。 Maven 坐标【一个完整的坐标信息，由 groupId、artifactId、version、packaging、classifier 组成】 GroupId定义当前 Maven 项目从属的实际项目； Maven 项目和实际项目不一定是一一对应的 groupId 不应该同开发项目的公司或组织对应； groupId 的表述形式同 Java 包名的表述方式类似，通常与域名反向一一对应； ArtifactId定义实际项目中的一个 Maven 项目（实际项目中的一个模块） 推荐命名的方式为：实际项目名称-模块名称； Version定义 Maven 当前所处的版本 Packaging定义 Maven 项目的打包方式【jar、war】 Maven POMPOM( Project Object Model，项目对象模型 ) 是 Maven 工程的基本工作单元，是一个XML文件，包含了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。 POM 中可以指定以下配置： 项目依赖 （√） 插件（√） 执行目标（√） 项目构建 profile（√） 项目版本（√） 项目开发者列表 相关邮件列表信息 举个荔枝： 12345678910111213141516&lt;project xmlns = \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi = \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation = \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;!-- 模型版本 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 公司或者组织的唯一标志，并且配置时生成的路径也是由此生成， 如com.companyname.project-group，maven会将该项目打成的jar包放本地路径：/com/companyname/project-group --&gt; &lt;groupId&gt;com.companyname.project-group&lt;/groupId&gt; &lt;!-- 项目的唯一ID，一个groupId下面可能多个项目，就是靠artifactId来区分的 --&gt; &lt;artifactId&gt;project&lt;/artifactId&gt; &lt;!-- 版本号 --&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/project&gt; Maven 生命周期Maven 构建生命周期 阶段 处理 描述 验证 validate 验证项目 验证项目是否正确且所有必须信息是可用的 编译 compile 执行编译 源代码编译在此阶段完成 测试 test 测试 使用适当的单元测试框架（例如JUnit）运行测试。 包装 package 打包 创建JAR/WAR包如在 pom.xml 中定义提及的包 检查 verify 检查 对集成测试的结果进行检查，以保证质量达标 安装 install 安装 安装打包的项目到本地仓库，以供其他项目使用 部署 deploy 部署 拷贝最终的工程包到远程仓库中，以共享给其他开发人员和工程 mvn 打包比较常用功能（重点） clean：执行该命令会删除项目路径下的 target 文件，但是不会删除本地的 maven 仓库已经生成的 jar 文件。 compile：编译命令，会在项目路径下生成一个 target 目录，在该目录中包含一个classes文件夹，里面全是生成的class文件及字节码文件。 package：这个命令会在你的项目路径下一个 target 目录，并且拥有 compile 命令的功能进行编译，同时会在 target 目录下生成项目的 jar/war 文件。 install：该命令包含了 package 命令功能，不但会在项目路径下生成 class 文件和 jar 包，同时会在本地 maven 仓库生成 jar 文件，供其他项目使用。 注意： 同时执行多次install或者package命令会每次都更新jar文件 Maven 仓库Maven 仓库类型Maven 仓库有三种类型： 本地（local）：Maven 的本地仓库，在安装 Maven 后并不会创建，它是在第一次执行 maven 命令的时候才被创建。 中央（central）：Maven 中央仓库是由 Maven 社区提供的仓库，其中包含了大量常用的库。 远程（remote）：如果 Maven 在中央仓库中也找不到依赖的文件，它会停止构建过程并输出错误信息到控制台。为避免这种情况，Maven 提供了远程仓库的概念，它是开发人员自己定制仓库，包含了所需要的代码库或者其他工程中用到的 jar 文件。 Maven 依赖搜索顺序当我们执行 Maven 构建命令时，Maven 开始按照以下顺序查找依赖的库： 步骤 1 － 在本地仓库中搜索，如果找不到，执行步骤 2，如果找到了则执行其他操作。 步骤 2 － 在中央仓库中搜索，如果找不到，并且有一个或多个远程仓库已经设置，则执行步骤 4，如果找到了则下载到本地仓库中以备将来引用。 步骤 3 － 如果远程仓库没有被设置，Maven 将简单的停滞处理并抛出错误（无法找到依赖的文件）。 步骤 4 － 在一个或多个远程仓库中搜索依赖的文件，如果找到则下载到本地仓库以备将来引用，否则 Maven 将停止处理并抛出错误（无法找到依赖的文件）。 Maven 阿里云(Aliyun)仓库修改 maven 根目录下的 conf 文件夹中的 settings.xml 文件，在 mirrors 节点上，添加内容如下： 12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt; Maven 的排除、归类和优化依赖排除依赖Maven 可能会自动引入快照版本的依赖，而快照版本的依赖是不稳定的，这时候就需要避免引入快照版本。这样的话需要用一种方式告知 Maven 排除快照版本的依赖引入，这种做法就是排除依赖。 直接依赖的配置里面添加 exclusions（除外） → exclusion（排除）元素，指定要排除依赖的 groupId 和 artifactId 就行。 例如： 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;$&#123;project.build.hibernate.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;xxx&lt;/groupId&gt; &lt;artifactId&gt;xxx&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 归类依赖在引用依赖的时候，很多情况需要引入一个 Maven 项目的多个模块，这些模块都应该是相同的版本。 例如在下次升级，需要将 1.0 版本升级成 2.0 版本，这样就需要将 org.springframework 的每个模块的版本都统一更改，这样做很容易出现不一致的情况，就很容易出错。 为了避免出现这种情况，可以在 pom.xml 中定义一个属性名称描述版本的值。 举个荔枝： 123456789101112131415161718192021222324252627282930313233&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; ... &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;!-- 3.2.16.RELEASE,3.1.4.RELEASE --&gt; &lt;project.build.spring.version&gt;4.2.7.RELEASE&lt;/project.build.spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;project.build.spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;project.build.spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;project.build.spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; ... &lt;/dependencies&gt; ...&lt;/project&gt; 优化依赖 Maven 定位依赖的方式、传递依赖的规则以及怎么样排除依赖等。但是要实现这些动作，还必须对项目中的依赖有全面的了解，这样才能更有效地达到目的。 查看依赖的相关命令 列出所有的依赖列表。 1Mvn dependency:list 以树形结构方式，列出依赖和层次关系。 1Mvn dependency:tree 分析主代码、测试代码编译的依赖。 1Mvn dependency:analyze 面试一下什么是依赖冲突/版本冲突?Maven 的依赖机制会导致 jar 包的冲突 举个例子，在项目中，使用了两个 jar 包，分别是 A 和 B。现在 A 需要依赖另一个 jar 包 C，B 也需要依赖 C。但是 A 依赖的 C 的版本是 1.0，B 依赖的C的版本是 2.0。这时候，Maven 会将这 1.0 的 C 和 2.0 的 C 都下载到你的项目中，这样你的项目中就存在了不同版本的 C。 这时Maven会采用最短路径优先原则（即，根据寻找到的依赖路径中最短的），来决定使用哪个版本的 jar 包，而另一个无用的 jar 包则未被使用，这就是所谓的依赖冲突。 注意： 在大多数时候，依赖冲突可能并不会对系统造成什么异常，因为 Maven 始终选择了一个 jar 包来使用。但是，不排除在某些特定条件下，会出现类似找不到类的异常。所以，只要存在依赖冲突，最好还是解决掉，不要给系统留下隐患。 解决办法： 最经典的就是 log4j 的依赖排除，使用 Maven 提供的标签 exclusion 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.10.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-api&lt;/artifactId&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; 解释： log4j-core 本身是依赖了 log4j-api 的，但是因为一些其他的模块也依赖了 log4j-api，并且两个 log4j-api 版本不同，所以我们使用标签排除掉 log4j-core 所依赖的 log4j-api，这样 Maven 就不会下载 log4j-core 所依赖的 log4j-api 了，也就保证了我们的项目中只有一个版本的 log4j-api。 maven 的依赖原则maven 有三种原则依赖原则 当一个项目中出现重复引用依赖 jar 包时，maven 一般有如下三种原则处理 jar 最短路径原则 12A -&gt; B -&gt; C -&gt; D(v1)F -&gt; G -&gt; D(v2) 这个时候项目中就出现了两个版本的 D，这时 maven 会采用最短路径原则，选择 v2 版本的 D，因为 v1 版本的 D 是由 A 包间接依赖的，整个依赖路径长度为 3，而 v2 版本的 D 是由 F 包间接依赖的，整个依赖路径长度为 2。 优先声明原则 12A -&gt; B -&gt; D(v1)F -&gt; G -&gt; D(v2) 如果两个 jar 包版本路径深度相同，则使用优先声明的版本 v1 多次直接引不同版本的 jar 时，使用最后声明的版本 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.3.17.RELEASE&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.3.20.RELEASE&lt;/version&gt;&lt;/dependency&gt; 如果 pom 文件中，同时引用了如上两个版本，则会使用 4.3.20.RELEASE 版本（最后声明的版本） install 和 package 的区别Maven install 安装指令，其实做了 2 件事情： 将项目打包（jar/war），将打包结果放到项目下的 target 目录下； 同时将上述打包结果放到本地仓库的相应目录中，供其他项目或模块引用； Maven package 打包指令，其实就做了 1 件事： 将项目打包（jar/war），将打包结果放到项目下的 target 目录下 （要先 clean）； 注意： clean 命令作用是：清理项目中 target 目录下文件；","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"maven","slug":"maven","permalink":"https://yugd.cn/tags/maven/"}]},{"title":"每日一面--布隆过滤器","slug":"面试--布隆过滤器","date":"2021-07-16T13:58:58.000Z","updated":"2022-05-26T18:16:42.101Z","comments":true,"path":"posts/11389/","link":"","permalink":"https://yugd.cn/posts/11389/","excerpt":"每天一篇面试小知识 本篇着重介绍一下布隆过滤器 写在前面 为啥要写一篇关于布隆过滤器的博客？ 还不是因为上集说到的 redis 中遇到缓存穿透的其中一个解决方案。 下面我们来详细的介绍一下 “ Bloom Filter ”","text":"每天一篇面试小知识 本篇着重介绍一下布隆过滤器 写在前面 为啥要写一篇关于布隆过滤器的博客？ 还不是因为上集说到的 redis 中遇到缓存穿透的其中一个解决方案。 下面我们来详细的介绍一下 “ Bloom Filter ” 百度了一下： 布隆过滤器本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure） 特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在” 。 相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。 讲述布隆过滤器的原理之前，我们先思考一下，通常你判断某个元素是否存在用的是什么？ 应该蛮多人回答 HashMap 吧，确实可以将值映射到 HashMap 的 Key，然后可以在 O (1) 的时间复杂度内返回结果，效率奇高。 了解布隆过滤器原理之前，先回顾下 Hash 函数原理。 哈希函数哈希函数的概念是：将任意大小的输入数据转换成特定大小的输出数据的函数，转换后的数据称为哈希值或哈希编码，也叫散列值。如图： 所有散列函数都有如下基本特性： 如果两个散列值是不相同的（根据同一函数），那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为单向散列函数。 散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“散列碰撞（collision）”。 但是用 hash 表存储大数据量时，空间效率还是很低，当只有一个 hash 函数时，还很容易发生哈希碰撞。 布隆过滤器数据结构布隆过滤器是一个 bit 向量或者说 bit 数组，长这样： 如果我们要映射一个值到布隆过滤器中，我们需要使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1，例如针对值 “baidu” 和三个不同的哈希函数分别生成了哈希值 1、4、7（橙色部分）则上图转变为： 我们现在再存一个值 “tencent”，如果哈希函数返回 3、4、8 （紫色部分）图继续变为： 值得注意的是，4 这个 bit 位由于两个值的哈希函数都返回了这个 bit 位，因此它被覆盖了（绿色部分） 现在我们如果想查询 “google” 这个值是否存在，哈希函数返回了 1、5、8 三个值，结果我们发现 5 这个 bit 位上的值为 0，说明没有任何一个值映射到这个 bit 位上; 因此我们可以很确定地说 “google” 这个值不存在。而当我们需要查询 “baidu” 这个值是否存在的话，那么哈希函数必然会返回 1、4、7，然后我们检查发现这三个 bit 位上的值均为 1; 那么我们可以说 “baidu” 存在了么？答案是不可以，只能是 “baidu” 这个值可能存在。 这是为什么呢？ 答案跟简单，因为随着增加的值越来越多，被置为 1 的 bit 位也会越来越多，这样某个值 “taobao” 即使没有被存储过，但是万一哈希函数返回的三个 bit 位，例如：1、3、8 都被其他值置位了 1 ，那么程序还是会判断 “taobao” 这个值存在。 布隆过滤器优点相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。 布隆过滤器存储空间和插入/查询时间都是常数。 另外, Hash 函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。 布隆过滤器可以表示全集，其它任何数据结构都不能； k 和 m 相同，使用同一组 Hash 函数的两个布隆过滤器的交并差运算可以使用位操作进行。 布隆过滤器缺点布隆过滤器的缺点和优点一样明显。误算率（False Positive）是其中之一。随着存入的元素数量增加，误算率随之增加。但是如果元素数量太少，则使用散列表足矣。 另外，一般情况下不能从布隆过滤器中删除元素. 我们很容易想到把位列阵变成整数数组，每插入一个元素相应的计数器加1, 这样删除元素时将计数器减掉就可以了。 然而要保证安全的删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面. 这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。 布隆过滤器的使用场景：在程序的世界中，布隆过滤器是程序员的一把利器，利用它可以快速地解决项目中一些比较棘手的问题。 如网页 URL 去重、垃圾邮件识别、大集合中重复元素的判断和缓存穿透等问题。 布隆过滤器的典型应用有： 数据库防止穿库。 Google Bigtable，HBase 和 Cassandra 以及 Postgresql 使用BloomFilter来减少不存在的行或列的磁盘查找。避免代价高昂的磁盘查找会大大提高数据库查询操作的性能。 业务场景中判断用户是否阅读过某视频或文章，比如抖音或头条，当然会导致一定的误判，但不会让用户看到重复的内容。 缓存宕机、缓存击穿场景，一般判断用户是否在缓存中，如果在则直接返回结果，不在则查询db，如果来一波冷数据，会导致缓存大量击穿，造成雪崩效应，这时候可以用布隆过滤器当缓存的索引，只有在布隆过滤器中，才去查询缓存，如果没查询到，则穿透到db。如果不在布隆器中，则直接返回。 WEB拦截器，如果相同请求则拦截，防止重复被攻击。用户第一次请求，将请求参数放入布隆过滤器中，当第二次请求时，先判断请求参数是否被布隆过滤器命中。可以提高缓存命中率。Squid 网页代理缓存服务器在 cache digests 中就使用了布隆过滤器。Google Chrome浏览器使用了布隆过滤器加速安全浏览服务 Venti 文档存储系统也采用布隆过滤器来检测先前存储的数据。 SPIN 模型检测器也使用布隆过滤器在大规模验证问题时跟踪可达状态空间。 布隆过滤器的使用（Java版） 需要引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;28.0-jre&lt;/version&gt;&lt;/dependency&gt; 创建一个布隆过滤器 123456789101112131415161718192021222324252627282930313233343536373839404142package com.example.demo.test;import com.google.common.hash.BloomFilter;import com.google.common.hash.Funnels;import lombok.extern.log4j.Log4j2;import org.junit.jupiter.api.AfterAll;import org.junit.jupiter.api.BeforeAll;import org.junit.jupiter.api.DisplayName;import org.junit.jupiter.api.Test;import java.nio.charset.Charset;@Log4j2@DisplayName(\"TestBloomFilterTest测试类\")class TestBloomFilterTest &#123; @BeforeAll static void beforeAll() &#123; log.info(\"===============测试开始===============\"); &#125; @AfterAll static void afterAll() &#123; log.info(\"===============测试结束===============\"); &#125; @Test @DisplayName(\"布隆过滤器\") void BloomFilterTest() &#123; BloomFilter&lt;String&gt; filter = BloomFilter.create( Funnels.stringFunnel(Charset.defaultCharset()), 1000, 0.001 ); filter.put(\"baidu.com\"); filter.put(\"tencent.com\"); log.info(\"布隆过滤器中是否含有 baidu.com? &#123;&#125;\",filter.mightContain(\"baidu.com\")); log.info(\"布隆过滤器中是否含有 google.com? &#123;&#125;\",filter.mightContain(\"google.com\")); &#125;&#125; 结果 结论本质上布隆过滤器是一种数据结构，特点是高效地插入和查询，可以用来确定某个值一定不存在或者可能存在 回到 redis 中遇到缓存穿透的其中一个解决方案，布隆过滤器能够过滤掉一定不存在的值，也就是说，我们可以把数据库中所有的数据存储到布隆过滤器中，一旦有非法的值传进来，就能够轻而易举的判断出该值对于数据库来说是否有效，从而避免无谓的查询。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://yugd.cn/tags/redis/"}]},{"title":"每日一面--Redis","slug":"面试--Redis","date":"2021-07-15T13:58:58.000Z","updated":"2022-05-26T18:17:33.925Z","comments":true,"path":"posts/3169/","link":"","permalink":"https://yugd.cn/posts/3169/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 Redis 写在前面 为什么不直接访问数据库？要在中间加一个Redis缓存？其实我在了解redis之前一直有这样一个疑问，但是既然使用redis作为中间缓存一定是有道理的！ 那么一起来看一下使用redis有哪些好处吧~","text":"每天一篇面试小知识 本篇着重介绍一下 Redis 写在前面 为什么不直接访问数据库？要在中间加一个Redis缓存？其实我在了解redis之前一直有这样一个疑问，但是既然使用redis作为中间缓存一定是有道理的！ 那么一起来看一下使用redis有哪些好处吧~ 原因： Redis 可以用几十 G 内存来做缓存； Redis 的缓存可以持久化 （RBD &amp; AOF）； Redis 可以实现分布式的缓存； Redis 可以处理每秒百万级的并发，是专业的缓存服务； Redis 缓存有过期机制； Redis 有丰富的 API。 其中redis最典型的应用场景，当做缓存使用。 因为传统的关系型数据库如Mysql已经不能适用所有的场景了，比如秒杀的库存扣减，APP首页的访问流量高峰等等…… 服务在处理请求时先从redis里获取结果，获取到了就可以直接返回，没有获取到的话再从数据库里获取，然后存到redis里以供下次使用。 用redis的好处是可以做到分布式，有状态的数据都存在redis里，使业务服务层无状态，以便业务层有很高的可扩展性。 先来说下redis是什么吧？我：Redis是C语言开发的一个开源的高性能键值对（key-value）的内存数据库； 它是一种NoSQL（非关系型数据库）的数据库。 可以用作数据库、缓存、消息中间件等。 我接着说：Redis作为一个内存数据库。 性能优秀，数据在内存中，读写速度非常快，支持并发10W QPS； 单进程单线程，是线程安全的，采用IO多路复用机制； 丰富的数据类型； 支持数据持久化。可以将内存中数据保存在磁盘中，重启时加载； 主从复制，哨兵，高可用； 可以用作分布式锁； 可以作为消息中间件使用，支持发布订阅。 具体说一下Redis有哪些数据结构呀？答：字符串（String）、字典（Hash）、列表（List）、集合（Set）、有序集合（SortedSet） 后面了解到还有：HyperLogLog、Geo、Pub/Sub 【这是加分的内容】 使用过Redis分布式锁么，它是怎么回事？答：先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？（这道题很经典啊，网上见过~） 答：使用keys指令可以扫出指定模式的key列表 【 key keys xxx*】 那如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？答：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。 后面了解到：这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。 使用过Redis做异步队列么，你是怎么用的？答：一般使用list结构作为队列，rpush生产消息，lpop消费消息。list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。 能不能生产一次消费多次呢？答：使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。 pub/su b有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如RabbitMQ等。 Redis是怎么持久化的？（送分题~） 答：RBD 和 AOF RDB做镜像全量持久化，即将整个Redis内存数据持久化到一个文件。 AOF做增量持久化，AOF会将redis中每一步对数据修改的操作记录（日志）append到相应的文件中。 那说一下 RBD 和 AOF 的优劣，及其原理吧答： RDB 优点： 二进制压缩文件，恢复速度快 缺点： 可能丢失数据（服务器宕机的时候） 原理： fork 和 cow fork是指redis通过创建子进程来进行RDB操作； cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 AOF 优点： 不易丢失数据，数据完整性好 缺点： 每一步操作都记录，相对影响性能 数据恢复慢，文件较大 原理： 为了降低 IO 消耗，AOF 写文件时，会先将数据写到缓冲区，然后再把缓冲区的内容 flush 到磁盘，这个过程叫做 fsync。 123$ appendfsync always //每次写操作都flush，影响性能$ appendfsync everysec //每秒flush$ appendfsync no //消极等待OS刷新(一般30s),可能丢失数据 相比于always的激进和no的消极，everysec在性能和数据完整性上取了一个折中。 是否使用过Redis集群，集群的高可用怎么保证，集群的原理是什么？答： Redis Sentinal 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master，继续提供服务。 Redis Cluster 着眼于扩展性，在单个 redis 内存不足时，使用 Cluster 进行分片存储。 Redis 会遇到的缓存雪崩，缓存穿透，缓存击穿吧先来了解一下缓存雪崩，缓存穿透，缓存击穿是什么意思！ 一、缓存雪崩 含义： 缓存雪崩表示在某一时间段，缓存集中失效，导致请求全部走数据库，有可能搞垮数据库，使整个服务瘫痪。 使缓存集中失效的原因： redis服务器挂掉了。 对缓存数据设置了相同的过期时间，导致某时间段内缓存集中失效。（√） 解决方案： 针对原因1，可以实现redis的高可用，Redis Cluster 或者 Redis Sentinel(哨兵) 等方案。 针对原因2，设置缓存过期时间时加上一个随机值，避免缓存在同一时间过期。 举个荔枝： 123## 设置过期时间加上一个随机值$redis-&gt;set('article_content_1', '文章内容', 60 + mt_rand(1, 60));$redis-&gt;set('article_content_2', '文章内容', 60 + mt_rand(1, 60)); 使用双缓存策略，设置两个缓存，原始缓存和备用缓存，原始缓存失效时，访问备用缓存，备用缓存失效时间设置长点。 1234## 原始缓存$redis-&gt;set('article_content_2', '文章内容', 60);## 设置备用缓存，失效时间设置长点$redis-&gt;set('article_content_backup_2', '文章内容', 1800); 二、缓存穿透 含义： 缓存穿透表示查询一个一定不存在的数据，由于没有获取到缓存，所以没写入缓存，导致这个不存在的数据每次都需要去数据库查询，失去了缓存的意义。 请求的数据大量的没有获取到缓存，导致走数据库，有可能搞垮数据库，使整个服务瘫痪。 比如文章表，一般我们的主键ID都是无符号的自增类型，有些人想要搞垮你的数据库，每次请求都用负数ID，而ID为负数的记录在数据库根本就没有。 解决方案： 对于像ID为负数的非法请求直接过滤掉，采用布隆过滤器 ( Bloom Filter ) 。 禁用IP 限制IP访问。 限流 每秒最多访问3次。 针对在数据库中找不到记录的，我们仍然将该空数据存入缓存中，当然一般会设置一个较短的过期时间。 12345//设置文章ID为-10000的缓存为空$id = -10000;$redis-&gt;set('article_content_' . $id, '', 60); var_dump($redis-&gt;get('article_content_' . $id)); 三、缓存击穿 含义： 缓存击穿表示某个key的缓存非常热门，有很高的并发一直在访问，如果该缓存失效，那同时会走数据库，压垮数据库。 缓存击穿与缓存雪崩的区别是这里针对的是某一热门 key 缓存，而雪崩针对的是大量缓存的集中失效。 解决方案： 让该热门 key 的缓存永不过期。 使用互斥锁，通过 redis 的 setnx 实现互斥锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455function getRedis()&#123; $redis = new Redis(); $redis-&gt;connect('127.0.0.1', 6379, 60); return $redis;&#125; //加锁function lock($key, $random)&#123; $redis = getRedis(); //设置锁的超时时间，避免释放锁失败，del()操作失败，产生死锁。 $ret = $redis-&gt;set($key, $random, ['nx', 'ex' =&gt; 3 * 60]); return $ret;&#125; //解锁function unLock($key, $random)&#123; $redis = getRedis(); //这里的随机数作用是，防止更新缓存操作时间过长，超过了锁的有效时间，导致其他请求拿到了锁。 //但上一个请求更新缓存完毕后，如果不加判断直接删除锁，就会误删其他请求创建的锁。 if ($redis-&gt;get($key) == $random) &#123; $redis-&gt;del($key); &#125;&#125; //从缓存中获取文章数据function getArticleInCache($id)&#123; $redis = getRedis(); $key = 'article_content_' . $id; $ret = $redis-&gt;get($key); if ($ret === false) &#123; //生成锁的key $lockKey = $key . '_lock'; //生成随机数，用于设置锁的值，后面释放锁时会用到 $random = mt_rand(); //拿到互斥锁 if (lock($lockKey, $random)) &#123; //这里是伪代码，表示从数据库中获取文章数据 $value = $db-&gt;getArticle($id); //更新缓存，过期时间可以根据情况自已调整 $redis-&gt;set($key, $value, 2 * 60); //释放锁 unLock($lockKey, $random); &#125; else &#123; //等待200毫秒，然后重新获取缓存值，让其他获取到锁的进程取得数据并设置缓存 usleep(200); getArticleInCache($id); &#125; &#125; else &#123; return $ret; &#125;&#125;","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://yugd.cn/tags/redis/"}]},{"title":"日积月累","slug":"日积月累","date":"2021-06-30T23:07:07.000Z","updated":"2022-05-26T18:18:08.794Z","comments":true,"path":"posts/33770/","link":"","permalink":"https://yugd.cn/posts/33770/","excerpt":"面试中遇到问题的相关总结","text":"面试中遇到问题的相关总结 1、@Autowired和@Resource的区别是什么？联系： @Autowired和@Resource注解都是作为bean对象注入的时候使用的； 两者都可以声明在字段和setter方法上； 区别： @Autowired注解是Spring提供的，而@Resource注解是J2EE本身提供的； @Autowird注解默认通过byType方式注入，而@Resource注解默认通过byName方式注入； @Autowired注解注入的对象需要在IOC容器中存在，否则需要加上属性required=false，表示忽略当前要注入的bean，如果有直接注入，没有跳过，不会报错； 其实 @Autowired 注入首先根据 byType 注入，当类型大于1时在根据 byName 注入。 2、HashMap与ConcurrentHashMap的区别？相同点： 首先两者的相同点在于底层都是数组+链表实现实现的； 区别： HashMap是线程非安全的，ConcurrentHashMap是线程安全的 3、处理哈希冲突的方法？ 开放定址法 链地址法（√） 再散列法 4、包装类和基本数据类型的区别？包装类： 优点： 可以赋值为null 提供了一系列的方法常用的有：parseInt(String s)、tostring()、valueOf(String s)、equals( object object)、i.compareto(integer anotherIntger) 集合中不允许放基本数据类型，只能放包装类！ 缺点： 由于每个值分别包装在对象中，所以ArrayList的效率远远低于int[]数组 基本数据类型： 优点： 计算效率高 不会由于常量池而引起比较大小的错误 缺点： 当数据库查询出结果封装到结果集时,如何返回的值为null时,会将结果赋值给字段,运行时会报错,不能将null值赋值给基本数据类型 两者的区别：1、声明方式不同，基本类型不适用new关键字，而包装类型需要使用new关键字来在堆中分配存储空间；2、存储方式及位置不同，基本类型是直接将变量值存储在堆栈中，而包装类型是将对象放在堆中，然后通过引用来使用；3、初始值不同，基本类型的初始值如int为0，boolean为false，而包装类型的初始值为null4、使用方式不同，基本类型直接赋值直接使用就好，而包装类型在集合如Collection、Map时会使用到。5、包装类都是继承Number 接口实现Compareble 接口的 5、MyISAM 和 INNODB 的区别？ 事务安全： MyISAM 不支持事务（×） INNODB 支持事务（√） 外键 ： MyISAM 不支持外键（×） INNODB 支持外键（√） 锁机制： MyISAM 是表锁 INNODB 是行锁 查询和添加速度： MyISAM 批量插入速度快 支持全文索引： MyISAM 支持全文索引（√） INNODB 不支持全文索引（×） MyISAM 内存空间使用率比 INNODB 低 Memory 存储，比如我们数据变化频繁，不需要入库，同时又频繁的查询和修改，我们考虑使用 memory, 速度极快. （如果 mysql 重启的话，数据就不存在了） 6、Java中final、finally、finalize的区别与用法 final：java中的关键字，修饰符。1.如果一个类被声明为final，就意味着它不能再派生出新的子类，不能作为父类被继承。因此，一个类不能同时被声明为abstract抽象类的和final的类。2.如果将变量或者方法声明为final，可以保证它们在使用中不被改变. 被声明为final的变量必须在声明时给定初值，而在以后的引用中只能读取，不可修改。 被声明final的方法只能使用，不能重载。 finally：java的一种异常处理机制。 finally是对Java异常处理模型的最佳补充。finally结构使代码总会执行，而不管无异常发生。使用finally可以维护对象的内部状态，并可以清理非内存资源。特别是在关闭数据库连接这方面，如果程序员把数据库连接的close()方法放到finally中，就会大大降低程序出错的几率。 finalize：Java中的一个方法名。Java技术使用finalize()方法在垃圾收集器将对象从内存中清除出去前，做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没被引用时对这个对象调用的。它是在Object类中定义的，因此所的类都继承了它。子类覆盖finalize()方法以整理系统资源或者执行其他清理工作。finalize()方法是在垃圾收集器删除对象之前对这个对象调用的。 7、try-catch-finally 异常处理语法结构中只有 try 块是必需的，也就是说，如果没有 try 块，则不能有后面的 catch 块和 finally 块； catch 块和 finally 块都是可选的，但 catch 块和 finally 块至少出现其中之一，也可以同时出现； 可以有多个 catch 块，捕获父类异常的 catch 块必须位于捕获子类异常的后面； 不能只有 try 块，既没有 catch 块，也没有 finally 块； 多个 catch 块必须位于 try 块之后，finally 块必须位于所有的 catch 块之后。 finally 与 try 语句块匹配的语法格式，此种情况会导致异常丢失，所以不常见。 8、Java中常见的五种异常 ClassCastException【类转换异常】 IndexOutOfBoundsException【数组越界】 NullPointerException【空指针】 IllegalAccessException【安全权限异常】 IOException【输入输出异常】 9、Java中垃圾回收的目的？什么时候进行？垃圾回收是在内存中中存在没有引用的对象或超过作用域的对象时进行垃圾回收，垃圾回收的目的是识别并且丢弃不再使用的对象来释放和重用资源。 目的：回收堆中不再使用的对象，释放资源。回收时间：当对象失去引用后，系统会在合适的时间回收它所占的内存。 老年代的对象所需要的内存大于老年代剩余内存，则会触发老年代 GC（Full GC）。 当程序调用System.gc() 时也会触发Full GC。 10、什么是内存泄漏？【out of memory】 当一个对象已经不需要再使用本该被回收时，另外一个正在使用的对象持有它的引用从而导致它不能被回收，这导致本该被回收的对象不能被回收而停留在堆内存中。 内存溢出的原因以及解决方法 内存中加载的数据量过于庞大，如一次从数据库取出过多数据； 集合类中有对对象的引用，使用完后未清空，使得JVM不能回收； 代码中存在死循环或循环产生过多重复的对象实体； 启动参数内存值设定的过小 内存溢出的解决方案： 第一步，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。) 第二步，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。 第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。 11、String s = new String(“xyz”);创建几个String对象？两个或一个 第一次调用 new String(“xyz”); 时，会在堆内存中创建一个字符串对象，同时在字符串常量池中创建一个对象 “xyz” 第二次调用 new String(“xyz”); 时，只会在堆内存中创建一个字符串对象，指向之前在字符串常量池中创建的 “xyz” 12、类加载器工作机制？ 装载：将Java二进制代码导入jvm中，生成Class文件。 连接： 校验：检查载入Class文件数据的正确性 准备：给类的静态变量分配存储空间 解析：将符号引用转成直接引用 初始化：对类的静态变量，静态方法和静态代码块执行初始化工作。双亲委派模型：类加载器收到类加载请求，首先将请求委派给父类加载器完成 用户自定义加载器-&gt;应用程序加载器-&gt;扩展类加载器-&gt;启动类加载器。 13、Spring中的Controller ，Service，Dao是不是线程安全的？ 在@Controller/@Service等容器中，默认情况下，scope 值是单例 singleton 的，也是线程不安全的。 尽量不要在@Controller/@Service等容器中定义静态变量，不论是单例 (singleton) 还是多实例 (prototype) 他都是线程不安全的。 默认注入的 Bean 对象，在不设置 scope 的时候他也是线程不安全的。 一定要定义变量的话，用 ThreadLocal 来封装，这个是线程安全的 14、Java 中 sleep() 和 wait() 的区别？ 这两个方法来自不同的类分别是，sleep 来自 Thread 类，和 wait 来自 Object 类。 最主要是 sleep 方法没有释放锁，而 wait 方法释放了锁，使得其他线程可以使用同步控制块或者方法。 使用范围：wait，notify 和 notifyAll 只能在同步控制方法或者同步控制块里面使用，而 sleep 可以在任何地方使用。 sleep 必须捕获异常，而 wait，notify 和 notifyAll 不需要捕获异常。 15、@bean 注解和 @component注解的区别 @Component 注解作用于类 @Bean 注解作用于方法 @Component 通常是通过路径扫描来自动侦测以及自动装配到 Spring 容器中【@ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中】 @Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean，@Bean 告诉了 Spring 这是某个类的实例，当我们需要用它的时候还给我。 @Bean 注解比 @Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring 容器时，只能通过 @Bean 来实现。 未完待续 … …","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"日积月累","slug":"日积月累","permalink":"https://yugd.cn/tags/%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF/"}]},{"title":"每日一面--SpringBoot启动原理","slug":"面试--SpringBoot启动原理","date":"2021-06-27T13:58:58.000Z","updated":"2022-12-10T12:07:49.769Z","comments":true,"path":"posts/65011/","link":"","permalink":"https://yugd.cn/posts/65011/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 SpringBoot 启动原理： 写在前面 最近在不断的面试中总结Spring全家桶已经是必须要熟练掌握的框架了，其中化繁为简的SpringBoot更是经常被提及的框架，所以我今天就来聊聊 SpringBoot。 说起SpringBoot的江湖地位，由于其设计优雅，实现简单，可以节省不少开发时间。","text":"每天一篇面试小知识 本篇着重介绍一下 SpringBoot 启动原理： 写在前面 最近在不断的面试中总结Spring全家桶已经是必须要熟练掌握的框架了，其中化繁为简的SpringBoot更是经常被提及的框架，所以我今天就来聊聊 SpringBoot。 说起SpringBoot的江湖地位，由于其设计优雅，实现简单，可以节省不少开发时间。 以下源码的 SpringBoot 版本：2.3.9.RELEASE 其实SpringBoot的启动大体上分为 2 个步骤： 启动类上注解：@SpringBootApplication 启动类中的main方法：org.springframework.boot.SpringApplication#run(java.lang.Class&lt;?&gt;, java.lang.String…) 启动原理@SpringBootApplicationmain 方法上的注解 @SpringBootApplication： 三个注解核心注解： @SpringBootConfiguration @EnableAutoConfiguratio @ComponentScan @SpringBootConfiguration 根据 Javadoc 可知，该注解作用就是将当前的类作为一个 JavaConfig，然后触发注解@EnableAutoConfiguration和@ComponentScan的处理，本质上与@Configuration注解没有区别。 @ComponentScan 扫描的 Spring 对应的组件，如 @Componet，@Repository。 总结 SpringBoot工程运行后初始化Spring容器，扫描引导类所在的包加载bean Spring注解注解的优势： 采用纯java代码，不在需要配置繁杂的xml文件。 在配置中也可享受面向对象带来的好处。 类型安全对重构可以提供良好的支持。 减少复杂配置文件的同时亦能享受到springIoC容器提供的功能。 配置文件的注解@SpringBootApplication（自动配置）引导类上面的@SpringBootApplication相当于是将：@Configuration 、@EnableAutoConfiguration 、 @ComponentScan 三个注解的组合注解。 @EnableAutoConfiguration也是组合注解，其中最关键的要是@Import(AutoConfigurationImportSelector.class)。 借助AutoConfigurationImportSelector，@EnableAutoConfiguration可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。 项目启动时会去classpath中搜索所有META-INF/spring.factories配置文件，根据以@ConditionalOnxxx为前缀的注解来判断是否加载当前的配置类。 @ComponentScan@ComponentScan注解主要是从约定的扫描路径中，识别标注了组件注册注解的类，并且把这些类自动注册到spring 。 包路径： 1@ComponentScan(&#123;\"com.xxx\"&#125;) 类路径： 1@ComponentScan(basePackageClasses=&#123;XxxService.class&#125;) 扫描路径可以配置，默认是从引导类所在的包开始及其子包下的所有文件 @Configuration本身就是一个组件，用于定义配置类，可替换xml配置文件。被注解的类内部包含有一个或多个被@Bean注解的方法。 作用于类上 @Bean将方法的返回值添加到容器中，AnnotationConfigWebApplicationContext类进行扫描，并用于构建bean定义，初始化Spring容器。 作用于方法上 @ConfigurationProperties使用注解的方式将自定义的properties、yml文件映射到实体bean中。 123456789@Data@Configuration@ConfigurationProperties(prefix = \"mail\")public class ConfigProperties &#123; private String hostName; private int port; private String from;&#125; 1234#Simple propertiesmail.hostname=host@mail.commail.port=1000mail.from=mailer@mail.com 如果不想使用@Configuration， 那么需要在@EnableConfigurationProperties(ConfigProperties.class)注解中手动导入配置文件 关于Bean的注解@Component泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注，作用就相当于 XML配置。 @Component注解及其衍生注解@RestController、@Controller、@Service和@Repository都是组件注册注解。 @Controller、@RestController在控制层使用，处理请求。 @Controller 一般应用在有返回界面的应用场景下. @RestController 如果只是接口，那么就用 RestController 来注解， @RestController = @Controller + @ResponseBody @Service 在业务逻辑层使用，就是对一个或多个DAO进行的再次封装，封装成一个服务，所以这里也就不会是一个原子操作了，需要事物控制。 1234567@Service(\"userServiceOne\")public class UserServiceImplOne implements UserService &#123; &#125;@Service(\"userServiceTwo\")public class UserServiceImplTwo implements UserService &#123; &#125; 123@Autowired@Qualifier(\"userServiceOne\") private UserService userService; @Repository在数据访问层使用， 123@Repository(value=\"userDao\")public class UserDaoImpl extends BaseDaoImpl&lt;User&gt; &#123; &#125; @Autowired基于Spring规范开发，在实现注入功能的时候是基于By type的方式去注入 根据被注解的属性的class，在容器中查找相同class的bean @Resource基于Java的规范开发，在实现注入功能的时候是基于By name的方式来注入 根据被注解的属性的name，在Spring容器中查找相同名字的bean @Order@Order注解不能指定 bean 的加载顺序，它适用于 AOP 的优先级，以及将多个 Bean 注入到集合时，这些 bean 在集合中的顺序。 Spring 常用配置注解@Import通过导入的方式实现把实例加入Spring IOC容器中。可以在需要时将没有被Spring容器管理的类导入至Spring容器中。 1@Import(&#123;User.class&#125;) @ImportResource与@Import类似，区别就是@ImportResource导入的是配置文件。比如原项目已经将配置文件打成包，需要在原来的基础上进行新添加配置的时候导入原配置。 1@ImportResource(\"classpath:spring-xxx.xml\") //导入xml配置 @ScopeSpring中bean的scope属性，有如下5种类型，在多数情况，我们只会使用singleton和prototype两种scope。 默认为单例 1@Scope(\"singleton\") 更改为多例模式 1@Scope(\"prototype\") @Value作用是通过注解将常量、配置文件中的值和其他bean的属性值注入到变量中，作为变量的初始值。 12@Value(\"$&#123;user.age&#125;\")private String age; 但是@value不能直接注入值给静态变量 解决方法： 把@Value(value=”${xxx}”)放到静态变量的set方法上 12345678/**文件存储目录*/public static String SAVE_PATH;//记得去掉static@Value(\"$&#123;local.file.temp.dir&#125;\")public void setSavePath(String savePath)&#123; SAVE_PATH = savePath;&#125; 配置文件： 1234local: file: temp: dir : /data/temp 使用 @postconstruct，是在 bean 初始化过程中调用的，是在@value之后调用的，可以通过这种方式给静态变量赋值。 123456789101112131415/**文件存储目录*/public static String SAVE_PATH;@Value(\"$&#123;local.file.temp.dir&#125;\")public String SAVE_PATH_TEMP;@PostConstructprivate void init()&#123; SAVE_PATH = SAVE_PATH_TEMP;&#125;@GetMapping(\"test\")public void test()&#123; System.out.println(SAVE_PATH);&#125; @Value (“hello”) –&gt; 普通字符串注入 @PostConstruct 在构造函数执行完之后执行 @EnableScheduling开启对计划任务的支持(定时器) @Scheduled声明这是一个计划任务 支持多种计划任务 1234@Scheduled(dixedDelay = 5000)public void prt()&#123; System.out.println(\"定时器...\");&#125; @Enable*注解EnableXXX这样的注解，通过这些注解我们可以很方便地启用某些功能，比如@EnableAutoConfiguration用来开启自动装配的功能。内部实现主要是通过@Import注解将指定的类实例注入之Spring IOC Container中，从下面代码可以看到@EnableAutoConfiguration的@Import @EnableAsync 开启异步任务的支持(多线程) @EnableScheduling 开启对计划任务的支持(定时器) @EnableWebMVC 开启对Web MVC 的配置支持 @EnableAaspectJAutoProxy开启Spring 对 这个切面(Aspect )的支持 @EnableConfigurationProperties开启对@ConfigurationProperties注解配置Bean的支持 @EnableJpaRepositories开启对Spring Data JAP Repository 的支持 @EnableTransactionManagement开启对注解式事物的支持 @EnableScheduling让spring可以进行任务调度,功能类似于spring.xml文件中的命名空间 @EnableCaching开启Cache缓存支持; SpringMVC 常用注解@RequestMapping value：指定 URL 请求的实际地址，是 @RequestMapping 的默认值。 用于将特定 HTTP 请求方法映射到将处理相应请求的控制器中的特定类、方法。此注释可应用于两个级别： 类级别：映射请求的 URL。 方法级别：映射 URL 以及 HTTP 请求方法。 method:指定请求的 method 类型，GET、POST、PUT、DELET。 1@RequestMapping(value = \"/index\",method = RequestMethod.GET) @RequestMapping 可进行 GET、POST、PUT、DELETE 等请求方法； @GetMapping、@PostMapping、@PutMapping、@DeleteMapping params：指定请求中必须包含某些参数，否则无法调用该方法。 12345@RequestMapping(value = \"/index\",method = RequestMethod.GET,params =&#123;\"name\",\"id=10\"&#125;)public String index()&#123; System.out.println(\"执行了index...\"); return \"index\";&#125; @RequestParam@RequestParam有三个参数： value：参数名； required：是否必需，默认为true，表示请求参数中必须包含该参数，如果不包含抛出异常。 defaultValue：默认参数值，如果设置了该值自动将required设置为false，如果参数中没有包含该参数则使用默认值。 1@RequestParam(value = \"userId\", required = false, defaultValue = \"1\") @PathVariableurl 占位符映射时，url中可以通过一个或多个{xxxx}占位符映射，通过@PathVariable可以绑定占位符参数到方法参数中。 123456@RequestMapping(“/user/&#123;userId&#125;/&#123;userName&#125;/query\")public String index(@PathVariable(\"userId\") Long userId, @PathVariable(\"userName\") String userName)&#123; ... return \"index\"; &#125; @RequestHeader通过此注解可以获取请求头相关信息。 123456Host localhost:8080Accept text/html,application/xhtml+xml,application/xml;q=0.9Accept-Language fr,en-gb;q=0.7,en;q=0.3Accept-Encoding gzip,deflateAccept-Charset ISO-8859-1,utf-8;q=0.7,*;q=0.7Keep-Alive 300 123456@GetMapping(\"/demo\")public void handle( @RequestHeader(\"Accept-Encoding\") String encoding, @RequestHeader(\"Keep-Alive\") long keepAlive) &#123; //...&#125; @CookieValue获取cookie 1234@GetMapping(\"/demo\")public void handle(@CookieValue(\"tok\") String cookie) &#123; //...&#125; @RequestBody@RequestBody主要用来接收前端传递给后端的json字符串中的数据的(请求体中的数据的)。 一个请求，只有一个RequestBody；一个请求，可以有多个RequestParam。 12345@GetMapping(\"/user\")public R queryUser(@RequestBody User user) &#123; //... return R.success();&#125; 测试单元的注解@SpringBootTest获取启动类，加载配置，寻找主配置启动类（被 @SpringBootApplication 注解的） @RunWith@RunWith(SpringRunner.class)，让JUnit运行Spring的测试环境,获得Spring环境的上下文的支持 @Test注解添加在测试方法上，表明这是一个测试方法。 1234567@SpringBootTestclass Boot05WebAdminApplicationTests &#123; @Test void contextLoads() &#123; &#125;&#125; @DisplayName为测试类或者测试方法设置展示名称。 123456789@DisplayName(\"junit5功能测试\")public class Junit5Test &#123; @DisplayName(\"测试displayname注解\") @Test void testDisplayName() &#123; System.out.println(\"测试displayname注解\"); &#125;&#125; @BeforeEach、@AfterEach、@BeforeAll、@AfterAll 注解 作用 @BeforeEach 表示在每个单元测试之前执行 @AfterEach 表示在每个单元测试之后执行 @BeforeAll 表示在所有单元测试之前执行 @AfterAll 表示在所有单元测试之后执行 @Disabled表示测试类或测试方法不执行。 123456@Disabled@DisplayName(\"测试2\")@Testvoid test2() &#123; System.out.println(\"此测试方法不执行\");&#125; @Timeout表示测试方法运行如果超过了指定时间将会返回错误。 12345@Test@Timeout(value = 500, unit = TimeUnit.MILLISECONDS)void testTimeOut() throws InterruptedException &#123; Thread.sleep(520);&#125; @RepeatedTest表示方法可重复执行。 123456@RepeatedTest(5) //重复测试5次@DisplayName(\"测试3\")@Testvoid test3() &#123; System.out.println(\"重复测试\");&#125; 事务注解@Transactional声明式事务管理： 建立在AOP之上的。其本质是对方法前后进行拦截，然后在目标方法开始之前创建或者加入一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务。 SpringBoot项目会自动配置一个 DataSourceTransactionManager，所以我们只需在方法（或者类）加上 @Transactional 注解，就自动纳入 Spring 的事务管理了 1234567@Transactionalpublic void insertUser() &#123; User user = new User(\"abc\"); userMapper.insertOneUser(user); //向数据库插入一条记录 throw new RuntimeException(\"发生异常\"); //手动模拟抛出异常&#125; 抛出异常之后，事务会自动回滚，数据不会插入到数据库。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yugd.cn/tags/SpringBoot/"}]},{"title":"每日一面--Spring入门","slug":"面试--Spring框架","date":"2021-06-19T13:58:58.000Z","updated":"2022-05-26T18:17:45.641Z","comments":true,"path":"posts/16824/","link":"","permalink":"https://yugd.cn/posts/16824/","excerpt":"每天一篇Java小知识 本篇着重介绍一下 Spring 框架 写在前面 百度百科： Spring 框架是由于软件开发的复杂性而创建的。 Spring 使用的是基本的JavaBean来完成以前只可能由EJB完成的事情。然而，Spring 的用途不仅仅限于服务器端的开发。从简单性、可测试性和松耦合性角度而言，绝大部分 Java 应用都可以从 Spring 中受益。","text":"每天一篇Java小知识 本篇着重介绍一下 Spring 框架 写在前面 百度百科： Spring 框架是由于软件开发的复杂性而创建的。 Spring 使用的是基本的JavaBean来完成以前只可能由EJB完成的事情。然而，Spring 的用途不仅仅限于服务器端的开发。从简单性、可测试性和松耦合性角度而言，绝大部分 Java 应用都可以从 Spring 中受益。 SpringSpring 核心Spring 的整体架构 Spring 应用的设计模式 工厂设计模式 : Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :Spring AOP 的增强或通知 (Advice) 使用到了适配器模式、Spring MVC 中也是用到了适配器模式适配 controller。 Spring 三层架构 A 表现层 web层 、 MVC是表现层的一个设计模型 B 业务层 service层 C 持久层 dao层 注意要与 SPringMVC 的三层架构区分开。 核心容器 spring-core 模块提供了框架的基本组成部分，包括 IoC 和依赖注入功能。 spring-beans 模块提供 BeanFactory，工厂模式的微妙实现，它移除了编码式单例的需要，并且可以把配置和依赖从实际编码逻辑中解耦。 context 模块建立在由 core和 beans 模块的基础上建立起来的，它以一种类似于 JNDI 注册的方式访问对象。Context 模块继承自 Bean 模块，并且添加了国际化（比如，使用资源束）、事件传播、资源加载和透明地创建上下文（比如，通过 Servelet 容器）等功能。Context 模块也支持 Java EE 的功能，比如 EJB、JMX 和远程调用等。ApplicationContext 接口是 Context 模块的焦点。spring-context-support 提供了对第三方集成到 Spring 上下文的支持，比如缓存（EhCache, Guava, JCache）、邮件（JavaMail）、调度（CommonJ, Quartz）、模板引擎（FreeMarker, JasperReports, Velocity）等。 spring-expression 模块提供了强大的表达式语言，用于在运行时查询和操作对象图。它是 JSP2.1 规范中定义的统一表达式语言的扩展，支持 set 和 get 属性值、属性赋值、方法调用、访问数组集合及索引的内容、逻辑算术运算、命名变量、通过名字从 Spring IoC 容器检索对象，还支持列表的投影、选择以及聚合等。 数据访问/集成注：JDBC【Java Data Base Connectivity】，ORM【Object Relational Mapping】，OXM【Object XML Mapping】，JMS【Java Message Service】 JDBC 模块提供了 JDBC 抽象层，它消除了冗长的 JDBC 编码和对数据库供应商特定错误代码的解析。 ORM 模块提供了对流行的对象关系映射 API 的集成，包括 JPA、JDO 和 Hibernate 等。通过此模块可以让这些 ORM 框架和 spring的其它功能整合，比如前面提及的事务管理。 OXM 模块提供了对 OXM 实现的支持，比如 JAXB、Castor、XML Beans、JiBX、XStream 等。 JMS 模块包含生产（produce）和消费（consume）消息的功能。从 Spring 4.1 开始，集成了 spring-messaging 模块。 事务模块为实现特殊接口类及所有的 POJO 支持编程式和声明式事务管理。（注：编程式事务需要自己写 beginTransaction()、commit()、rollback() 等事务管理方法，声明式事务是通过注解或配置由 spring 自动处理，编程式事务粒度更细） WebWeb 层由 Web，Web-MVC，Web-Socket 和 Web-Portlet 组成，它们的细节如下： Web 模块提供面向 web 的基本功能和面向 web 的应用上下文，比如多部分（multipart）文件上传功能、使用 Servlet 监听器初始化 IoC 容器等。它还包括 HTTP 客户端以及 Spring 远程调用中与 web 相关的部分。 Web-MVC 模块为 web 应用提供了模型视图控制（MVC）和 REST Web服务的实现。Spring 的 MVC 框架可以使领域模型代码和 web 表单完全地分离，且可以与 Spring 框架的其它所有功能进行集成。 Web-Socket 模块为 WebSocket-based 提供了支持，而且在 web 应用程序中提供了客户端和服务器端之间通信的两种方式。 Web-Portlet 模块提供了用于 Portlet 环境的 MVC 实现，并反映了 spring-webmvc 模块的功能。 Spring 框架的优点 非侵入式设计 方便解耦、简化开发 支持AOP 支持声明式事务处理 方便程序的测试 方便集成各种优秀框架 降低Jave EE API的使用难度。 说到 spring 的容器管理就不得不先提一下 bean 的概念 Bean 的概念 在 Java 中，“Bean”是对“可重用组件”的惯用叫法。组件本身就是一个抽象概念，Bean 作为其代称，也是一个抽象概念，当我们将一个类或一个对象作为组件来考虑时，就可以称它为 Bean。 在 Spring 中，Bean 的概念同上，它有时也被称为 Component。由 Spring 容器管理的 Bean 则称为 Spring Bean。 扩展： Java Bean 的概念不同于 Bean，Java Bean 是指符合 JavaBeans 规范的一类特殊的 Bean，即：所有属性均为 private，提供 getter 和 setter，提供默认构造方法。JavaBean 也可以认为是遵循特定约定的 POJO。 POJO（Plain Ordinary Java Object）是指简单且普通的 Java 对象。严格来说，它不继承类，不实现接口，不处理业务逻辑，仅用于封装数据。 说到 spring 就不得不提到两个重要的概念 IoC 【控制反转】 DI 【依赖注入】 IOC 与 DIIOC 定义IoC（Inverse Of Control，控制反转）是一种设计思想，所谓控制反转，指的是对资源的控制方式进行反转。 IOC 容器具有依赖注入功能的容器，它可以创建对象，IOC 容器负责实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。 解释【控制权在自己】：在 OOP 中，对象之间往往存在某种依赖关系，当一个对象依赖另一个对象时，传统 OOP 的做法是在它内部直接 new 一个出来，这种做法是由对象自己主动创建并管理依赖资源。 【控制权在 Spring 容器】：”控制反转”是指 new 实例工作不由程序员来做而是交给 Spring 容器来做。使得对象不再主动控制依赖资源，而是被动接受资源，IoC 要求将资源的控制权下放给 Ioc 容器，它将对资源进行集中管理，对象需要什么资源就从容器中取，或者让容器主动将资源注入进来。 好处在 IoC 之后，对象与依赖资源之间不再具有强耦合性，资源可以被直接替换，而无需改动需求方的代码。 注意在 Spring 中 BeanFactory 是 IOC 容器的实际代表者。【工厂模式】 Spring 的两种 IoC 容器Spring 提供了两种 IoC 容器： BeanFactory 和 ApplicationContext BeanFactory 提供基本的 IoC 服务支持。 ApplicationContext 对 BeanFactory 进行了扩展与增强，除了拥有 BeanFactory 的所有能力外，还提供了许多高级特性，如事件发布、资源加载、国际化消息等。ApplicationContext 接口继承自 BeanFactory 接口，它的实现也是直接复用了 BeanFactory 的实现，因此可以说，ApplicationContext 是 BeanFactory 的增强版。 两者在核心功能上的区别主要是默认的加载策略不同，这点区别几乎可以忽略不计，通常情况下，我们总是使用更为强大的 ApplicationContext，很少会直接使用 BeanFactory。 IoC 的两种实现方式 DI（Dependency Injection，依赖注入）所谓依赖注入，是指对象所依赖的资源将通过被动注入的方式得到，换言之，容器会主动地根据预先配置的依赖关系将资源注入进来。 DL（Dependency Lookup，依赖查找）依赖查找是早先提出的一种 IoC 实现方式，它要求对象主动查找依赖资源，这种方式已经不再使用。 DI 定义Spring 容器在创建被调用者的实例时，会自动将调用者需要的对象实例注入给调用者，这样，调用者通过 Spring 容器获得被调用者实例，这称为依赖注入。 实现方式依赖注入主要有两种实现方式，分别是属性 setter 注入和构造方法注入 属性 setter 注入 指 IoC 容器使用 setter 方法注入被依赖的实例。通过调用无参构造器或无参 static 工厂方法实例化 bean 后，调用该 bean 的 setter 方法，即可实现基于 setter 的 DI。 构造方法注入 指 IoC 容器使用构造方法注入被依赖的实例。基于构造器的 DI 通过调用带参数的构造方法实现，每个参数代表一个依赖。 注意依赖注入（Dependency Injection，DI）和控制反转含义相同，它们是从两个角度描述的同一个概念。 AOPAOP 的定义 AOP（面向切面编程），它是利用对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 AOP 采取横向抽取机制，取代了传统纵向继承体系重复性代码（性能监视、事务管理、安全检查、缓存） AOP：面向切面编程【底层就是动态代理】，指程序在运行期间动态的将某段代码切入到指定方法位置进行的编程方式。 AOP 的优势 减少重复的代码 提供开发的效率 维护方便 AOP 体系 AOP 的使用场景日志场景 诊断上下文，如：【log4j 或 logback 】 辅助信息，如：方法执行时间 【System.currentTimeMillis()】 统计场景 方法调用次数 执行异常次数 数据抽样 数值累加 安防场景 熔断，如：【Netflix Hystrix】 限流和降级：如：【Alibaba Sentinel】 认证和授权，如：【Spring Security】 监控，如：【JMX】 性能场景 缓存，如 【Spring Cache】 超时控制 AOP 的底层原理JDK的动态代理技术（主要） 为接口创建代理类的字节码文件 使用 ClassLoader 将字节码文件加载到 JVM 创建代理类实例对象，执行对象的目标方法 AOP 的重要名词 【 Joinpoint 】连接点 所谓连接点是指那些被拦截到的点。在spring中指的是所有方法,因为spring只支持方法类型的连接点。 【 Pointcut 】切入点 （编写切入点表达式），程序增强的入口。 【 Advice 】通知/增强 对spring中方法要进行增强，编写事务管理相关代码。 【 Target 】目标对象 代理的目标对象 【 Weaving 】织入 是指把增强应用到目标对象来创建新的代理对象的过程 【 Proxy 】代理 一个类被AOP织入增强后，就产生一个结果代理类 Aspect(切面) = 切入点 + 通知 AOP 通知执行顺序执行顺序正常情况 异常情况 多个切面的情况（假设正常情况） 注意从 Spring 5.2.7 开始，Spring AOP 不再严格按照 AspectJ 定义的规则来执行 advice，而是根据其类型按照从高到低的优先级进行执行：@Around，@Before ，@After，@AfterReturning，@AfterThrowing 1、单个切面类Spring 5.28： 正常情况：around 环绕前置 ==&gt; @Before ==&gt; target 目标方法执行 ==&gt; @AfterReturning ==&gt; @After ==&gt; around 环绕返回 ==&gt; around 环绕最终 异常情况：around 环绕前置 ==&gt; @Before ==&gt; target 目标方法执行 ==&gt; @AfterThrowing ==&gt; @After ==&gt; around 环绕异常 ==&gt; around 环绕最终 2、多个切面 Spring 5.28： 正常情况：切面1环绕前置 ==&gt; 切面1@Before ==&gt; 切面2环绕前置 ==&gt; 切面2@Before ==&gt; 目标方法执行 ==&gt; 切面2@AfterReturning ==&gt; 切面2@After ==&gt; 切面2环绕返回 ==&gt; 切面2环绕最终 ==&gt; 切面1@AfterReturning ==&gt; 切面1@After ==&gt; 切面1环绕返回 ==&gt; 切面1环绕最终 异常情况：切面1环绕前置 ==&gt; 切面1@Before ==&gt; 切面2环绕前置 ==&gt; 切面2@Before ==&gt; 目标方法执行 ==&gt; 切面2@AfterThrowing ==&gt; 切面2@After ==&gt; 切面2环绕异常 ==&gt; 切面2环绕最终 ==&gt; 切面1@AfterThrowing ==&gt; 切面1@After ==&gt; 切面1环绕异常 ==&gt; 切面1环绕最终 3、@Order注解指定先后顺序数字越小，优先级越高，先进后出 举个荔枝： 123456789101112131415161718192021222324252627@Order(value = 1)@Aspect@Componentpublic class BookServiceProxy &#123;&#125; @Order(value = 0)@Aspect@Componentpublic class BookServiceProxy2 &#123;&#125;/** * 结果： * * 切面二：环绕前置通知 * 切面二：@Before * 切面一：环绕前置通知 * 切面一：@Before * 目标方法执行 * 切面一：@AfterReturning * 切面一：@After * 切面一：环绕返回通知 * 切面一：环绕最终通知 * 切面二：@AfterReturning * 切面二：@After * 切面二：环绕返回通知 * 切面二：环绕最终通知 */ 由此得出： spring aop 就是一个同心圆，要执行的方法为圆心，最外层的 order 最小。 AOP 实践AOP看起来很麻烦, 只要3步就可以了: 将业务逻辑组件和切面类都加入到容器中, 告诉spring哪个是切面类(@Aspect) 在切面类上的每个通知方法上标注通知注解, 告诉Spring何时运行(写好切入点表达式,参照官方文档) 开启基于注解的AOP模式 @EableXXXX 1、引入 Aop 的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 2、编写 Aop 切面类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081@Component@Aspect@Log4j2public class LogAspect &#123; /** * 配置切入点,该方法无方法体,主要为方便同类中其他方法使用此处配置的切入点 * 切点的集合，这个表达式所描述的是一个虚拟面（规则） * 就是为了Annotation扫描时能够拿到注解中的内容 * * * execution函数用于匹配方法执行的连接点，语法为： * execution(方法修饰符(可选) 返回类型 方法名 参数 异常模式(可选)) * 参数部分允许使用通配符： * * 匹配任意字符，但只能匹配一个元素 * .. 匹配任意字符，可以匹配任意多个元素，表示类时，必须和*联合使用 * + 必须跟在类名后面，如Horseman+，表示类本身和继承或扩展指定类的所有类 */ @Pointcut(\"execution(public * com.ase.aop.controller.*.*(..))\") public void aspect() &#123; &#125; /** * 配置环绕通知,使用在方法aspect()上注册的切入点 * * @param joinPoint */ @Around(\"aspect()\") public void around(JoinPoint joinPoint) &#123; long start = System.currentTimeMillis(); try &#123; ((ProceedingJoinPoint) joinPoint).proceed(); long end = System.currentTimeMillis(); log.info(\"around \" + joinPoint + \"\\tUse time : \" + (end - start) + \" ms!\"); &#125; catch (Throwable e) &#123; long end = System.currentTimeMillis(); log.info(\"around \" + joinPoint + \"\\tUse time : \" + (end - start) + \" ms with exception : \" + e.getMessage()); &#125; &#125; /** * 前置通知: 在目标方法()运行之前运行 (@Before) * * @param joinPoint */ @Before(\"aspect()\") public void logStart(JoinPoint joinPoint) &#123; log.info(\"before: &#123;&#125;\", joinPoint); &#125; /** * 后置通知：在目标方法()运行结束之后运行,无论正常或异常结束 (@After) * * @param joinPoint */ @After(\"aspect()\") public void logAfter(JoinPoint joinPoint) &#123; log.info(\"after: &#123;&#125;\", joinPoint); &#125; /** * 返回通知：在目标方法()正常返回之后运行 (@AfterReturning) * * @param joinPoint */ @AfterReturning(\"aspect()\") public void logAfterReturn(JoinPoint joinPoint) &#123; log.info(\"afterReturn: &#123;&#125;\", joinPoint); &#125; /** * 异常通知：在目标方法()出现异常后运行(@AfterThrowing) * * @param joinPoint */ @AfterThrowing(pointcut = \"aspect()\", throwing = \"ex\") public void logException(JoinPoint joinPoint, Exception ex) &#123; log.info(\"afterThrow: &#123;&#125;\", joinPoint); log.info(\"message: &#123;&#125;\", ex.getMessage()); &#125;&#125; 3、编写切点方法12345678910@RestControllerpublic class BaseController &#123; @GetMapping(\"/aop\") public Map&lt;String, Object&gt; api1() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16); map.put(\"nowTime\", LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); return map; &#125;&#125; 4、结果12345678[nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'[nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'[nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : Completed initialization in 0 ms[nio-8080-exec-2] com.ase.aop.config.LogAspect : before: execution(Map com.ase.aop.controller.BaseController.api1())[nio-8080-exec-2] com.ase.aop.controller.BaseController : map = &#123;nowTime=2021-07-24 20:37:05&#125;[nio-8080-exec-2] com.ase.aop.config.LogAspect : afterReturn: execution(Map com.ase.aop.controller.BaseController.api1())[nio-8080-exec-2] com.ase.aop.config.LogAspect : after: execution(Map com.ase.aop.controller.BaseController.api1())[nio-8080-exec-2] com.ase.aop.config.LogAspect : around execution(Map com.ase.aop.controller.BaseController.api1()) Use time : 16 ms! 注意JoinPoint 对象封装了 Spring Aop 中切面方法的信息,在切面方法中添加 JoinPoint 参数,就可以获取到封装了该方法信息的JoinPoint对象.。 方法名 功能 Signature getSignature() 获取封装了署名信息的对象,在该对象中可以获取到目标方法名,所属类的Class等信息 Object[] getArgs() 获取传入目标方法的参数对象 Object getTarget() 获取被代理的对象 Object getThis() 获取代理对象 使用 annotation（注解）可以定义一个注解，注解分为两部分 : ① 元注解 ; ② public @interface 注解名称 ; annotation 注解属性注解的本质是接口 , 接口中可以定义 常量 和 方法 ; 在注解中定义 接口方法 , 就是 注解的属性 ; 为注解添加属性 : 接口中的方法都是抽象方法 , 其中 public abstract 可以省略 ; 1234567@Target(ElementType.METHOD) // 注解用于字段上@Retention(RetentionPolicy.RUNTIME) // 保留到运行时，可通过注解获取@Documentedpublic @interface MyAnnotation &#123; //public abstract String path(); String path();&#125; 注解属性使用格式 : @注解名称(属性名称 = 属性值) 举个荔枝： 123@MyAnnotation(path = \"\")MyMethods(String arg)&#123;&#125; annotation 注解属性类型注解属性 ( 接口方法 ) 返回值类型要求 : ① 基本数据类型 : byte , short , int , long , float , double , char , boolean ; ② 字符串类型 : String ; ③ 枚举类型 : enum ; ④ 注解类型 ; ⑤ 以上类型的数组形式 ; 注解属性返回值必须是以上的类型 , 不能设置其它类型返回值 , 否则会报错 ; 定义 注解属性 时 , 可以 使用 default 关键字 指定属性默认值 举个荔枝：注解属性 intValue 值类型为 int 整型 , 默认值 100 1int intValue() default 100; 注意 如果 注解属性指定了默认值 , 在使用注解时 , 可以选择不为该属性赋值 ( 此时使用默认属性值 ) , 也可以进行赋值 ( 指定一个新的属性值 ) ; 如果 注解属性没有指定默认值 , 则使用注解 时 , 必须为其指定一个默认值 , 否则编译时报错 ; 如果 注解属性名称是 value , 并且 注解中只有 1 个属性 , 那么在使用注解为注解属性赋值时 , 可以省略注解名称 , 直接传入注解属性值 ; annotation 反射获取注解1234567891011121314151617181920212223242526@Log4j2@DisplayName(\"Annotation 自定义注解测试\")class MyAnnotationTest &#123; //使用我们的自定义注解 @MyAnnotation(path = \"Annotation-Aop\") private String path; @Test @DisplayName(\"自定义注解\") public void myAnnotationTest() &#123; // 获取类模板 Class c = MyAnnotationTest.class; // 获取所有字段 for (Field field : c.getDeclaredFields()) &#123; // 判断这个字段是否有MyField注解 if (field.isAnnotationPresent(MyAnnotation.class)) &#123; MyAnnotation annotation = field.getAnnotation(MyAnnotation.class); log.info(\"字段:[\" + field.getName() + \"], 描述:[\" + annotation.path() + \"]\"); &#125; &#125; &#125;&#125; 结果 1[main] INFO com.ase.aop.annotation.MyAnnotationTest - 字段:[path], 描述:[Annotation-Aop] Log 日志实践1、引入 Aop 的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 2、自定义注解12345@Target(ElementType.METHOD) // 注解用于字段上@Retention(RetentionPolicy.RUNTIME) // 保留到运行时，可通过注解获取@Documentedpublic @interface MyLog &#123;&#125; 3、编写 Aop 切面类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687@Component@Aspect@Log4j2public class LogAspect &#123; /** * 配置切入点,该方法无方法体,主要为方便同类中其他方法使用此处配置的切入点 * 切点的集合，这个表达式所描述的是一个虚拟面（规则） * 就是为了Annotation扫描时能够拿到注解中的内容 */ @Pointcut(\"@annotation(com.ase.aop.annotation.MyLog)\") public void aspect() &#123; &#125; /** * 配置环绕通知,使用在方法aspect()上注册的切入点 * * @param joinPoint */ @Around(\"aspect()\") public void around(JoinPoint joinPoint) &#123; long start = System.currentTimeMillis(); // 获取方法名称 String methodName = joinPoint.getSignature().getName(); // 获取入参 Object[] param = joinPoint.getArgs(); StringBuilder sb = new StringBuilder(); for(Object o : param)&#123; sb.append(o + \"; \"); &#125; System.out.println(\"进入[\" + methodName + \"]方法,参数为:\" + sb.toString()); // 继续执行方法 try &#123; ((ProceedingJoinPoint) joinPoint).proceed(); long end = System.currentTimeMillis(); log.info(\"around \" + joinPoint + \"\\tUse time : \" + (end - start) + \" ms!\"); &#125; catch (Throwable throwable) &#123; long end = System.currentTimeMillis(); log.info(\"around \" + joinPoint + \"\\tUse time : \" + (end - start) + \" ms with exception : \" + throwable.getMessage()); throwable.printStackTrace(); &#125; log.info(methodName , \"&#123;&#125; 方法执行结束\"); &#125; /** * 前置通知: 在目标方法(div)运行之前运行 (@Before) * * @param joinPoint */ @Before(\"aspect()\") public void logStart(JoinPoint joinPoint) &#123; log.info(\"before: &#123;&#125;\", joinPoint); &#125; /** * 后置通知：在目标方法(div)运行结束之后运行,无论正常或异常结束 (@After) * * @param joinPoint */ @After(\"aspect()\") public void logAfter(JoinPoint joinPoint) &#123; log.info(\"after: &#123;&#125;\", joinPoint); &#125; /** * 返回通知：在目标方法(div)正常返回之后运行 (@AfterReturning) * * @param joinPoint */ @AfterReturning(\"aspect()\") public void logAfterReturn(JoinPoint joinPoint) &#123; log.info(\"afterReturn: &#123;&#125;\", joinPoint); &#125; /** * 异常通知：在目标方法(div)出现异常后运行(@AfterThrowing) * * @param joinPoint */ @AfterThrowing(pointcut = \"aspect()\", throwing = \"ex\") public void logException(JoinPoint joinPoint, Exception ex) &#123; log.info(\"afterThrow: &#123;&#125;\", joinPoint); log.info(\"message: &#123;&#125;\", ex.getMessage()); &#125;&#125; 4、编写切点方法123456789101112131415161718192021@Log4j2@RestControllerpublic class BaseController &#123; @GetMapping(\"/aop\") public Map&lt;String, Object&gt; aop1() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16); map.put(\"nowTime\", LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); log.info(\"map = \" + map); return map; &#125; @MyLog @GetMapping(\"/aop2\") public Map&lt;String, Object&gt; aop2() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16); map.put(\"nowTime\", LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); log.info(\"map = \" + map); return map; &#125;&#125; 5、结果1234567进入[aop2]方法,参数为:[nio-8080-exec-1] com.ase.aop.config.LogAspect : before: execution(Map com.ase.aop.controller.BaseController.aop2())[nio-8080-exec-1] com.ase.aop.controller.BaseController : map = &#123;nowTime=2021-07-25 00:04:02&#125;[nio-8080-exec-1] com.ase.aop.config.LogAspect : afterReturn: execution(Map com.ase.aop.controller.BaseController.aop2()) [nio-8080-exec-1] com.ase.aop.config.LogAspect : after: execution(Map com.ase.aop.controller.BaseController.aop2())[nio-8080-exec-1] com.ase.aop.config.LogAspect : around execution(Map com.ase.aop.controller.BaseController.aop2()) Use time : 17 ms![nio-8080-exec-1] com.ase.aop.config.LogAspect : aop2方法执行结束 注意在编写的切点方法中只有标注了自定义的注解 MyLog 的 aop2 切点方法才会被 Aop 切面所处理","categories":[{"name":"框架","slug":"框架","permalink":"https://yugd.cn/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://yugd.cn/tags/Spring/"}]},{"title":"每日一面--TCP 3次挥手与4次握手","slug":"面试--HTTP3次挥手与4次握手","date":"2021-06-16T13:58:58.000Z","updated":"2022-05-26T18:17:03.987Z","comments":true,"path":"posts/4046/","link":"","permalink":"https://yugd.cn/posts/4046/","excerpt":"每天一篇面试小知识 本篇着重介绍一下 TCP 3次挥手与4次握手 ： 但不局限于介绍 TCP~ HTTP划重点 HTTP协议是基于TCP/IP的应用层协议 写在前面无论是 Java、PHP 开发者，还是运维人员，只要从事互联网行业，面试时都可能被问到 HTTP 协议相关知识。 那么要弄清楚 http 的相关知识必需要先来了解一下 http 的 7 层模型。","text":"每天一篇面试小知识 本篇着重介绍一下 TCP 3次挥手与4次握手 ： 但不局限于介绍 TCP~ HTTP划重点 HTTP协议是基于TCP/IP的应用层协议 写在前面无论是 Java、PHP 开发者，还是运维人员，只要从事互联网行业，面试时都可能被问到 HTTP 协议相关知识。 那么要弄清楚 http 的相关知识必需要先来了解一下 http 的 7 层模型。 OSI 七层模型 由上至下依次为：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。 应用层HTTP 头部包含哪些信息HTTP 头部本质上是一个传递额外重要信息的键值对。主要分为：通用头部，请求头部，响应头部和实体头部。 下面重点来说一下我们熟悉的 “实体头部” 协议头 说明 举例 Allow 对某网络资源的有效的请求行为，不允许则返回405 Allow: GET, HEAD Content-encoding 返回内容的编码方式 Content-Encoding: gzip Content-Length 返回内容的字节长度 Content-Length: 348 Content-Language 响应体的语言 Content-Language: en,zh Content-Location 请求资源可替代的备用的另一地址 Content-Location: /index.htm Content-MD5 返回资源的MD5校验值 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Range 在整个返回体中本部分的字节位置 Content-Range: bytes 21010-47021/47022 Content-Type 返回内容的MIME类型 Content-Type: text/html; charset=utf-8 Expires 响应过期的日期和时间 Expires: Thu, 01 Dec 2010 16:00:00 GMT Last-Modified 请求资源的最后修改时间 Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT POST 和 Get 的区别我们知道，HTTP定义了与服务器进行交互的不同方法，常见的有四种：GET、POST、PUT、DELETE。其中，GET 和 POST 最常用。 GET 用来获取资源，它只是获取、查询数据，不会修改服务器的数据。 POST 则是可以向服务器发送修改请求，进行数据的修改的。 从性能角度 post 携带的请求头更多； 握手次数 post：get （6 : 4）； get 保存数据（Ajax），post则不会； 从安全角度 post 更加的安全（请求数据不会作为 url 的一部分，缓存、日志等） post 发送的数据量更大，get 有 url 的长度限制； post 发送的更多的数据类型 ， get 只能是 ASCLL； 注意我们常说的一些区别都是一些表面上的。 比如：GET没有POST安全；GET请求时URL的长度是有限制的；GET没有body而POST有body等等。 这些都是针对浏览器中的要求， 在使用HTTP作为接口进行传输时，就没有这么多条条框框了。 此时GET和POST只是HTTP协议中的两种请求方式，而HTTP协议是基于TCP/IP的应用层协议， 无论GET还是POST，用的都是同一个传输层协议，所以在传输上没有区别。 GET也可以有body，POST也不一定非要使用body HTTP 和 HTTPS 的区别HTTP 和 HTTPS 的区别有哪些？ 最明显直观的就是在网页上访问网址，地址栏位的 url 显示区别 如果是 http 请求，则显示为不安全 如果是 https 请求，则显示为安全 什么是HTTP?超文本传输协议，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据。 HTTP报文格式 什么是HTTPS?HTTPS = SSL + HTTP HTTPS是一种通过计算机网络进行安全通信的传输协议，经由HTTP进行通信，利用SSL/TLS建立全信道，加密数据包。HTTPS使用的主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。 特点Http： 无状态 【是指协议对于交互性场景没有记忆能力、cookie / session 让服务器有记忆能力】 无连接 【限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接】 基于请求和响应 简单快速 使用明文通信（不会确认通信方） Https: 通过 SSL / TLS 提供加密 对比 Https更加的安全 Https需要申请证书 端口不同：http =&gt; 80； https =&gt; 443； 状态不同：http =&gt; 无状态； https =&gt; 协议加密； HTTP通信传输 传输层TCP三次握手三次握手经典图例（客户端请求服务端获取数据） 图中单词解释： 【seq】序号 【ack】确认序号 【SYN】同步 【ACK】确认 三次握手 第一次握手：客户端首先向服务端发送请求，tcp 报文头中发送标识 SYN=1 (SYN表示客户端请求跟服务端建立连接),序号 Seq=x。 第二次握手：服务端在接收到客户端发送的请求之后，需要告诉客户端已收到请求，tcp 报文头中发送标识SYN=1,ACK=1(SYN表示服务端请求跟客户端建立连接，ACK 表示对客户端的连接请求进行应答),序号 Seq=y,确认号=x+1（表示对客户端发送的序号Seq=x的请求进行确认）。 第三次握手：客户端在接收到服务端发送的请求和确认信息之后，同样需要告诉服务端已收到信息，tcp 报文头中发送标识 ACK=1(ACK表示对服务端的连接请求进行应答),序号 Seq=x+1，确认号 Ack=y+1（表示对服务端发送的序号 Seq=y 的请求进行确认） 当三次握手都成功的时候，我们发现此时客户端发送的信息服务端能够收到并且服务端发送的信息客户端也能收到，通信双方连接成功。 注意 发送请求中的发送标识SYN、ACK表示的是发送报文中两个标识位！而Seq和Ack分别代表发送序号和确认号。 服务端在接收到了客户端的连接请求后，回复中同时发送了SYN、ACK两个标识位，将建立连接的请求和对客户端的确认应答在同一个数据包中发送了，这也是为什么只需要三次握手，就能建立连接 TCP四次挥手当客户端和服务端之间的数据传输完毕之后，我们就需要释放连接（一直建立连接会浪费资源），那为啥需要四次挥手呢？ 四次挥手经典图例 图中单词解释： 【MSL】报文最大生存时间 （它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃） 四次挥手 第一次挥手：客户端向服务端发送断开连接的请求，告诉服务端我这边不需要再请求你的数据了，tcp报文头中发送标识FIN=1（表示客户端请求跟服务端断开连接）,序号Seq=u 第二次挥手：服务端在接收到客户端发送的断开请求后，需告诉客户端已收到请求，tcp报文头中发送标识ACK=1(ACK表示对客户端的断开连接的请求进行应答),序号Seq=v,确认号Ack=u+1（表示对客户端发送的序号Seq=u的请求进行确认）。 第三次挥手：当服务端数据传输完毕之后，向客户端发起断开连接的请求，告诉客户端我这边也不需要再发送数据了，tcp报文头中发送标识FIN=1，ACK=1(FIN表示服务端请求跟客户端断开连接，ACK表示对上一次客户端的断开连接的请求进行应答),序号Seq=w,确认号Ack=u+1（表示对客户端发送的序号Seq=u的请求进行确认） 第四次挥手：客户端接收到服务发送的断开连接请求后，需告诉服务端已收到信息，作出应答，tcp报文头中发送标识ACK=1(ACK表示对服务端的断开连接的请求进行应答),序号Seq=u+1,确认号Ack=w+1（表示对服务端发送的序号Seq=w的请求进行确认） 1. 为什么不能像握手的时候一样三次握手，为啥需要四次挥手呢？ 答：在实际的网络中，服务端在接收到客户端断开连接的请求的时候，此时服务端可能还有数据没有传输完毕，不能立即向客户端发送断开连接的请求！ 当客户端主动发起断开请求的时候，服务器先回应一个确认，等所有数据传输完毕后再发送服务器断开的请求。 2. 为什么需要维持2MSL呢？ 答：第4次挥手的时候客户端向服务端发送断开连接的请求的确认ACK，如果客户端发送完成后就直接就关闭连接，如果由于网络原因服务端没有收到ACK，那服务端就没法关闭连接了！ 因此客户端在回复确认后，还需要等待，万一服务端没有收到应答还会继续发送断开连接的请求； TCP 长连接和短连接长连接： 所谓长连接，指在一个TCP连接上可以连续发送多个数据包，在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持（不发生RST包和四次挥手）。 短连接： 短连接是指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接（管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段）； 应用场景： 长连接多用于操作频繁（读写），点对点的通讯，而且连接数不能太多情况。 例如： 数据库的连接用长连接（如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费） 微信，QQ 之类的即时通讯（文本消息、语音消息、视频消息、图片消息）。 短连接多用于 WEB 网站的 http 服务。 因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源。 UDP协议无连接协议，也称透明协议，也位于传输层。 UDP 与 TCP 区别： TCP 提供面向连接的传输，通信前要先建立连接（三次握手机制）； UDP 提供无连接的传输，通信前不需要建立连接。 TCP 提供可靠的传输（有序，无差错，不丢失，不重复）； UDP 提供不可靠的传输。 TCP 面向字节流的传输，因此它能将信息分割成组，并在接收端将其重组； UDP 是面向数据报的传输，没有分组开销。 TCP 提供拥塞控制和流量控制机制； UDP 不提供拥塞控制和流量控制机制。 对比 UDP TCP 是否连接 无连接 面向连接 是否可靠 不可靠传输，不使用流量控制和拥塞控制 可靠传输，使用流量控制和拥塞控制 连接对象个数 支持一对一，一对多，多对一和多对多交互通信 只能是一对一通信 传输方式 面向报文 面向字节流 首部开销 首部开销小，仅8字节 首部最小20字节，最大60字节 适用场景 适用于实时应用（IP电话、视频会议、直播等） 适用于要求可靠传输的应用，例如文件传输 网络层IPIP协议（Internet Protocol，互联网协议），是TCP/IP协议栈中最核心的协议之一，通过IP地址，保证了联网设备的唯一性，实现了网络通信的面向无连接和不可靠的传输功能。 IP 就是一张身份证，存在于电脑、手机、监控摄像头、汽车等任何需要联网的设备上面； IP 是可以被追踪到和定位的； 面试的时候有面试官聊到关于网络相关考点，于是问道： 能说出访问一个网页的全过程？ 答：打开浏览器，在地址栏输入URL，回车，出现网页内容。 太笼统了，要具体！ 在地址栏输入URL后，整个过程发生了什么？其中的原理是什么？ 答：整个过程可以概括为几下几个部分： 通过解析域名找到 IP，如果缓存里没有就要请求 DNS 服务器得到 IP 地址； 与目的主机进行 TCP 连接（三次握手）构建 HTTP 请求； 发送与收取数据（浏览器与目的主机开始HTTP访问过程）； 与目的主机断开 TCP 连接（四次挥手）； DNS能简单说说域名解析？并且一个域名可以对应多个IP地址吗？ 域名通过 DNS 解析 得到 IP 首先得知道啥是 DNS ？ DNS（Domain Name System）是因特网的一项服务，它作为域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网。 作用 解析域名 人们在通过浏览器访问网站时只需要记住网站的域名即可，而不需要记住那些不太容易理解的IP地址。 在DNS系统中有一个比较重要的的资源类型叫做主机记录也称为A记录，A记录是用于名称解析的重要记录，它将特定的主机名映射到对应主机的IP地址上。 负载均衡 DNS除了能解析域名之外还具有负载均衡的功能。 由上图可以看出，在 DNS 服务器中应该配置了多个A记录 123www.apusapp.com IN A 114.100.20.201;www.apusapp.com IN A 114.100.20.202;www.apusapp.com IN A 114.100.20.203; 每次域名解析请求都会根据对应的负载均衡算法计算出一个不同的IP地址并返回，这样A记录中配置多个服务器就可以构成一个集群，并可以实现负载均衡。 一个域名可以对应多个IP地址。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://yugd.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"每日一面--锁（Lock）","slug":"面试--锁","date":"2021-06-15T13:58:58.000Z","updated":"2022-05-26T18:16:46.274Z","comments":true,"path":"posts/29556/","link":"","permalink":"https://yugd.cn/posts/29556/","excerpt":"每天一篇 Java 小知识 本篇着重介绍一下 Java 中的锁： 写在前面面试中我们都会遇到一个场景： 在某某某并发场景下，我们为了保证线程的安全性，应该如何处理呢？ 很多人脑海里最先想到的一定是“加锁”。 提到锁，大家肯定想到的是 sychronized 关键字，用它可以解决一切并发问题。 除了使用 sychronized 关键字，还有其他的解决方案吗？ JDK 1.5 之前，使用 synchronized 关键字，拿到 Java 对象的锁，保护锁定的代码块。JVM 保证同一时刻只有一个线程可以拿到这个 Java 对象的锁，执行对应的代码块。 JDK 1.5 开始，引入了并发工具包 java.util.concurrent.locks.Lock，让锁的功能更加丰富。 下面我们来详细的介绍一下 “锁”","text":"每天一篇 Java 小知识 本篇着重介绍一下 Java 中的锁： 写在前面面试中我们都会遇到一个场景： 在某某某并发场景下，我们为了保证线程的安全性，应该如何处理呢？ 很多人脑海里最先想到的一定是“加锁”。 提到锁，大家肯定想到的是 sychronized 关键字，用它可以解决一切并发问题。 除了使用 sychronized 关键字，还有其他的解决方案吗？ JDK 1.5 之前，使用 synchronized 关键字，拿到 Java 对象的锁，保护锁定的代码块。JVM 保证同一时刻只有一个线程可以拿到这个 Java 对象的锁，执行对应的代码块。 JDK 1.5 开始，引入了并发工具包 java.util.concurrent.locks.Lock，让锁的功能更加丰富。 下面我们来详细的介绍一下 “锁” Java 的主流锁都有哪些 悲观锁、乐观锁、自旋锁、偏向锁、轻量级锁、重量级锁、公平锁、非公平锁、可重入锁、非可重入锁。 1、乐观锁 VS 悲观锁顾名思义，两种锁的名字分别体现了看待线程同步的不同角度。 对于同一个数据的并发操作： 悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。 乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。 总结 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 代码看下乐观锁和悲观锁的调用方式示例： 123456789101112131415161718192021222324252627282930public class Lock &#123; // ------------------------- 悲观锁的调用方式 ------------------------- // 1、synchronized public synchronized void testMethod() &#123; // 操作同步资源 &#125; // 2、ReentrantLock // 需要保证多个线程使用的是同一个锁 private ReentrantLock lock = new ReentrantLock(); public void modifyPublicResources() &#123; //防止因为没有获取到锁的情况，finally中lock.unlock()去释放锁，导致出错！ lock.lock(); try &#123; // 操作同步资源 &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; // ------------------------- 乐观锁的调用方式 ------------------------- // 需要保证多个线程使用的是同一个AtomicInteger private AtomicInteger atomicInteger = new AtomicInteger(); public void optimistic()&#123; atomicInteger.incrementAndGet(); //执行自增1 &#125;&#125; 可以发现悲观锁基本都是在显式的锁定之后再操作同步资源，而乐观锁则直接去操作同步资源。 为何乐观锁能够做到不锁定同步资源也可以正确的实现线程同步呢？ 答：乐观锁的主要实现方式 “CAS” 的技术原理实现。 CASCAS 全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。 java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。 CAS算法涉及到三个操作数： 需要读写的内存值 V。 进行比较的值 A。 要写入的新值 B。 当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。所以对于乐观锁，“更新”是一个不断重试的操作。 那么我们进入原子类 AtomicInteger 的源码，看一下 AtomicInteger 的定义： 根据定义我们可以看出各属性的作用： unsafe： 获取并操作内存的数据。 valueOffset： 存储 value 在 AtomicInteger 中的偏移量。 value： 存储 AtomicInteger 的 int 值，该属性需要借助 volatile 关键字保证其在线程间是可见的。 CAS虽然很高效，但是它也存在三大问题 ABA问题 循环时间长开销大 只能保证一个共享变量的原子操作 解决ABA问题加标志位，例如搞个⾃增的字段，操作⼀次就⾃增加⼀，或者搞个时间戳，⽐较时间戳的值。 举个栗⼦：现在我们去要求操作数据库，根据CAS的原则我们本来只需要查询原本的值就好了，现在我 们⼀同查出他的标志位版本字段vision。 12update table set value &#x3D; newValue where value &#x3D; #&#123;oldValue&#125;# oldValue就是我们执⾏前查询出来的值 带版本号能防⽌ABA的修改： 123update table set value &#x3D; newValue ，vision &#x3D; vision + 1 where value &#x3D; #&#123;oldValue&#125; and vision &#x3D; #&#123;vision&#125;# 判断原来的值和版本号是否匹配，中间有别的线程修改，值可能相等，但是版本号100%不⼀样 2、自旋锁 VS 适应性自旋锁为什么要有自旋锁和适应性自旋锁？ 首先，阻塞或唤醒一个 Java 线程需要操作系统切换 CPU 状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。 在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。 自旋锁我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。 虽然自旋锁有效的避免了因线程之间的切换而产生的开销，但是也并非没有缺点。 缺点就是它不能代替阻塞。而且它要占用处理器时间。 如果锁被占用的时间很短，自旋等待的效果就会非常好。 如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。 所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次）没有成功获得锁，就应当挂起线程。 自旋锁的实现原理同样也是CAS。 AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。 适应性自旋锁自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。 如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。、 3、无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁这四种锁是指锁的状态，专门针对synchronized的。 无锁 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 偏向锁 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 轻量级锁 是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 重量级锁 升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 4、公平锁 VS 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。 优点：等待锁的线程不会饿死。 缺点：整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。 优点：可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。 缺点：处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。 但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示： ReentrantLock的源码来看一下公平锁和非公平锁 5、可重入锁 VS 非可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。 Java中ReentrantLock和synchronized都是可重入锁。 可重入锁的一个优点是可一定程度避免死锁。 代码1234567891011public class Lock &#123; // ------------------------- 可重入锁 ------------------------- public synchronized void doSomething() &#123; System.out.println(\"方法1执行...\"); doOthers(); &#125; public synchronized void doOthers() &#123; System.out.println(\"方法2执行...\"); &#125;&#125; 类中的两个方法都是被内置锁 synchronized 修饰的，doSomething() 方法中调用 doOthers() 方法。因为内置锁是可重入的，所以同一个线程在调用 doOthers() 时可以直接获得当前对象的锁，进入 doOthers() 进行操作。 如果是一个不可重入锁，那么当前线程在调用 doOthers() 之前需要将执行 doSomething() 时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。 为什么可重入锁就可以在嵌套调用时可以自动获得锁呢？ 有多个人在排队打水，此时管理员允许锁和同一个人的多个水桶绑定。这个人用多个水桶打水时，第一个水桶和锁绑定并打完水之后，第二个水桶也可以直接和锁绑定并开始打水，所有的水桶都打完水之后打水人才会将锁还给管理员。这个人的所有打水流程都能够成功执行，后续等待的人也能够打到水。这就是可重入锁。 但如果是非可重入锁的话，此时管理员只允许锁和同一个人的一个水桶绑定。第一个水桶和锁绑定打完水之后并不会释放锁，导致第二个水桶不能和锁绑定也无法打水。当前线程出现死锁，整个等待队列中的所有线程都无法被唤醒。 6、独享锁 VS 共享锁独享锁（排他锁）和共享锁同样是一种概念。 独享锁是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。 共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 ReentrantReadWriteLock 有两把锁： ReadLock WriteLock 由词知意，一个读锁一个写锁，合称“读写锁” 最终发现在 ReentrantLock 虽然有公平锁和非公平锁两种，但是它们添加的都是独享锁。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"锁","slug":"锁","permalink":"https://yugd.cn/tags/%E9%94%81/"}]},{"title":"【JVM系列】-- JVM垃圾回收机制","slug":"JVM系列--JVM垃圾回收机制","date":"2021-06-13T15:58:58.000Z","updated":"2022-05-26T18:19:41.917Z","comments":true,"path":"posts/26971/","link":"","permalink":"https://yugd.cn/posts/26971/","excerpt":"写在前面 为啥要写这篇文章呢？还要从很久之前的一次问答说起！ 什么是 Java 垃圾回收机制？（ JC 哥问我） 我：就是收集一些不被用到的对象，然后集中销毁吧~ 那应该如何来判断那些对象不被用到呢？ 我：好像是 … … 我真的不知道 仔细想想 我：莫非是判断此对象有没有它的引用？或者说有没有指针指向它？ 我就说嘛，想想能知道的，继续 我：继续不下去了，按照我做前端的经验，难道是通过价格标志位来判断的？ 是个办法，具体呢？ 我：xxx xxx … … 最后，我还是决定回去好好看一下相关的知识吧！（算是感谢他对于我的帮助） 本篇着重介绍一下JVM垃圾回收机制：","text":"写在前面 为啥要写这篇文章呢？还要从很久之前的一次问答说起！ 什么是 Java 垃圾回收机制？（ JC 哥问我） 我：就是收集一些不被用到的对象，然后集中销毁吧~ 那应该如何来判断那些对象不被用到呢？ 我：好像是 … … 我真的不知道 仔细想想 我：莫非是判断此对象有没有它的引用？或者说有没有指针指向它？ 我就说嘛，想想能知道的，继续 我：继续不下去了，按照我做前端的经验，难道是通过价格标志位来判断的？ 是个办法，具体呢？ 我：xxx xxx … … 最后，我还是决定回去好好看一下相关的知识吧！（算是感谢他对于我的帮助） 本篇着重介绍一下JVM垃圾回收机制： Java垃圾回收机制在 java 中，程序员是不需要显示的去释放一个对象的内存的，而是由虚拟机自行执行。 在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫描那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。 回去好好看一下什么是 GC ，那GC 是什么？ GC 是什么？为什么要 GCGC 垃圾收集（Gabage Collection），内存处理是编程人员容易出现问题的地方，忘记或者错误的内存。 不当的回收可能会导致程序或系统的不稳定甚至崩溃，Java 提供的 GC 功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java 语言没有提供释放已分配内存的显示操作方法。 对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。 首先来看一下 Java 中都有哪些引用类型吧 Java 中的引用类型 强引用：发生 gc 的时候不会被回收。 软引用：有用但不是必须的对象，在发生内存溢出之前会被回收。 弱引用：有用但不是必须的对象，在下一次GC时会被回收。 虚引用（幽灵引用/幻影引用）：无法通过虚引用获得对象，用 PhantomReference 实现虚引用，虚引用的用途是在 gc 时返回一个通知。 我之前说通过标记位（flag）来判断对象是否被引用，算是说对了一点点吧 如何判断对象是否可以被回收？什么时候被回收？一般有两种方法来判断： 引用计数器法为每个对象创建一个引用计数，有对象引用时计数器 +1，引用被释放时计数 -1，当计数器为 0 时就可以被回收。但是他有一个缺点是不能解决循环引用的问题。 可达性分析算法从 GC Roots 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是可以被回收的。 当对象对当前使用这个对象的应用程序变得不可触及的时候，这个对象就可以被回收了。 说了这么多，既然是算法都分别有哪些呢？ JVM 的垃圾回收算法？ 标记-清除算法 标记-复制算法 标记-整理算法 分代-收集算法 标记-清除算法（mark-sweep）原理该算法分为两个阶段，标记和清除。 标记阶段标记所有需要回收的对象，清除阶段回收被标记的对象所占用的空间。 优点执行速度快 缺点 执行效率不稳定，大量的标记、清除 内存碎片严重化，后续可能发生对象不能找到利用空间的问题 标记-复制算法（mark-cope）标记-复制算法也称为【半区复制】 原理按内存容量将内存划分为等大小的两块。 每次只使用其中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用的内存清掉。 优点内存连续 缺点内存使用率不高，只有原来的一半，浪费内存空间 标记-整理算法（mark-compact）原理改进于标记-标记-清除算法，通过标记后将存活的对象移动向内存的一端，然后清除端边界外的对象。 优点保证了内存的连续性，不会浪费内存。 缺点 效率低（需要移动内存对象） 移动时会有并发问题。 重点说一下分代-收集算法 分代-收集算法（generation-collect）原理根据对象存活周期的不同将内存划分为几块，一般是新生代和老年代，新生代基本采用标记-复制算法，老年代采用标记-整理算法和标记-清除算法。 新生代每次垃圾回收大偶会后大批的对象死去，每次回收存活后的少量对象在阈值将去到老年代。 回收对象优先在 Eden 区分配： 多数情况，对象都在新生代 Eden 区分配。 当 Eden 区分配没有足够的空间进行分配时，虚拟机将会发起一次 Minor GC。 如果本次 GC 后还是没有足够的空间，则将启用分配担保机制在老年代中分配内存。 Minor GC 是指发生在新生代的 GC，因为 Java 对象大多都是朝生夕死，所有 Minor GC 非常频繁，一般回收速度也非常快； Major GC/Full GC 是指发生在老年代的 GC，出现了 Major GC 通常会伴随至少一次 Minor GC。Major GC 的速度通常会比 Minor GC 慢 10 倍以上。 大对象直接进入老年代 新生代使用的是标记-清除算法来处理垃圾回收的，如果大对象直接在新生代分配就会导致 Eden 区和两个 Survivor 区之间发生大量的内存复制。 所谓大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组。 大对象对虚拟机的内存分配来说就是一个坏消息，经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来 “安置” 它们。 虚拟机提供了一个XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配，这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制（新生代采用的是复制算法）。 长期存活对象将进入老年代 虚拟机采用分代收集的思想来管理内存，那么内存回收时就必须判断哪些对象应该放在新生代，哪些对象应该放在老年代。 因此虚拟机给每个对象定义了一个对象年龄的计数器，如果对象在 Eden 区出生，并且能够被 Survivor 容纳，将被移动到 Survivor 空间中，这时设置对象年龄为 1。 对象在 Survivor 区中每过一次 Minor GC 年龄就加 1，当年龄达到一定程度（默认 15） 就会被晋升到老年代。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://yugd.cn/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://yugd.cn/tags/Java/"},{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"}]},{"title":"【JVM系列】-- JVM内存结构","slug":"JVM系列--JVM内存结构","date":"2021-06-13T14:58:58.000Z","updated":"2022-12-15T07:24:20.976Z","comments":true,"path":"posts/43345/","link":"","permalink":"https://yugd.cn/posts/43345/","excerpt":"什么是JVM？ 百度词条： 123JVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机)，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。引入Java语言虚拟机后，Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。 本篇着重介绍一下JVM内存结构：","text":"什么是JVM？ 百度词条： 123JVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机)，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。引入Java语言虚拟机后，Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。 本篇着重介绍一下JVM内存结构： JVM内存模型结构图 JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配； 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。 线程与进程： 同步于线程：程序计数器、虚拟机栈、本地方法栈 同步于进程：方法区、堆 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。唯一一个不会出现Stack Overflow Error 的地方。 JVM栈与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 本地方法栈本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。 方法区方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 堆1、对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。几乎所有的对象实例都在这里分配内存。 2、Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。 控制参数 -Xms设置堆的最小空间大小。 -Xmx设置堆的最大空间大小。 -XX:NewSize设置新生代最小空间大小。 -XX:MaxNewSize设置新生代最大空间大小。 -XX:PermSize设置永久代最小空间大小。 -XX:MaxPermSize设置永久代最大空间大小。 -Xss设置每个线程的堆栈大小。 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。 老年代空间大小=堆空间大小-年轻代大空间大小 内存结构相关包含","categories":[{"name":"JVM","slug":"JVM","permalink":"https://yugd.cn/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://yugd.cn/tags/Java/"},{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"}]},{"title":"【JVM系列】-- Java的类加载机制","slug":"JVM系列--Java的类加载机制","date":"2021-06-13T13:58:58.000Z","updated":"2021-10-26T14:26:00.098Z","comments":true,"path":"posts/8906/","link":"","permalink":"https://yugd.cn/posts/8906/","excerpt":"什么是JVM？百度词条： 123JVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机)，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。引入Java语言虚拟机后，Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。 本篇着重介绍一下Java的类加载机制：","text":"什么是JVM？百度词条： 123JVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机)，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。引入Java语言虚拟机后，Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。 本篇着重介绍一下Java的类加载机制： 什么是类的加载类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个 java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的 Class对象， Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误 加载.class文件的方式 从本地系统中直接加载 通过网络下载.class文件 从zip，jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件 类的生命周期加载的过程包括了加载、验证、准备、解析、初始化五个阶段。 加载 查找并加载类的二进制数据加载时类加载过程的第一个阶段，在加载阶段获取类的二进制字节流的动作是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个 java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 验证：确保被加载的类的正确性 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 准备：为类的 静态变量分配内存，并将其初始化为默认值 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。 解析：把类中的符号引用转换为直接引用 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 初始化 初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式： ①声明类变量是指定初始值 ②使用静态代码块为类变量指定初始值 结束生命周期 在如下几种情况下，Java虚拟机将结束生命周期 执行了 System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 双亲委派模型定义 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://yugd.cn/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://yugd.cn/tags/Java/"},{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"}]},{"title":"每日一面--HashMap红黑树","slug":"面试--HashMap红黑树","date":"2021-06-13T13:58:58.000Z","updated":"2022-05-26T18:17:01.994Z","comments":true,"path":"posts/3472/","link":"","permalink":"https://yugd.cn/posts/3472/","excerpt":"每天一篇 Java 小知识 本篇着重介绍一下 HashMap为什么用红黑树： 写在前面上文说到，HashMap的扩容原理。 JDK1.7 使用的是 数组 + 单链表 的数据结构。 JDK1.8 及之后时，使用的是数组+链表+红黑树的数据结构。 当阈值是默认阈值 0.75，链表的深度大于等于 8，数组容量大于等于 64 时，扩容的时候会把链表转成红黑树，时间复杂度从 O(n) 变成 O(logN)；当红黑树的节点深度小于等于 6 时，红黑树会转为链表结构。 在Java8中为什么要使用红黑树来实现的HashMap？ 答：好处就是避免在最极端的情况下冲突链表变得很长很长，在查询的时候，效率会非常慢。（单向链表）","text":"每天一篇 Java 小知识 本篇着重介绍一下 HashMap为什么用红黑树： 写在前面上文说到，HashMap的扩容原理。 JDK1.7 使用的是 数组 + 单链表 的数据结构。 JDK1.8 及之后时，使用的是数组+链表+红黑树的数据结构。 当阈值是默认阈值 0.75，链表的深度大于等于 8，数组容量大于等于 64 时，扩容的时候会把链表转成红黑树，时间复杂度从 O(n) 变成 O(logN)；当红黑树的节点深度小于等于 6 时，红黑树会转为链表结构。 在Java8中为什么要使用红黑树来实现的HashMap？ 答：好处就是避免在最极端的情况下冲突链表变得很长很长，在查询的时候，效率会非常慢。（单向链表） 什么是红黑树呢？别急，先来回顾一下什么是二叉树！ 二叉树简单地理解，满足以下两个条件的树就是二叉树： 本身是有序树； 树中包含的各个节点的度不能超过 2，即只能是 0、1 或者 2； 二叉树还可以继续分类，衍生出满二叉树和完全二叉树。 满二叉树如果二叉树中除了叶子结点，每个结点的度都为 2，则此二叉树称为满二叉树。 完全二叉树如果二叉树中除去最后一层节点为满二叉树，且最后一层的结点依次从左到右分布，则此二叉树被称为完全二叉树。 完全二叉树 非完全二叉树 好了说完二叉树相关的知识后，还没有引入红黑树，因为在不断优化的过程中还是需要慢慢来，回顾一下平衡二叉树（AVL Tree）。 二叉查找树二叉树具有以下性质：左子树的键值小于根的键值，右子树的键值大于根的键值。 对二叉树的节点进行查找发现深度为 1 的节点的查找次数为 1，深度为2的查找次数为 2，深度为n的节点的查找次数为n，因此其平均查找次数为 (1+2+2+3+3+3) / 6 = 2.3 次 当然上面是理想的情况，因为二叉查找树可以任意地构造，同样是 2,3,5,6,7,8 这六个数字，也可以按照下图的方式来构造。 但是这棵二叉树的查询效率就低了。因此若想二叉树的查询效率尽可能高，需要这棵二叉树是平衡的，从而引出新的定义——平衡二叉树，或称 AVL 树。 平衡二叉树（AVL Tree）平衡二叉树（AVL树）在符合二叉查找树的条件下，还满足任何节点的两个子树的高度最大差为1。 AVL树，它的任何节点的两个子树的高度差&lt;=1； AVL树 不是AVL树，其根节点的左子树高度为3，而右子树高度为1； 非AVL树 至此，引出红黑树(弱平衡二叉树) 红黑树(弱平衡二叉树)红黑树也属于平衡二叉树，但在每个节点增加一个存储位表示节点的颜色，非红即黑。 红黑树的英文是“Red-Black Tree”，简称R-B Tree。它是一种不严格的平衡二叉查找树，我前面说了，它的定义是不严格符合平衡二叉查找树的定义的。 顾名思义，红黑树中的节点，一类被标记为黑色，一类被标记为红色除此之外，一棵红黑树还需要满足这样几个要求： 性质1：每个节点要么是黑色，要么是红色。 性质2：根节点是黑色。 性质3：每个叶子节点（NIL）是黑色。 性质4：每个红色结点的两个子结点一定都是黑色。 性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 从性质5又可以推出：如果一个结点存在黑子结点，那么该结点肯定有两个子结点 B树（Balance-Tree）B树是一颗多路平衡查找树 它类似普通的平衡二叉树，不同的一点是B 树允许每个节点有更多的子节点。 B 树有如下特点: 所有键值分布在整颗树中（索引值和具体data都在每个节点里）； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束（最好情况 O(1) 就能找到数据）； 在关键字全集内做一次查找,性能逼近二分查找； B 树是专门为外部存储器设计的。如磁盘，它对于读取和写入大块数据有良好的性能，所以一般被用在文件系统及数据库中。 B 树允许每个节点有更多的子节点即可（多叉树）。子节点数量一般在上千，具体数量依赖外部存储器的特性。 B+树（ Balance+Tree）B+Tree是在B Tree基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用B+Tree实现其索引结构。 B+Tree相对于B Tree有几点不同： 非叶子节点只存储键值信息； 所有叶子节点之间都有一个链指针； 数据记录都存放在叶子节点中；（查询时间复杂度固定为 log n） 通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。 咋一看 B+ 树好像查询要比 B 树慢一些（同样的数据，查询【IO】次数变多了），但是是事实如此吗？ 根据空间局部性原理：如果一个存储器的某个位置被访问，那么将它附近的位置也会被访问。 B+ 树可以很好的利用局部性原理，若我们访问节点 key为 80，则 key 为 79、83、87的节点将来也可能被访问，磁盘预读原理就会提前把这些数据都读进内存，使得范围查询和排序都很快，从而减少了磁盘 IO 的次数。 由于B树的节点都存了 key 和 data ，而 B+ 树只有叶子节点存 data，非叶子节点都只是索引值，没有实际的数据，这就时 B+ 树在一次IO里面，能读出的索引值更多。从而减少查询时候需要的IO次数！ B+ 树优势： B+ 树叶节点两两相连可大大增加区间访问性； B+ 树更适合外部存储。由于内节点无 data 域，每个节点能索引的范围更大更精确； 拓展：MySQL 为什么使用 B Tree（B+Tree）存储？ 这就是下篇博客要着重介绍的东西咯~ 我好像发现通过一个 hashmap 能够牵扯出一连串的知识啊！ 这可能就是它的知识体系吧，正如我们在面试的过程中，面试官通过一个”点“，问着问着就问出来一个“面”。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"HashMap","slug":"HashMap","permalink":"https://yugd.cn/tags/HashMap/"}]},{"title":"排序总结（Sort Algorithm）","slug":"排序--总结","date":"2021-06-12T15:58:58.000Z","updated":"2022-05-26T18:18:06.887Z","comments":true,"path":"posts/9706/","link":"","permalink":"https://yugd.cn/posts/9706/","excerpt":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重为排序做个总结： 什么是排序算法？排序也称排序算法(Sort Algorithm)，排序是将一组数据，依指定的顺序进行排列的过程。","text":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重为排序做个总结： 什么是排序算法？排序也称排序算法(Sort Algorithm)，排序是将一组数据，依指定的顺序进行排列的过程。 算法分类 算法总结 解释说明 稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面 （相等不交换位置）； 不稳定：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面（相等交换位置）； 内排序：所有排序操作都在内存中完成； 外排序：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行； 时间复杂度： 一个算法执行所耗费的时间； 空间复杂度：运行完一个程序所需内存的大小； 比较和非比较的区别快速排序、归并排序、堆排序、冒泡排序 等属于 比较排序 计数排序、基数排序、桶排序 则属于 非比较排序 比较排序：在排序的最终结果里，元素之间的次序依赖于它们之间的比较。每个数都必须和其他数进行比较，才能确定自己的位置 非比较排序：非比较排序是通过确定每个元素之前，应该有多少个元素来排序。针对数组arr，计算arr[i]之前有多少个元素，则唯一确定了arr[i]在排序后数组中的位置 常见的时间复杂度 常数阶 O(1) 对数阶 O(log2n) 线性阶 O(n) 线性对数阶 O(nlog2n) 平方阶 O(n^2) 立方阶 O(n^3) k 次方阶 O(n^k) 指数阶 O(2^n) 常见的算法时间复杂度由小到大依次为：Ο(1)＜Ο(log2n)＜Ο(n)＜Ο(nlog2n)＜Ο(n2)＜Ο(n3)＜ Ο(nk) ＜ Ο(2n) ，随着问题规模 n 的不断增大，上述时间复杂度不断增大，算法的执行效率越低","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"排序总结","slug":"排序总结","permalink":"https://yugd.cn/tags/%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"}]},{"title":"每日一面--HashMap原理","slug":"面试--HashMap","date":"2021-06-12T13:58:58.000Z","updated":"2022-05-26T18:17:00.213Z","comments":true,"path":"posts/10592/","link":"","permalink":"https://yugd.cn/posts/10592/","excerpt":"每天一篇 Java 小知识 本篇着重介绍一下 HashMap： 写在前面众所周知，HashMap 是一个用于存储 Key-Value 键值对的集合，每一个键值对也叫做 Entry。这些个键值对（Entry）分散存储在一个数组当中，这个数组就是 HashMap 的主干。 画个重点： Hash的公式 —&gt; index = HashCode（Key） &amp; （Length - 1） HashMap 的数据结构两种：数组 + 链表 数组：查询速度快，可以根据索引查询；但插入和删除比较困难； 链表：查询速度慢，需要遍历整个链表，但插入和删除操作比较容易; HashMap 是数组和链表组成的，数据结构中又叫“链表散列”;","text":"每天一篇 Java 小知识 本篇着重介绍一下 HashMap： 写在前面众所周知，HashMap 是一个用于存储 Key-Value 键值对的集合，每一个键值对也叫做 Entry。这些个键值对（Entry）分散存储在一个数组当中，这个数组就是 HashMap 的主干。 画个重点： Hash的公式 —&gt; index = HashCode（Key） &amp; （Length - 1） HashMap 的数据结构两种：数组 + 链表 数组：查询速度快，可以根据索引查询；但插入和删除比较困难； 链表：查询速度慢，需要遍历整个链表，但插入和删除操作比较容易; HashMap 是数组和链表组成的，数据结构中又叫“链表散列”; HashMap特点 快速存储 ：比如当我们对 hashmap 进行 get 和 put 的时候速度非常快 快速查找（时间复杂度o(1)）当我们通过key去get一个 value 的时候时间复杂度非常的低，效率非常高 可伸缩：(1) 数组扩容，边长；(2) 单线列表如果长度超过 8 的话会变成红黑树 HashMap的扩容原理HashMap 数组每一个元素的初始值都是 Null； 对于 HashMap，我们最常使用的是两个方法：Get 和 Put （获取和添加） 1.Put方法的原理调用 Put 方法的时候发生了什么呢？ 比如调用 hashMap.put(“apple”, 0) ，插入一个 Key 为 “apple” 的元素。这时候我们需要利用一个哈希函数来确定Entry的插入位置（index）： index = Hash（“apple”） 假定最后计算出的index是2，那么结果如下： 但是，因为 HashMap 的长度是有限的，当插入的 Entry 越来越多时，再完美的 Hash 函数也难免会出现 index冲突的情况。比如下面这样： HashMap数组的每一个元素不止是一个 Entry 对象，也是一个链表的头节点。每一个Entry对象通过 Next指针指向它的下一个 Entry节点。当新来的 Entry 映射到冲突的数组位置时，只需要插入到对应的链表即可： 当前采用的是 jdk 7 默认方法，也就是头插法 2.Get方法的原理使用Get方法根据Key来查找Value的时候，发生了什么呢？ 首先会把输入的 Key 做一次 Hash 映射，得到对应的 index： index = Hash（“apple”） =&gt; index = 2 由于刚才所说的 Hash 冲突，同一个位置有可能匹配到多个 Entry，这时候就需要顺着对应链表的头节点，一个一个向下来查找。假设我们要查找的 Key 是 “apple”： 第一步，我们查看的是头节点 Entry6，Entry6 的 Key 是 banana，显然不是我们要找的结果。 第二步，我们查看的是 Next 节点 Entry1，Entry1 的 Key 是 apple，正是我们要找的结果。 之所以把 Entry6 放在头节点，是因为 HashMap 的发明者认为，后插入的 Entry 被查找的可能性更大。 HashMap 尾插法上面提到过 hashmap 添加采用的是 jdk 7 默认方法（头插法），那一定时有原因的呀！ 当来到 jdk 8 的时候改成尾插法了，why？ 来看看Node的源码 每一个节点都会保存自身的 hash、key、value 以及下个Next（节点） java8之前是头插法，就是说新来的值会取代原有的值，原有的值就顺推到链表中去，就像上面的例子一样，因为写这个代码的作者认为后来的值被查找的可能性更大一点，提升查找的效率。 但是，在java8之后，都是所用尾部插入了。 为啥改为尾部插入呢？ 答：数组容量是有限的，数据多次插入的，到达一定的数量就会进行扩容，也就是resize。 什么时候resize呢？ 答： 有两个因素： Capacity：HashMap当前长度 【list.length()】 LoadFactor：负载因子，默认值0.75f 【3/4】 比如当前的容量大小为100，当你存进第76个的时候，判断发现需要进行resize了，那就进行扩容 分为两步： 扩容：创建一个新的 Entry 空数组，长度是原数组的 2 倍。 ReHash：遍历原 Entry 数组，把所有的Entry重新 Hash 到新数组。 为什么不直接复制过去？ 答：是因为长度扩大以后，Hash的规则也随之改变。 （原来长度（Length）是 8 你位运算出来的值是 2 ，新的长度是 16 你位运算出来的值明显不一样了） Hash的公式 —&gt; index = HashCode（Key） &amp; （Length - 1） 扩容前： 扩容后： 现在我们要在容量为2的容器里面用不同线程插入 A，B，C 我们可以看到链表的指向 A =&gt; B =&gt; C Tip：A的下一个指针是指向B的 因为resize的赋值方式，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置，在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 所以：可能会出现 B 的下一个指针指向了 A 一旦几个线程都调整完成，就可能出现环形链表！ 这个时候去取值,会出现 Infinite Loop 来到 jdk 8 链表有红黑树代码已经多了很多if else的逻辑判断了，红黑树的引入巧妙的将原本 O(n) 的时间复杂度降低到了 O(logn)。 好处：如果使用尾插，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。 就是说原本是 A =&gt; B ，在扩容后那个链表还是 A =&gt; B 解决哈希冲突的三种方法 拉链法【将所有哈希地址相同的记录都链接在同一链表中】（√） 开放地址法【哈希冲突时，去寻找一个新的空闲的哈希地址】 再散列法【同时构造多个不同的哈希函数，等发生哈希冲突时就使用第 2 个、第 3 个……等其他的哈希函数计算地址，直到不发生冲突为止】 HashMap 为什么扩容为2的整数次幂二进制算法 二进制的【或】运算【|】：遇 1 得 1 运算规则：0|0=0； 0|1=1； 1|0=1； 1|1=1； 二进制的【与】运算【&amp;】：遇 0 得 0 运算规则：0&amp;0=0; 0&amp;1=0; 1&amp;0=0; 1&amp;1=1; 二进制的【非】运算【~】：各位取反 运算规则：~1=0； ~0=1； 二进制的【异或】运算【^】：相同为 0 ，不同为 1 运算规则：0^0=0； 0^1=1； 1^0=1； 1^1=0； 回到问题答案： 加快哈希计算速度 减少哈希冲突 为什么可以加快计算？Hash的公式 —&gt; index = HashCode（Key） &amp; （Length - 1） 但是 % 计算比 &amp; 慢很多！ 为什么可以减少冲突？先说明：2进制中偶数的最后一位一定为 0；奇数的最后一位一定为 1 假设现在数组的长度 length 可能是偶数也可能是奇数； length 为偶数时：length-1 为奇数，hash &amp;(length-1) 的最后一位可能为 0，也可能为 1（这取决于 h 的值），这样便可以保证散列的均匀性。 length 为奇数时：length-1 为偶数，hash &amp;(length-1) 的最后一位必为 0，即只能为偶数！这样任何 hash 值都只会被散列到数组的偶数下标位置上，这便浪费了近一半的空间！ 因此，length 取 2 的整数次幂，是为了使不同 hash 值发生碰撞的概率较小，这样就能使元素在哈希表中均匀地散列。 总结 Java 7 在多线程操作 HashMap 时可能引起死循环，原因是扩容转移后前后链表顺序倒置，在转移过程中修改了原来链表中节点的引用关系。 Java 8 在同样的前提下并不会引起死循环，原因是扩容转移后前后链表顺序不变，保持之前节点的引用关系。 即使如此 Java 8 也是不建议把 HashMap 用在多线程中。 因为无法保证上一秒 put 的值，下一秒 get 的时候还是原值，所以线程安全还是无法保证。 提问HashMap的默认初始化长度是多少？ 走，源码中找答案去 在 JDK1.8 的 236 行有 1&lt;&lt;4 就是 16 （逻辑左移 4 位） 现在回过头来再看一下，重写 equals 方法的时候需要重写 hashCode 方法 如果两个对象的 hash 值相同，那么这两个对象并不一定是相同； 如果两个对象的相同，那么这两个对象的 hash 值一定是相同； HashMap 与 HashTable 的区别？ HashMap 线程不安全，HashTable 线程安全。 HashMap 是允许 key 和 value 为 null 值的，用 containsValue 和 containsKey 方法判断是否包含对应键值对；HashTable 键值对都不能为空，否则包空指针异常。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"HashMap","slug":"HashMap","permalink":"https://yugd.cn/tags/HashMap/"}]},{"title":"每日一练--桶排序（Bucket Sort）","slug":"排序--桶排序","date":"2021-06-11T13:58:58.000Z","updated":"2022-05-26T18:18:01.017Z","comments":true,"path":"posts/55604/","link":"","permalink":"https://yugd.cn/posts/55604/","excerpt":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下桶排序： 写在前面桶排序： 时间复杂度：O(n) 空间复杂度：O(n) 稳定性：不稳定 排序思想桶排序又叫箱排序，是计数排序的升级版，它的工作原理是将数组分到有限数量的桶子里，然后对每个桶子再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序），最后将各个桶中的数据有序的合并起来。就像是分不同的桶，在桶内再排序。","text":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下桶排序： 写在前面桶排序： 时间复杂度：O(n) 空间复杂度：O(n) 稳定性：不稳定 排序思想桶排序又叫箱排序，是计数排序的升级版，它的工作原理是将数组分到有限数量的桶子里，然后对每个桶子再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序），最后将各个桶中的数据有序的合并起来。就像是分不同的桶，在桶内再排序。 算法描述 找出待排序数组中的最大值max、最小值min; 我们使用 动态数组ArrayList 作为桶，桶里放的元素也用 ArrayList 存储。桶的数量为(max-min)/arr.length+1; 遍历数组 arr，计算每个元素 arr[i] 放的桶; 每个桶各自排序; 遍历桶数组，把排序好的元素放进输出数组; 图示 算法实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class BucketSort &#123; public static void bucketSort(int[] arr) &#123; //分别定义 arr 的最大值和最小值 (默认 arr 中首个元素为最小值) int max = arr[0]; int min = arr[0]; //通过遍历数组寻找到最大值和最小值 for (int i = 0; i &lt; arr.length; i++) &#123; max = Math.max(max, arr[i]); min = Math.min(min, arr[i]); &#125; //桶数 (最大值-最小值)/数组长度+1 int bucketNum = (max - min) / arr.length + 1; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketNum); //根据计算出来桶子个数来创建桶子 for (int i = 0; i &lt; bucketNum; i++) &#123; bucketArr.add(new ArrayList&lt;&gt;()); &#125; //根据桶子数值范围，将每个元素放入相应的桶中 for (int i = 0; i &lt; arr.length; i++) &#123; int num = (arr[i] - min) / (arr.length); bucketArr.get(num).add(arr[i]); &#125; //对每个桶进行排序 for (int i = 0; i &lt; bucketArr.size(); i++) &#123; Collections.sort(bucketArr.get(i)); &#125; //新数组 ArrayList&lt;Integer&gt; newArr = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; bucketArr.size(); i++) &#123; for (int j = 0; j &lt; bucketArr.get(i).size(); j++) &#123; newArr.add(bucketArr.get(i).get(j)); &#125; &#125; System.out.println(\"每个桶内：\" + bucketArr.toString()); System.out.println(\"新数组：\" + newArr.toString()); &#125; public static void main(String[] args) &#123; int[] arr = &#123;3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48&#125;; bucketSort(arr); &#125;&#125; 运行结果为： 12每个桶内：[[2, 3, 4, 5, 15], [19, 26, 27], [36, 38, 44, 46], [47, 48, 50]]新数组：[2, 3, 4, 5, 15, 19, 26, 27, 36, 38, 44, 46, 47, 48, 50] 稳定性可以看出，在分桶和从桶依次输出的过程是稳定的。但是，由于我们在对每个桶进行排序时使用了其他算法，所以，桶排序的稳定性依赖于这一步。如果我们使用了快排，显然，算法是不稳定的。 适用场景桶排序可用于最大最小值相差较大的数据情况，但桶排序要求数据的分布必须均匀，否则可能导致数据都集中到一个桶中。比如[104,150,123,132,20000], 这种数据会导致前4个数都集中到同一个桶中。导致桶排序失效。 最差的情况就是数据过于集中从而导致都放在一个或者某几个桶中。","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"桶排序","slug":"桶排序","permalink":"https://yugd.cn/tags/%E6%A1%B6%E6%8E%92%E5%BA%8F/"}]},{"title":"每日一练--归并排序（Merge Sort）","slug":"排序--归并排序","date":"2021-06-10T13:58:58.000Z","updated":"2022-05-26T18:17:55.574Z","comments":true,"path":"posts/7518/","link":"","permalink":"https://yugd.cn/posts/7518/","excerpt":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下归并排序： 写在前面归并排序： 时间复杂度：O(nlogn) 空间复杂度：O(n) 稳定性：稳定 排序思想归并排序，是创建在归并操作上的一种有效的排序算法。算法是采用分治法（Divide and Conquer）的一个非常典型的应用，且各层分治递归可以同时进行。归并排序思路简单，速度仅次于快速排序，为稳定排序算法，一般用于对总体无序，但是各子项相对有序的数列。 归并排序动图演示 递归法动图演示","text":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下归并排序： 写在前面归并排序： 时间复杂度：O(nlogn) 空间复杂度：O(n) 稳定性：稳定 排序思想归并排序，是创建在归并操作上的一种有效的排序算法。算法是采用分治法（Divide and Conquer）的一个非常典型的应用，且各层分治递归可以同时进行。归并排序思路简单，速度仅次于快速排序，为稳定排序算法，一般用于对总体无序，但是各子项相对有序的数列。 归并排序动图演示 递归法动图演示 算法描述归并排序是用分治思想 分解（Divide）：将n个元素分成个含n/2个元素的子序列。 解决（Conquer）：用合并排序法对两个子序列递归的排序。 合并（Combine）：合并两个已排序的子序列已得到排序结果。 递归法 ① 将序列每相邻两个数字进行归并操作，形成floor(n/2)个序列，排序后每个序列包含两个元素 ② 将上述序列再次归并，形成floor(n/4)个序列，每个序列包含四个元素 ③ 重复步骤②，直到所有元素排序完毕 总结：先分组，再归并 算法实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class MergeSort &#123; // 归并排序 public static void merge_sort(int[] arr)&#123; int[] temp =new int[arr.length]; internalMergeSort(arr, temp, 0, arr.length-1); &#125; private static void internalMergeSort(int[] arr, int[] temp, int left, int right)&#123; //当left==right的时，已经不需要再划分了 if (left&lt;right)&#123; int middle = (left+right)/2; //左子数组 internalMergeSort(arr, temp, left, middle); //右子数组 internalMergeSort(arr, temp, middle+1, right); //合并两个子数组 mergeSortedArray(arr, temp, left, middle, right); &#125; &#125; // 合并两个有序子序列 private static void mergeSortedArray(int[] arr, int[] temp, int left, int middle, int right)&#123; int i=left; int j=middle+1; int k=0; while (i&lt;=middle &amp;&amp; j&lt;=right)&#123; temp[k++] = arr[i] &lt;= arr[j] ? arr[i++] : arr[j++]; &#125; while (i &lt;=middle)&#123; temp[k++] = arr[i++]; &#125; while ( j&lt;=right)&#123; temp[k++] = arr[j++]; &#125; //把数据复制回原数组 for (i=0; i&lt;k; ++i)&#123; arr[left+i] = temp[i]; &#125; &#125; public static void main(String[] args) &#123; int[] array = &#123;5, 10, 1, 9, 4, 3, 7, 6, 2, 8, 11&#125;; merge_sort(array); System.out.println(Arrays.toString(array)); &#125;&#125; 运行结果为： 1[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] 稳定性因为我们在遇到相等的数据的时候必然是按顺序“复刻”到辅助数组temp[]上的，所以，归并排序同样是稳定算法。 适用场景归并排序在数据量比较大的时候也有较为出色的表现（效率上），但是，其空间复杂度O(n)使得在数据量特别大的时候（例如，1千万数据）几乎不可接受。","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"归并排序","slug":"归并排序","permalink":"https://yugd.cn/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"}]},{"title":"每日一练--堆排序（Heap Sort）","slug":"排序--堆排序","date":"2021-06-09T13:58:58.000Z","updated":"2022-05-26T18:17:53.511Z","comments":true,"path":"posts/26918/","link":"","permalink":"https://yugd.cn/posts/26918/","excerpt":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下堆排序： 写在前面堆排序： 时间复杂度：O(nlogn) 初始化建堆：O(n) 排序重建堆: nlog(n) 空间复杂度：O(1) 稳定性：不稳定 排序思想堆是一种特殊的完全二叉树（complete binary tree）。完全二叉树的一个“优秀”的性质是，除了最底层之外，每一层都是满的，这使得堆可以利用数组来表示，每一个结点对应数组中的一个元素。利用大顶堆(小顶堆)堆顶记录的是最大关键字(最小关键字)这一特性，使得每次从无序中选择最大记录(最小记录)变得简单。 堆排序动图演示1 堆排序动图演示2","text":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下堆排序： 写在前面堆排序： 时间复杂度：O(nlogn) 初始化建堆：O(n) 排序重建堆: nlog(n) 空间复杂度：O(1) 稳定性：不稳定 排序思想堆是一种特殊的完全二叉树（complete binary tree）。完全二叉树的一个“优秀”的性质是，除了最底层之外，每一层都是满的，这使得堆可以利用数组来表示，每一个结点对应数组中的一个元素。利用大顶堆(小顶堆)堆顶记录的是最大关键字(最小关键字)这一特性，使得每次从无序中选择最大记录(最小记录)变得简单。 堆排序动图演示1 堆排序动图演示2 算法描述 最大堆调整（Max-Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点； 创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆； 堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 继续进行下面的讨论前，需要注意的一个问题是：数组都是 Zero-Based，这就意味着我们的堆数据结构模型要发生改变； 堆什么是堆？堆一般指的是二叉堆，顾名思义，二叉堆是完全二叉树或者近似完全二叉树 堆的性质 是一棵完全二叉树 每个节点的值都大于或等于其子节点的值，为最大堆；反之为最小堆。 堆的存储一般用数组来表示堆，下标为 i 的结点的父结点下标为(i-1)/2；其左右子结点分别为 (2i + 1)、(2i + 2) 算法实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class HeapSort &#123; private int[] arr; public HeapSort(int[] arr) &#123; this.arr = arr; &#125; /** * 堆排序的主要入口方法，共两步。 */ public void sort() &#123; /** * 第一步：将数组堆化 * beginIndex = 第一个非叶子节点。 * 从第一个非叶子节点开始即可。无需从最后一个叶子节点开始。 * 叶子节点可以看作已符合堆要求的节点，根节点就是它自己且自己以下值为最大。 */ int len = arr.length - 1; int beginIndex = (len - 1) &gt;&gt; 1; for (int i = beginIndex; i &gt;= 0; i--) &#123; maxHeapify(i, len); &#125; /** * 第二步：对堆化数据排序 * 每次都是移出最顶层的根节点A[0]，与最尾部节点位置调换，同时遍历长度 - 1。 * 然后从新整理被换到根节点的末尾元素，使其符合堆的特性。 * 直至未排序的堆长度为 0。 */ for (int i = len; i &gt; 0; i--) &#123; swap(0, i); maxHeapify(0, i - 1); &#125; &#125; private void swap(int i, int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; /** * 调整索引为 index 处的数据，使其符合堆的特性。 * * @param index 需要堆化处理的数据的索引 * @param len 未排序的堆（数组）的长度 */ private void maxHeapify(int index, int len) &#123; // 左子节点索引 int li = (index &lt;&lt; 1) + 1; // 右子节点索引 int ri = li + 1; // 子节点值最大索引，默认左子节点。 int cMax = li; if (li &gt; len) &#123; // 左子节点索引超出计算范围，直接返回。 return; &#125; // 先判断左右子节点，哪个较大。 if (ri &lt;= len &amp;&amp; arr[ri] &gt; arr[li]) &#123; cMax = ri; &#125; if (arr[cMax] &gt; arr[index]) &#123; // 如果父节点被子节点调换， swap(cMax, index); // 则需要继续判断换下后的父节点是否符合堆的特性。 maxHeapify(cMax, len); &#125; &#125; /** * 测试用例 */ public static void main(String[] args) &#123; int[] arr = new int[]&#123;3, 5, 3, 8, 6, 1, 5, 8, 6, 2, 4, 9, 4, 7, 0, 1, 8, 9, 7, 3, 1, 2, 5, 9, 7, 4, 2, 6&#125;; new HeapSort(arr).sort(); System.out.println(Arrays.toString(arr)); &#125;&#125; 运行结果为： 1[ 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9] 稳定性堆排序存在大量的筛选和移动过程，属于不稳定的排序算法。 适用场景堆排序在建立堆和调整堆的过程中会产生比较大的开销，在元素少的时候并不适用。但是，在元素比较多的情况下，还是不错的一个选择。尤其是在解决诸如“前n大的数”一类问题时，几乎是首选算法。 堆排序操作过程中其运行时间主要耗费在建初始堆和调整建新堆时进行的反复“筛选”上。","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"选择排序","slug":"选择排序","permalink":"https://yugd.cn/tags/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/"}]},{"title":"每日一练--选择排序（Selection Sort）","slug":"排序--选择排序","date":"2021-06-08T13:58:58.000Z","updated":"2022-05-26T18:18:05.150Z","comments":true,"path":"posts/2193/","link":"","permalink":"https://yugd.cn/posts/2193/","excerpt":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下选择排序： 写在前面选择排序： 时间复杂度：O(n²) 空间复杂度：O(1) 稳定性：不稳定 排序思想选择排序是一种简单直观的排序算法，它也是一种交换排序算法，和冒泡排序有一定的相似度，可以认为选择排序是冒泡排序的一种改进。 选择排序动图演示","text":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下选择排序： 写在前面选择排序： 时间复杂度：O(n²) 空间复杂度：O(1) 稳定性：不稳定 排序思想选择排序是一种简单直观的排序算法，它也是一种交换排序算法，和冒泡排序有一定的相似度，可以认为选择排序是冒泡排序的一种改进。 选择排序动图演示 算法描述 在未排序序列中找到最小（大）元素，存放到排序序列的起始位置； 从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾； 重复第二步，直到所有元素均排序完毕。 基本思路： 外循环：循环每个位置（其实就是选择了这个位置，然后用内循环去选择一个合适的数，放到这个位置）； 内循环：在无序元素中选择一个合适的数； 把第二步选中的数据放到第一步选中的位置上就可以了； 算法实现1234567891011121314151617181920212223242526272829/** * 选择排序法，外层循环控制所需找到最小值的次数，内层循环来寻找目标值后面比目标值小的元素，进行下标更新 * 每次找到后，都将其放倒前面，与冒泡排序恰恰相反。 **/public class SelectionSort &#123; public static void selectSort(int[] arr) &#123; //外层循环控制所需找到最小值的次数,挖坑 for (int i = 0; i &lt; arr.length - 1; i++) &#123; int index = i; //内层循环来寻找目标值后面比目标值小的元素，准备填坑 for (int j = i + 1; j &lt; arr.length; j++) &#123; //下标更新 if (arr[j] &lt; arr[index]) &#123; index = j; &#125; &#125; //填坑 int temp = arr[index]; arr[index] = arr[i]; arr[i] = temp; &#125; &#125; public static void main(String[] args) &#123; int[] arr = &#123;3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48&#125;; selectSort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125; 运行结果为： 1[2, 3, 4, 5, 15, 19, 26, 27, 36, 38, 44, 46, 47, 48, 50] 稳定性用数组实现的选择排序是不稳定的，用链表实现的选择排序是稳定的。 适用场景选择排序实现也比较简单，并且由于在各种情况下复杂度波动小，因此一般是优于冒泡排序的。在所有的完全交换排序中，选择排序也是比较不错的一种算法。","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"选择排序","slug":"选择排序","permalink":"https://yugd.cn/tags/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/"}]},{"title":"每日一练--希尔排序（Shell Sort）","slug":"排序--希尔排序","date":"2021-06-07T13:58:58.000Z","updated":"2022-05-26T18:18:03.092Z","comments":true,"path":"posts/51007/","link":"","permalink":"https://yugd.cn/posts/51007/","excerpt":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下希尔排序： 写在前面希尔排序： 时间复杂度：当增量（gap ）为1时，希尔排序退化成了直接插入排序，此时的时间复杂度为O(N²)，而Hibbard增量的希尔排序的时间复杂度为O(N3/2)。 空间复杂度：O(1) 稳定性：不稳定 排序思想插入排序是效率低下是因为其移动元素每次只能移动一位，当排序元素的规模较大时，需要将元素一位一位地从一端移动到另一端。希尔排序正是基于此原理来优化、提高插入排序的效率。通过指定步长step，将原数组分为step个互相独立子数组，然后通过插入排序对这些子数组分别进行排序(即分组排序)，这时我们称其为step有序数组。当step最终为1做最后一次step有序时，就是我们平常所熟悉的插入排序了，由于该数组已经多次被较大的step进行分组排序了，此时只需要较少次数的元素移动就可以实现整个数组全局有序。 希尔排序动图演示","text":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下希尔排序： 写在前面希尔排序： 时间复杂度：当增量（gap ）为1时，希尔排序退化成了直接插入排序，此时的时间复杂度为O(N²)，而Hibbard增量的希尔排序的时间复杂度为O(N3/2)。 空间复杂度：O(1) 稳定性：不稳定 排序思想插入排序是效率低下是因为其移动元素每次只能移动一位，当排序元素的规模较大时，需要将元素一位一位地从一端移动到另一端。希尔排序正是基于此原理来优化、提高插入排序的效率。通过指定步长step，将原数组分为step个互相独立子数组，然后通过插入排序对这些子数组分别进行排序(即分组排序)，这时我们称其为step有序数组。当step最终为1做最后一次step有序时，就是我们平常所熟悉的插入排序了，由于该数组已经多次被较大的step进行分组排序了，此时只需要较少次数的元素移动就可以实现整个数组全局有序。 希尔排序动图演示 图解 算法描述 按照一定的增量 gap ，先将待排序表分割成若干个特殊子表，首个gap取值为数组长度一半（地板除）； 对于各个子表，进行直接插入排序； 随后 缩小 gap ，重复上述过程，直到 gap = 1 为止。 算法实现1234567891011121314151617181920212223242526272829303132public class ShellSort &#123; public static void shellSort(int[] arr) &#123; //增量每次都/2 for (int step = arr.length / 2; step &gt; 0; step /= 2) &#123; //从增量那组开始进行插入排序，直至完毕 for (int i = step; i &lt; arr.length; i++) &#123; //得到分组下标对应的值 int j = i; //临时变量，用于保存步长下标值 int temp = arr[j]; // j - step 就是代表与它同组隔壁的元素,如果分组前面大于后面的 while (j - step &gt;= 0 &amp;&amp; arr[j - step] &gt; temp) &#123; //将分组前面的值赋给后面的 arr[j] = arr[j - step]; //下标减去步长，来到分组前面的下标 j -= step; &#125; //如果分组之间有过交换，那么将分组后面的值发给分组前面的值 arr[j] = temp; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] array = &#123;5, 10, 1, 9, 4, 3, 7, 6, 2, 8&#125;; shellSort(array); System.out.println(Arrays.toString(array)); &#125;&#125; 运行结果为： 1[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 稳定性由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序， 但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱。 所以 希尔shell排序是不稳定的。 适用场景 Shell排序虽然快，但是毕竟是插入排序，其数量级并没有快速排序O(n㏒n)快； Shell排序在大量数据面前不是一个好的算法，但是，中小型规模的数据完全可以使用它； 希尔排序只是适用于线性表为顺序存储的i情况，不适用于链表。","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"插入排序","slug":"插入排序","permalink":"https://yugd.cn/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"}]},{"title":"每日一练--插入排序（Insert Sort）","slug":"排序--插入排序","date":"2021-06-06T13:58:58.000Z","updated":"2022-05-26T18:17:51.177Z","comments":true,"path":"posts/17455/","link":"","permalink":"https://yugd.cn/posts/17455/","excerpt":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下插入排序： 写在前面插入排序： 时间复杂度：O(n²) 空间复杂度：O(1) 稳定性：稳定 排序思想插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。即：每次确定要排序的元素并将其与之前已排好序的元素进行插入。 插入排序动图演示","text":"每天一篇排序算法（Java版本） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下插入排序： 写在前面插入排序： 时间复杂度：O(n²) 空间复杂度：O(1) 稳定性：稳定 排序思想插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。即：每次确定要排序的元素并将其与之前已排好序的元素进行插入。 插入排序动图演示 算法描述 把待排序的数组分成已排序和未排序两部分，初始的时候把第一个元素认为是已排好序的； 从第二个元素开始，在已排好序的子数组中寻找到该元素合适的位置并插入该位置； 重复上述过程直到最后一个元素被插入有序子数组中。 算法实现1234567891011121314151617181920212223242526/** * 插入排序:外层循环控制每次索要插入的元素（定义一个待插入的数），再定义一个待插入数的前一个数的下标，内层循环比较插入数字 * 与前一个数字之间的大小比较，如果待插入数的前一个数大于本次索要插入的元素，那么将前一个元素的值赋值给本次插入值的位置， * 继续向前比较，知道找到前面的元素之都比插入元素值小的位置，在跳出内层循环，执行外层循环。 **/public class InsertSort &#123; public static void insertSort(int[] arr) &#123; for (int i = 1; i &lt; arr.length; i++) &#123; //定义待插入的数 int insertVal = arr[i]; //找到待插入数的前一个数的下标 int insertIndex = i - 1; while (insertIndex &gt;= 0 &amp;&amp; arr[insertIndex] &gt; insertVal) &#123; arr[insertIndex + 1] = arr[insertIndex]; insertIndex--; &#125; arr[insertIndex + 1] = insertVal; &#125; &#125; public static void main(String[] args) &#123; int[] arr = &#123;3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48&#125;; insertSort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125; 运行结果为： 1[2, 3, 4, 5, 15, 19, 26, 27, 36, 38, 44, 46, 47, 48, 50] 稳定性由于只需要找到不大于当前数的位置而并不需要交换，因此，直接插入排序是稳定的排序方法。 适用场景插入排序由于O( n2 )的复杂度，在数组较大的时候不适用。 但是，在数据比较少的时候，是一个不错的选择，一般做为快速排序的扩充。","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"插入排序","slug":"插入排序","permalink":"https://yugd.cn/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"}]},{"title":"每日一练--快速排序（Quick Sort）","slug":"排序--快速排序","date":"2021-06-05T13:58:58.000Z","updated":"2022-05-26T18:17:57.481Z","comments":true,"path":"posts/42911/","link":"","permalink":"https://yugd.cn/posts/42911/","excerpt":"每天一篇排序算法（Java版） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下快速排序： 写在前面快速排序： 时间复杂度：O(nlogn) 空间复杂度：O(logn) 稳定性：不稳定 排序思想快排的性能在所有排序算法里面是最好的排序算法。数据规模越大快速排序的性能越优。快排在极端情况下会退化成 O(n2) 的算法，因此假如在提前得知处理数据可能会出现极端情况的前提下，可以选择使用较为稳定的归并排序。 快速排序动图演示","text":"每天一篇排序算法（Java版） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下快速排序： 写在前面快速排序： 时间复杂度：O(nlogn) 空间复杂度：O(logn) 稳定性：不稳定 排序思想快排的性能在所有排序算法里面是最好的排序算法。数据规模越大快速排序的性能越优。快排在极端情况下会退化成 O(n2) 的算法，因此假如在提前得知处理数据可能会出现极端情况的前提下，可以选择使用较为稳定的归并排序。 快速排序动图演示 算法描述快排运用了二分的思想: 首先从数列中挑出一个元素基准pivot； 定义左右两端指针。先从右往左进行扫描，如果 R[right] &lt; pivot，将R[right]移动至left所在位置，从左往右进行扫描，否则right前移；如果 R[left] &gt; pivot，将R[left]移动到right所在位置上，否则left后移。左右端指针在排序过程中从数组的两端往中间进行靠近； 直到 right == left （重合），该基准pivot就处于数列的中间位置，这个称为分区（partition）操作； 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。直到划分的区间最后长度仅为1。 算法实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 * 从数列中挑出一个元素，称为 “基准”（pivot）； * 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； * 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。 */public class QuickSort &#123; /** * 快速排序 */ public static void quick_sort(int[] arr, int left, int right) &#123; //如果左边指针小于右边指针 if (left &lt; right) &#123; /** * i:表示左边指针 * j:表示右边指针 * pivot:表示基准值（一般取分区的首个值） */ int i = left, j = right, pivot = arr[left]; while (i &lt; j) &#123; // 从右向左找第一个小于x的数，如果右侧指针所指向的值大于基准pivot，指针前移 while (i &lt; j &amp;&amp; arr[j] &gt;= pivot) &#123; j--; &#125; //如果右侧指针所指向的值小于基准pivot，交换右侧指针所指向的值与左侧指针所指向的值，并且左侧指针后移 if (i &lt; j) &#123; arr[i++] = arr[j]; &#125; // 从左向右找第一个大于等于x的数，如果左侧指针所指向的值小于基准pivot，指针后移 while (i &lt; j &amp;&amp; arr[i] &lt; pivot) &#123; i++; &#125; //如果左侧指针所指向的值大于基准pivot，交换左侧指针所指向的值与右侧指针所指向的值，并且右侧指针前移 if (i &lt; j) &#123; arr[j--] = arr[i]; &#125; &#125; arr[i] = pivot; // 递归调用左子数组 quick_sort(arr, left, i - 1); // 递归调用右子数组 quick_sort(arr, i + 1, right); &#125; &#125; public static void main(String[] args) &#123; int[] array = &#123;5, 10, 1, 9, 4, 3, 7, 6, 2, 8&#125;; quick_sort(array, 0, array.length - 1); //打印快速排序后的数组 System.out.println(Arrays.toString(array)); &#125;&#125; 运行结果为： 1[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 稳定性快速排序并不是稳定的。这是因为我们无法保证相等的数据按顺序被扫描到和按顺序存放。 适用场景快速排序在大多数情况下都是适用的，尤其在数据量大的时候性能优越性更加明显。但是在必要的时候，需要考虑下优化以提高其在最坏情况下的性能。 结论 最差情况：O(n2) 最差情况是，每次我们在划分时，所取的基准总是数组中最小的，因此我们总共会进行n-1次划分，且在第i次划分时，区间长度为：n-i+1 ,需要进行n-i比较。 故： 最好情况：O(nlog2n) 最好的情况是，每次所取的基准就是该数组的中点，因此一共需要进行n次划分，对于 长度为n的划分空间，需要进行n-1次比较。剩下的两个无序子区间需要进行2C(n/2)的比较次数。设n=2k 故： 平均情况： 随机进行切割，最好算出复杂度还是O(nlog2n)","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"交换排序","slug":"交换排序","permalink":"https://yugd.cn/tags/%E4%BA%A4%E6%8D%A2%E6%8E%92%E5%BA%8F/"}]},{"title":"每日一练--冒泡排序（Bubble Sort）","slug":"排序--冒泡排序","date":"2021-06-04T14:58:58.000Z","updated":"2022-05-26T18:17:59.249Z","comments":true,"path":"posts/54187/","link":"","permalink":"https://yugd.cn/posts/54187/","excerpt":"每天一篇排序算法（Java版） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下冒泡排序： 写在前面快速排序： 时间复杂度：O(n²) 空间复杂度：O(1) 稳定性：稳定 排序思想冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。可以理解为每次都能够将最大的数字找到。 冒泡排序动图演示","text":"每天一篇排序算法（Java版） 十种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序。 本篇着重介绍一下冒泡排序： 写在前面快速排序： 时间复杂度：O(n²) 空间复杂度：O(1) 稳定性：稳定 排序思想冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。可以理解为每次都能够将最大的数字找到。 冒泡排序动图演示 算法描述 比较相邻的元素。如果第一个比第二个大，就交换它们两个； 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数； 针对所有的元素重复以上的步骤，除了最后一个； 重复步骤1~3，直到排序完成。 算法实现 第一种，也是最为常见的一种（双重循环） 123456789101112131415161718192021222324252627282930/** * 外层循环来控制所需找到最大值的次数，内层循环用来比较相邻的两个值之间的大小，若前面的值大于后面的值，则两个元素之间进行位置交换。 * 每次外层循环所得到的都是最大元素的位置。 */public class Sort1 &#123; public static void sort(int[] array) &#123; int temp; for (int i = 0; i &lt; array.length; i++) &#123; for (int j = 0; j &lt; array.length - i - 1; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; temp = array[j + 1]; array[j + 1] = array[j]; array[j] = temp; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] array = new int[]&#123;15, 18, 36, 83, 94, 23, 10, 73, 85, 82&#125;; long startTime = System.currentTimeMillis();// System.out.println(\"startTime = \" + startTime); sort(array); long endTime = System.currentTimeMillis();// System.out.println(\"endTime = \" + endTime); System.out.println(\"time = \" + (endTime-startTime)); System.out.println(Arrays.toString(array)); &#125;&#125; 稳定性在相邻元素相等时，它们并不会交换位置，所以，冒泡排序是稳定排序。 适用场景冒泡排序思路简单，代码也简单，特别适合小数据的排序。但是，由于算法复杂度较高，在数据量大的时候不适合使用。 第二种，对于外层循环的一种优化 12345678910111213141516171819202122232425262728293031public class Sort2 &#123; public static void sort(int[] array) &#123; int temp; for (int i = 0; i &lt; array.length; i++) &#123; //有序标记，每一轮的初始是true boolean flag = true; for (int j = 0; j &lt; array.length - i - 1; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; temp = array[j + 1]; array[j + 1] = array[j]; array[j] = temp; //有元素交换，所以不是有序，标记变为false flag = false; &#125; &#125; if (flag) &#123; break; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] array = new int[]&#123;15, 18, 36, 83, 94, 23, 10, 73, 85, 82&#125;; long startTime = System.currentTimeMillis(); sort(array); long endTime = System.currentTimeMillis(); System.out.println(\"time2 = \" + (endTime - startTime)); System.out.println(Arrays.toString(array)); &#125;&#125; 运行结果为： 1[10, 15, 18, 23, 36, 73, 82, 83, 85, 94] 总结在内层循环添加一个flag默认为true（也就是默认本次不会发生元素交换），当在外层循环某次执行后，数组元素已经有序，但是外层还有循环次数的时候，flag可以跳出外层循环，缩短排序时间。 第三种，基于第二种优化方式对于内层循环的次数优化 1234567891011121314151617181920212223242526272829303132333435363738public class Sort3 &#123; public static void sort(int[] array) &#123; int temp; //记录最后一次交换的位置 int lastExchangeIndex = 0; //无序数列的边界，每次比较只需要比到这里为止 int sortBorder = array.length - 1; for (int i = 0; i &lt; array.length; i++) &#123; //有序标记，每一轮的初始是true boolean flag = true; for (int j = 0; j &lt; sortBorder; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; temp = array[j + 1]; array[j + 1] = array[j]; array[j] = temp; //有元素交换，所以不是有序，标记变为false flag = false; //把无序数列的边界更新为最后一次交换元素的位置 lastExchangeIndex = j; &#125; &#125; sortBorder = lastExchangeIndex; if (flag) &#123; break; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] array = new int[]&#123;15, 18, 36, 83, 94, 23, 10, 73, 85, 82&#125;; long startTime = System.currentTimeMillis(); sort(array); long endTime = System.currentTimeMillis(); System.out.println(\"time3 = \" + (endTime-startTime)); System.out.println(Arrays.toString(array)); &#125;&#125; 总结在外层循环添加一个标记用来–记录最后一次交换的位置，基于对内层循环的优化基础，外层循环每次确定无序数列的边界位置，这样可以减少在无需情况下内层循环的时间。 结论在数据完全有序的时候展现出最优时间复杂度，为O(n)。其他情况下，几乎总是O(n^2 )","categories":[{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"交换排序","slug":"交换排序","permalink":"https://yugd.cn/tags/%E4%BA%A4%E6%8D%A2%E6%8E%92%E5%BA%8F/"}]},{"title":"面试题（Java基础）","slug":"面试--题","date":"2021-05-29T03:58:58.000Z","updated":"2021-10-26T14:26:00.222Z","comments":true,"path":"posts/45686/","link":"","permalink":"https://yugd.cn/posts/45686/","excerpt":"Java 基础1. JDK 和 JRE 有什么区别？ JDK：Java Development Kit 的简称，java 开发工具包，提供了 java 的开发环境和运行环境。 JRE：Java Runtime Environment 的简称，java 运行环境，为 java 的运行提供了所需环境。 具体来说 JDK 其实包含了 JRE，同时还包含了编译 java 源码的编译器 javac，还包含了很多 java 程序调试和分析的工具。简单来说：如果你需要运行 java 程序，只需安装 JRE 就可以了，如果你需要编写 java 程序，需要安装 JDK。 2. == 和 equals 的区别是什么？","text":"Java 基础1. JDK 和 JRE 有什么区别？ JDK：Java Development Kit 的简称，java 开发工具包，提供了 java 的开发环境和运行环境。 JRE：Java Runtime Environment 的简称，java 运行环境，为 java 的运行提供了所需环境。 具体来说 JDK 其实包含了 JRE，同时还包含了编译 java 源码的编译器 javac，还包含了很多 java 程序调试和分析的工具。简单来说：如果你需要运行 java 程序，只需安装 JRE 就可以了，如果你需要编写 java 程序，需要安装 JDK。 2. == 和 equals 的区别是什么？ == 解读 对于基本类型和引用类型 == 的作用效果是不同的，如下所示： 基本类型：比较的是值是否相同； 引用类型：比较的是引用是否相同； 代码示例： 1234567String x = \"string\";String y = \"string\";String z = new String(\"string\");System.out.println(x==y); // trueSystem.out.println(x==z); // falseSystem.out.println(x.equals(y)); // trueSystem.out.println(x.equals(z)); // true 代码解读：因为 x 和 y 指向的是同一个引用，所以 == 也是 true，而 new String()方法则重写开辟了内存空间，所以 == 结果为 false，而 equals 比较的一直是值，所以结果都为 true。 equals 解读 总结 ：== 对于基本类型来说是值比较，对于引用类型来说是比较的是引用；而 equals 默认情况下是引用比较，只是很多类重新了 equals 方法，比如 String、Integer 等把它变成了值比较，所以一般情况下 equals 比较的是值是否相等。 3. 两个对象的 hashCode()相同，则 equals()也一定为 true，对吗？ 不对，两个对象的 hashCode()相同，equals()不一定 true。 4. final 在 java 中有什么作用？ final 修饰的类叫最终类，该类不能被继承。 final 修饰的方法不能被重写。 final 修饰的变量叫常量，常量必须初始化，初始化之后值就不能被修改。 5. java 中的 Math.round(-1.5) 等于多少？ 等于 -1，因为在数轴上取值时，中间值（0.5）向右取整，所以正 0.5 是往上取整，负 0.5 是直接舍弃。 6. String 属于基础的数据类型吗？ String 不属于基础类型，基础类型有 8 种：byte、boolean、char、short、int、float、long、double，而 String 属于对象。 7. java 中操作字符串都有哪些类？它们之间有什么区别？ 操作字符串的类有：String、StringBuffer、StringBuilder。 8. String str=”i”与 String str=new String(“i”)一样吗？ 不一样，因为内存的分配方式不一样。String str=”i”的方式，java 虚拟机会将其分配到常量池中；而 String str=new String(“i”) 则会被分到堆内存中。 9. 如何将字符串反转？ 使用 StringBuilder 或者 stringBuffer 的 reverse() 方法。 示例代码： 12345678// StringBuffer reverseStringBuffer stringBuffer = new StringBuffer();stringBuffer.append(\"abcdefg\");System.out.println(stringBuffer.reverse()); // gfedcba// StringBuilder reverseStringBuilder stringBuilder = new StringBuilder();stringBuilder.append(\"abcdefg\");System.out.println(stringBuilder.reverse()); // gfedcba 10. String 类的常用方法都有那些？ indexOf()：返回指定字符的索引。 charAt()：返回指定索引处的字符。 replace()：字符串替换。 trim()：去除字符串两端空白。 split()：分割字符串，返回一个分割后的字符串数组。 getBytes()：返回字符串的 byte 类型数组。 length()：返回字符串长度。 toLowerCase()：将字符串转成小写字母。 toUpperCase()：将字符串转成大写字符。 substring()：截取字符串。 equals()：字符串比较。 11. 普通类和抽象类有哪些区别？ 普通类不能包含抽象方法，抽象类可以包含抽象方法。 抽象类不能直接实例化，普通类可以直接实例化。 12. 抽象类能使用 final 修饰吗？ 不能，定义抽象类就是让其他类继承的，如果定义为 final 该类就不能被继承，这样彼此就会产生矛盾，所以 final 不能修饰抽象类，如下图所示，编辑器也会提示错误信息： 13. 接口和抽象类有什么区别？ 实现：抽象类的子类使用 extends 来继承；接口必须使用 implements 来实现接口。 构造函数：抽象类可以有构造函数；接口不能有。 main 方法：抽象类可以有 main 方法，并且我们能运行它；接口不能有 main 方法。 实现数量：类可以实现很多个接口；但是只能继承一个抽象类。 访问修饰符：接口中的方法默认使用 public 修饰；抽象类中的方法可以是任意访问修饰符。 14. java 中 IO 流分为几种？ 按功能来分：输入流（input）、输出流（output）。 按类型来分：字节流和字符流。 字节流和字符流的区别是：字节流按 8 位传输以字节为单位输入输出数据，字符流按 16 位传输以字符为单位输入输出数据。 15. BIO、NIO、AIO 有什么区别？ BIO：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。 NIO：New IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。 AIO：Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。","categories":[{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"面试","slug":"面试","permalink":"https://yugd.cn/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Redis--基本语句","slug":"面试--Redis--基本语句","date":"2021-05-21T15:29:58.000Z","updated":"2022-05-26T18:17:32.054Z","comments":true,"path":"posts/18405/","link":"","permalink":"https://yugd.cn/posts/18405/","excerpt":"","text":"key–操作数据库123456789101112131415161718192021222324252627282930313233$ 插入数据/更新key的值 set key_name value $ 查询数据 get key_name$ 删除键值 del key_name $ 验证键是否存在 exists key_name$ 返回所有 key keys * $ 返回所有 xxx开头的 key keys xxx*$ 设置一个 key 的过期时间(单位:秒) expire key_name 10$ 移除给定 key 的过期时间 persist key_name $ 选择数据库[0..15] select index$ 将当前数据库中的 key 转移到其它数据库中 move key_name 1 $ 返回值的类型 type key_name$ 更新key的值返回原来的值 getset key_name value$ 测试连接是否存活 ping$ 返回当前数据库中 key 的数目 dbsize$ 监视--实时转储收到的请求 monitor$ 删除当前选择数据库中的所有 key flushdb$ 删除所有数据库中的所有 key flushall Redis数据类型(string) string 是最简单的类型 ，一个 key 对应一个value redis 的 string 可以包含任何数据， 比如 jpg 图片或者序列化的对象，从内部实现来看其实 string 可以看作 byte 数组，最大上限是 1G 字节。 123456789101112131415161718192021222324252627set:插入数据/更新key的值 set name dheeget:查询数据 get key_namemset:一次设置多个 key 的值 mset key1 dhc key2 jhcmget :一次获取多个 key 的值 mget key1 key2 key3setnx:如果 key 已经存在，返回 0 ,setnx name dheesetex:指定此键值对应的有效期,时间单位为秒 ,setex name 120 dheesetrange:设置指定 key 的 value 值的子字符串 ，从指定的位置开始替换字符 ,setrange name 3 @dhc.comgetrange:获取指定 key 的 value 值的子字符串 getrange name 0 6** expire:设置key失效时间 expire key_name 3incr keyname 将键存储的值加1decr kename 将键存储的是减1incrby keyname amount 将键存储的值加上整数amountdecrby keyname amount 将键存储的值减去整数amountincrbyfloat keyname amount 将键存储的值加上浮点数amount Redis 哈希(Hash) 一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。 Redis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。 1234567891011121314151617hset :设置 hash field 为指定值,hset myhash name dheehget :获取指定的 hash field,hget myhash name** hmset:同时设置 hash 的多个 field,hmset myhash name dhee age 20** hmget :获取全部指定的 hash filed,hmget myhash name age password** hlen :返回指定 hash 的 field 数量,hlen myhashhdel :删除一个或多个哈希表字段,hdel myhash agehkeys:返回 hash 的所有 field,hkeys myhashhvals :返回 hash 的所有 value:hvals myhashhgetall :获取某个 hash 中全部的 filed及value,hgetall myhash Redis 列表(List) 简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边） 一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。 123456789101112131415161718192021lpush:在 key 对应 list 的头部添加字符串元素 ,lpush mylist world lpush mylist hello lrange: lrange mylist 0 1** rpush :在 key 对应 list 的尾部添加字符串元素 , rpush mylist world rpush mylist hello ** linsert :在 key 对应 list 的特定位置前或后添加字符串 ,linsert mylist before world dhee** lset :设置 list 中指定下标的元素值(下标从 0 开始) ,lset mylist 0 dhc`lrem` :从 key 对应 list 中删除 count 个和 value 相同的元素,lrem mylist 2 hello** ltrim :保留指定 key 的值范围内的数据, ltrim mylist 1 3lpop :从 list 的头部删除元素，并返回删除元素, lpop mylist** rpop :从 list 的尾部删除元素，并返回删除元素, rpop mylist** lindex :返回名称为 key 的 list 中 index 位置的元素 ,lindex mylist 0** llen :返回 key 对应 list 的长度 ,llen mylist Redis 集合(Set) Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。 123456789101112131415161718192021222324252627`sadd` ： sadd myset hello`smembers` ：查看 myset 中的所有元素 , smembers myset`srem` ：删除名称为 key 的 set 中的元素 member, srem myset hellospop ：随机删除名称为 key 的 se t 中一个元素,spop mysetsdiff:返回第一个 set集合与第二个 set集合的差集,sdiff myset2 myset1sdiffstore :返回第一个 set集合与第二个 set集合的差集 ，并将结果存为另一个 set, sdiffstoremyset3 myset2 myset1sinter:返回所有给定 key 的交集 ,sinter myset1 myset2sinterstore :返回所有给定 key 的交集，并将结果存为另一个 key ,sinterstore myset4 myset2 myset1`sunion`:返回所有给定 key 的并集 ,sunion myset2 myset1sunionstore :返回所有给定 key 的并集，并将结果存为另一个key sunionstore myset5 myset2 myset1`scard`:返回名称为 key 的 set 的元素个数 ,scard myset2 Redis 有序集合(sorted set) Redis 有序集合和集合一样也是 string 类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。 有序集合的成员是唯一的,但分数(score)却可以重复。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。 12345678910111213141516171819202122232425`zadd`：向名称为 key 的 zset 中添加元素 member， score 用于设定分数。如果该元素已经存在，则根据`score` 更新该元素的分数。zadd key score member,zrange myzset 0 -1 withscores`zrem` :删除名称为 key 的 zset 中的元素 member ,zrem myzset two`zincrby`：给成员增加指定分数 zincrby myzset 1 one`zrank` ：返回zset 中名称为 key 的 member 元素的排名(按 score 从小到大排序)即下标 zrank myzset two`zrevrank`：返回zset 中名称为 key 的 member 元素的排名(按 score 从大到小排序)即下标 zrevrank myzset two`zrevrange` ：按 score 从大到小排序，再取出全部元素 ,zrevrange myzset 0 -1 withscores`zrangebyscore` ：返回集合中 score 在给定区间的元素,zrangebyscore myzset 2 3 withscores`zcount` ：返回集合中 score 在给定区间的数量 ,zcount myzset 2 3`zcard` ：返回集合中元素个数 zcard myzset (key 的个数)`zscore` ：返回给定元素对应的 score ,zscore myzset two (key 的 score 数量)zremrangebyrank ：删除集合中排名在给定区间的元素 ,zremrangebyrank myzset 3 3zremrangebyscore ：删除集合中 score 在给定区间的元素,zremrangebyscore myzset 1 2","categories":[{"name":"数据库","slug":"数据库","permalink":"https://yugd.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://yugd.cn/tags/redis/"}]},{"title":"MongoDB概念","slug":"面试--MongoDB概念","date":"2021-05-21T14:29:58.000Z","updated":"2022-05-26T18:17:15.315Z","comments":true,"path":"posts/46617/","link":"","permalink":"https://yugd.cn/posts/46617/","excerpt":"","text":"不管我们学习什么数据库都应该学习其中的基础概念，在mongodb中基本的概念是文档、集合、数据库，下面我们挨个介绍。 下表将更容易理解Mongo中的一些概念： SQL术语/概念 MongoDB术语/概念 解释/说明 database database 数据库 table collection 数据库表/集合 row document 数据记录行/文档 column field 数据字段/域 index index 索引 table joins 表连接,MongoDB不支持 primary key primary key 主键,MongoDB自动将_id字段设置为主键 数据库一个mongodb中可以建立多个数据库。 MongoDB的默认数据库为”db”，该数据库存储在data目录中。 MongoDB的单个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中。 “show dbs” 命令可以显示所有数据的列表。 1$ ./mongo MongoDB shell version: 3.0.6 connecting to: test &gt; show dbs local 0.078GB test 0.078GB &gt; 执行 “db” 命令可以显示当前数据库对象或集合。 1$ ./mongo MongoDB shell version: 3.0.6 connecting to: test &gt; db test &gt; 运行”use”命令，可以连接到一个指定的数据库。 1&gt; use local switched to db local &gt; db local &gt; 以上实例命令中，”local” 是你要链接的数据库。 在下一个章节我们将详细讲解MongoDB中命令的使用。 数据库也通过名字来标识。数据库名可以是满足以下条件的任意UTF-8字符串。 不能是空字符串（””)。 不得含有’ ‘（空格)、.、$、/、\\和\\0 (空宇符)。 应全部小写。 最多64字节。 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。 admin： 从权限的角度来看，这是”root”数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。 local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合 config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。 文档文档是一个键值(key-value)对(即BSON)。MongoDB 的文档不需要设置相同的字段，并且相同的字段不需要相同的数据类型，这与关系型数据库有很大的区别，也是 MongoDB 非常突出的特点。 一个简单的文档例子如下： 1&#123;&quot;site&quot;:&quot;www.runoob.com&quot;, &quot;name&quot;:&quot;菜鸟教程&quot;&#125; 下表列出了 RDBMS 与 MongoDB 对应的术语： RDBMS MongoDB 数据库 数据库 表格 集合 行 文档 列 字段 表联合 嵌入文档 主键 主键 (MongoDB 提供了 key 为 _id ) 数据库服务和客户端 Mysqld/Oracle mongod mysql/sqlplus mongo 需要注意的是： 文档中的键/值对是有序的。 文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型（甚至可以是整个嵌入的文档)。 MongoDB区分类型和大小写。 MongoDB的文档不能有重复的键。 文档的键是字符串。除了少数例外情况，键可以使用任意UTF-8字符。 文档键命名规范： 键不能含有\\0 (空字符)。这个字符用来表示键的结尾。 .和$有特别的意义，只有在特定环境下才能使用。 以下划线”_”开头的键是保留的(不是严格要求的)。 集合集合就是 MongoDB 文档组，类似于 RDBMS （关系数据库管理系统：Relational Database Management System)中的表格。 集合存在于数据库中，集合没有固定的结构，这意味着你在对集合可以插入不同格式和类型的数据，但通常情况下我们插入集合的数据都会有一定的关联性。 比如，我们可以将以下不同数据结构的文档插入到集合中： 1&#123;&quot;site&quot;:&quot;www.baidu.com&quot;&#125; &#123;&quot;site&quot;:&quot;www.google.com&quot;,&quot;name&quot;:&quot;Google&quot;&#125; &#123;&quot;site&quot;:&quot;www.runoob.com&quot;,&quot;name&quot;:&quot;菜鸟教程&quot;,&quot;num&quot;:5&#125; 当第一个文档插入时，集合就会被创建。 合法的集合名 集合名不能是空字符串””。 集合名不能含有\\0字符（空字符)，这个字符表示集合名的结尾。 集合名不能以”system.”开头，这是为系统集合保留的前缀。 用户创建的集合名字不能含有保留字符。有些驱动程序的确支持在集合名里面包含，这是因为某些系统生成的集合中包含该字符。除非你要访问这种系统创建的集合，否则千万不要在名字里出现$。 如下实例： 1db.col.findOne() capped collectionsCapped collections 就是固定大小的collection。 它有很高的性能以及队列过期的特性(过期按照插入的顺序). 有点和 “RRD” 概念类似。 Capped collections是高性能自动的维护对象的插入顺序。它非常适合类似记录日志的功能 和标准的collection不同，你必须要显式的创建一个capped collection， 指定一个collection的大小，单位是字节。collection的数据存储空间值提前分配的。 要注意的是指定的存储大小包含了数据库的头信息。 1db.createCollection(&quot;mycoll&quot;, &#123;capped:true, size:100000&#125;) 在capped collection中，你能添加新的对象。 能进行更新，然而，对象不会增加存储空间。如果增加，更新就会失败 。 数据库不允许进行删除。使用drop()方法删除collection所有的行。 注意: 删除之后，你必须显式的重新创建这个collection。 在32bit机器中，capped collection最大存储为1e9( 1X109)个字节。 元数据数据库的信息是存储在集合中。它们使用了系统的命名空间： 1dbname.system.* 在MongoDB数据库中名字空间 .system.* 是包含多种系统信息的特殊集合(Collection)，如下: 集合命名空间 描述 dbname.system.namespaces 列出所有名字空间。 dbname.system.indexes 列出所有索引。 dbname.system.profile 包含数据库概要(profile)信息。 dbname.system.users 列出所有可访问数据库的用户。 dbname.local.sources 包含复制对端（slave）的服务器信息和状态。 对于修改系统集合中的对象有如下限制。 在插入数据，可以创建索引。但除此之外该表信息是不可变的(特殊的drop index命令将自动更新相关信息)。 是可修改的。 是可删除的。 MongoDB 数据类型下表为MongoDB中常用的几种数据类型。 数据类型 描述 String 字符串。存储数据常用的数据类型。在 MongoDB 中，UTF-8 编码的字符串才是合法的。 Integer 整型数值。用于存储数值。根据你所采用的服务器，可分为 32 位或 64 位。 Boolean 布尔值。用于存储布尔值（真/假）。 Double 双精度浮点值。用于存储浮点值。 Min/Max keys 将一个值与 BSON（二进制的 JSON）元素的最低值和最高值相对比。 Arrays 用于将数组或列表或多个值存储为一个键。 Timestamp 时间戳。记录文档修改或添加的具体时间。 Object 用于内嵌文档。 Null 用于创建空值。 Symbol 符号。该数据类型基本上等同于字符串类型，但不同的是，它一般用于采用特殊符号类型的语言。 Date 日期时间。用 UNIX 时间格式来存储当前日期或时间。你可以指定自己的日期时间：创建 Date 对象，传入年月日信息。 Object ID 对象 ID。用于创建文档的 ID。 Binary Data 二进制数据。用于存储二进制数据。 Code 代码类型。用于在文档中存储 JavaScript 代码。 Regular expression 正则表达式类型。用于存储正则表达式。 不管我们学习什么数据库都应该学习其中的基础概念，在mongodb中基本的概念是文档、集合、数据库，下面我们挨个介绍。 下表将帮助您更容易理解Mongo中的一些概念： SQL术语/概念 MongoDB术语/概念 解释/说明 database database 数据库 table collection 数据库表/集合 row document 数据记录行/文档 column field 数据字段/域 index index 索引 table joins 表连接,MongoDB不支持 primary key primary key 主键,MongoDB自动将_id字段设置为主键 数据库一个mongodb中可以建立多个数据库。 MongoDB的默认数据库为”db”，该数据库存储在data目录中。 MongoDB的单个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中。 “show dbs” 命令可以显示所有数据的列表。 1$ .&#x2F;mongo MongoDB shell version: 3.0.6 connecting to: test &gt; show dbs local 0.078GB test 0.078GB &gt; 执行 “db” 命令可以显示当前数据库对象或集合。 1$ .&#x2F;mongo MongoDB shell version: 3.0.6 connecting to: test &gt; db test &gt; 运行”use”命令，可以连接到一个指定的数据库。 1&gt; use local switched to db local &gt; db local &gt; 以上实例命令中，”local” 是你要链接的数据库。 在下一个章节我们将详细讲解MongoDB中命令的使用。 数据库也通过名字来标识。数据库名可以是满足以下条件的任意UTF-8字符串。 不能是空字符串（””)。 不得含有’ ‘（空格)、.、$、/、\\和\\0 (空宇符)。 应全部小写。 最多64字节。 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。 admin： 从权限的角度来看，这是”root”数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。 local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合 config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。 文档文档是一个键值(key-value)对(即BSON)。MongoDB 的文档不需要设置相同的字段，并且相同的字段不需要相同的数据类型，这与关系型数据库有很大的区别，也是 MongoDB 非常突出的特点。 一个简单的文档例子如下： 1&#123;&quot;site&quot;:&quot;www.runoob.com&quot;, &quot;name&quot;:&quot;菜鸟教程&quot;&#125; 下表列出了 RDBMS 与 MongoDB 对应的术语： RDBMS MongoDB 数据库 数据库 表格 集合 行 文档 列 字段 表联合 嵌入文档 主键 主键 (MongoDB 提供了 key 为 _id ) 数据库服务和客户端 Mysqld/Oracle mongod mysql/sqlplus mongo 需要注意的是： 文档中的键/值对是有序的。 文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型（甚至可以是整个嵌入的文档)。 MongoDB区分类型和大小写。 MongoDB的文档不能有重复的键。 文档的键是字符串。除了少数例外情况，键可以使用任意UTF-8字符。 文档键命名规范： 键不能含有\\0 (空字符)。这个字符用来表示键的结尾。 .和$有特别的意义，只有在特定环境下才能使用。 以下划线”_”开头的键是保留的(不是严格要求的)。 集合集合就是 MongoDB 文档组，类似于 RDBMS （关系数据库管理系统：Relational Database Management System)中的表格。 集合存在于数据库中，集合没有固定的结构，这意味着你在对集合可以插入不同格式和类型的数据，但通常情况下我们插入集合的数据都会有一定的关联性。 比如，我们可以将以下不同数据结构的文档插入到集合中： 1&#123;&quot;site&quot;:&quot;www.baidu.com&quot;&#125; &#123;&quot;site&quot;:&quot;www.google.com&quot;,&quot;name&quot;:&quot;Google&quot;&#125; &#123;&quot;site&quot;:&quot;www.runoob.com&quot;,&quot;name&quot;:&quot;菜鸟教程&quot;,&quot;num&quot;:5&#125; 当第一个文档插入时，集合就会被创建。 合法的集合名 集合名不能是空字符串””。 集合名不能含有\\0字符（空字符)，这个字符表示集合名的结尾。 集合名不能以”system.”开头，这是为系统集合保留的前缀。 用户创建的集合名字不能含有保留字符。有些驱动程序的确支持在集合名里面包含，这是因为某些系统生成的集合中包含该字符。除非你要访问这种系统创建的集合，否则千万不要在名字里出现$。 如下实例： 1db.col.findOne() capped collectionsCapped collections 就是固定大小的collection。 它有很高的性能以及队列过期的特性(过期按照插入的顺序). 有点和 “RRD” 概念类似。 Capped collections是高性能自动的维护对象的插入顺序。它非常适合类似记录日志的功能 和标准的collection不同，你必须要显式的创建一个capped collection， 指定一个collection的大小，单位是字节。collection的数据存储空间值提前分配的。 要注意的是指定的存储大小包含了数据库的头信息。 1db.createCollection(&quot;mycoll&quot;, &#123;capped:true, size:100000&#125;) 在capped collection中，你能添加新的对象。 能进行更新，然而，对象不会增加存储空间。如果增加，更新就会失败 。 数据库不允许进行删除。使用drop()方法删除collection所有的行。 注意: 删除之后，你必须显式的重新创建这个collection。 在32bit机器中，capped collection最大存储为1e9( 1X109)个字节。 元数据数据库的信息是存储在集合中。它们使用了系统的命名空间： 1dbname.system.* 在MongoDB数据库中名字空间 .system.* 是包含多种系统信息的特殊集合(Collection)，如下: 集合命名空间 描述 dbname.system.namespaces 列出所有名字空间。 dbname.system.indexes 列出所有索引。 dbname.system.profile 包含数据库概要(profile)信息。 dbname.system.users 列出所有可访问数据库的用户。 dbname.local.sources 包含复制对端（slave）的服务器信息和状态。 对于修改系统集合中的对象有如下限制。 在插入数据，可以创建索引。但除此之外该表信息是不可变的(特殊的drop index命令将自动更新相关信息)。 是可修改的。 是可删除的。 MongoDB 数据类型下表为MongoDB中常用的几种数据类型。 数据类型 描述 String 字符串。存储数据常用的数据类型。在 MongoDB 中，UTF-8 编码的字符串才是合法的。 Integer 整型数值。用于存储数值。根据你所采用的服务器，可分为 32 位或 64 位。 Boolean 布尔值。用于存储布尔值（真/假）。 Double 双精度浮点值。用于存储浮点值。 Min/Max keys 将一个值与 BSON（二进制的 JSON）元素的最低值和最高值相对比。 Arrays 用于将数组或列表或多个值存储为一个键。 Timestamp 时间戳。记录文档修改或添加的具体时间。 Object 用于内嵌文档。 Null 用于创建空值。 Symbol 符号。该数据类型基本上等同于字符串类型，但不同的是，它一般用于采用特殊符号类型的语言。 Date 日期时间。用 UNIX 时间格式来存储当前日期或时间。你可以指定自己的日期时间：创建 Date 对象，传入年月日信息。 Object ID 对象 ID。用于创建文档的 ID。 Binary Data 二进制数据。用于存储二进制数据。 Code 代码类型。用于在文档中存储 JavaScript 代码。 Regular expression 正则表达式类型。用于存储正则表达式。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://yugd.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://yugd.cn/tags/MongoDB/"}]},{"title":"Linux常用命令","slug":"面试--Linux常用命令","date":"2021-05-20T14:29:58.000Z","updated":"2022-05-26T18:17:11.285Z","comments":true,"path":"posts/48230/","link":"","permalink":"https://yugd.cn/posts/48230/","excerpt":"导语 因为在日常工作中会遇到远程控制、部署程序的问题，总会使用到 linux 的相关命令，所以在此总结一些常用的 linux 命令。","text":"导语 因为在日常工作中会遇到远程控制、部署程序的问题，总会使用到 linux 的相关命令，所以在此总结一些常用的 linux 命令。 Linux 的系统目录结构如下图 123456789101112131415161718$ /bin ## 二进制文件，系统常规命令$ /boot ## 系统启动分区，系统启动时读取的文件$ /dev ## 设备文件$ /etc ## 大多数配置文件$ /home ## 普通用户的家目录$ /lib ## 32位函数库$ /lib64 ## 64位库$ /media ## 手动临时挂载点$ /mnt ## 手动临时挂载点$ /opt ## 第三方软件安装位置$ /proc ## 进程信息及硬件信息$ /root ## 临时设备的默认挂载点$ /sbin ## 系统管理命令$ /srv ## 数据$ /var ## 数据$ /sys ## 内核相关信息$ /tmp ## 临时文件$ /usr ## 用户相关设定 命令的组成1$ 示例：命令 参数名 参数值 常用命令ls【作用】：列出目录内容 12[root@localhost ~]# ls[root@localhost ~]# ll tree【作用】：显示树形目录 1[root@localhost ~]# tree 需要 yum install -y tree 安装 cd【作用】：更改当前目录 12[root@localhost ~]# cd ..[root@localhost ~]# cd / mkdir【作用】：在当前目录下创建下一级目录 1[root@localhost ~]# mkdir test rmdir【作用】：仅可以删除空白目录（不可以删除包含内容的目录） 1[root@localhost ~]# rmdir test touch【作用】：创建空白文件 1[root@localhost ~]# touch test.txt rm【作用】：删除文件 删除文件123[root@localhost ~]# rm [文件名]（删除时会询问是否删除）[root@localhost ~]# rm -f [文件名]（强制删除）[root@localhost ~]# rm -v [文件名]（可视化删除） 删除目录123[root@localhost ~]# rm -r [文件名]（删除时会询问是否删除）[root@localhost ~]# rm -rf [文件名]（强制删除，若目录不存在，此命令依旧可以执行，不报错）[root@localhost ~]# rm -rv [文件名]（可视化强制） 删除目录和文件时，先删除文件在删除目录 cp【作用】：源文件始终不变，仅仅是对目标文件进行改变 1[root@localhost ~]# cp [源文件] [目标文件] mv【作用】：mv命令使源文件的状态发生改变 1[root@localhost ~]# mv [源文件] [目标文件] 若果目录存在，则会将原目录移动到目标目录下；如果目录不存在，则相当于移动并重命名 cat【作用】：正序查看文件内容 参数-A 查看所有内容，$代表每行的结尾 参数-n 显示行号 全文搜索 从前往后搜索：可以输入 /（其中代表要搜索的内容），搜索到的内容会高亮度显示 1[root@localhost ~]# cat -An /etc/passwd tail【作用】：用于查看文件的内容，有一个常用的参数 -f 常用于查阅正在改变的日志文件 1[root@localhost ~]# tail [参数] [文件] chmod【作用】：更改当前目录权限 1[root@localhost ~]# chmod 777 [文件] tar【作用】：打包与解压 12[root@localhost ~]# tar -zcvf 打包压缩后的文件名 要打包的文件[root@localhost ~]# tar -zxvf a.tar //解包至当前目录 ifconfig【作用】：查看网络地址 1[root@localhost ~]# ifconfig ps【作用】：查看进程 1[root@localhost ~]# ps -ef //查看所有正在运行的进程 kill【作用】：结束进程 12[root@localhost ~]# kill pid //杀死该pid的进程 [root@localhost ~]# kill -9 pid //强制杀死该进程 ping【作用】：查看与此IP地址的连接情况 1[root@localhost ~]# ping www.baidu.com clear【作用】：快速清屏 1[root@localhost ~]# clear firewalld查看防火墙状态1[root@localhost ~]# systemctl status firewalld 开启防火墙1[root@localhost ~]# systemctl start firewalld 关闭防火墙1[root@localhost ~]# systemctl stop firewalld 设置对外开放访问的端口12[root@localhost ~]# firewall-cmd --add-service=http –permanent [root@localhost ~]# firewall-cmd --add-port=80/tcp --permanent 重新载入1[root@localhost ~]# firewall-cmd –reload 删除1[root@localhost ~]# firewall-cmd --zone=public --remove-port=80/tcp --permanent 查看已开放的端口号1[root@localhost ~]# firewall-cmd --list-all vim 编译1:set number --vim显示行号 （一次性）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://yugd.cn/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://yugd.cn/tags/linux/"}]},{"title":"设计模式--总结","slug":"设计模式--总结","date":"2021-05-19T04:00:00.000Z","updated":"2022-05-26T18:18:25.977Z","comments":true,"path":"posts/23168/","link":"","permalink":"https://yugd.cn/posts/23168/","excerpt":"设计模式总结（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、策略模式、模板方法模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重总结一下 23 种设计模式：","text":"设计模式总结（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、策略模式、模板方法模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重总结一下 23 种设计模式： 写在前面 设计模式的本质是面向对象设计原则的实际运用，是对类的封装性、继承性和多态性以及类的关联关系和组合关系的充分理解 设计模式的七大原则 设计原则 一句话归纳 目的 开闭原则 对扩展开放，对修改关闭 降低维护带来的新风险 依赖倒置原则 高层不应该依赖低层，要面向接口编程 更利于代码结构的升级扩展 单一职责原则 一个类只干一件事，实现类要单一 便于理解，提高代码的可读性 接口隔离原则 一个接口只干一件事，接口要精简单一 功能解耦，高聚合、低耦合 迪米特法则 不该知道的不要知道，一个类应该保持对其它对象最少的了解，降低耦合度 只和朋友交流，不和陌生人说话，减少代码臃肿 里氏替换原则 不要破坏继承体系，子类重写方法功能发生改变，不应该影响父类方法的含义 防止继承泛滥 合成复用原则 尽量使用组合或者聚合关系实现代码复用，少使用继承 降低代码耦合 访问加限制，函数要节俭，依赖不允许，动态加接口，父类要抽象，扩展不更改。 降低对象之间的耦合，增加程序的可复用性、可扩展性和可维护性 设计模式的分类 范围 \\ 目的 创建型模式 结构型模式 行为型模式 类模式 工厂方法 (类）适配器 模板方法、解释器 对象模式 抽象工厂 代理 (对象）、装饰 策略、命令、备忘录 单例、原型 适配器、组合 职责链、状态 建造者 桥接、享元、外观 观察者、中介者 迭代器、访问者 设计模式的归纳 分类 设计模式 简述 一句话归纳 目的 生活案例 创建型设计模式 （简单来说就是用来创建对象的） 工厂模式（Factory Pattern） 不同条件下创建不同实例 产品标准化，生产更高效 封装创建细节 实体工厂 单例模式（Singleton Pattern） 保证一个类仅有一个实例，并且提供一个全局访问点 世上只有一个我 保证独一无二 CEO 原型模式（Prototype Pattern） 通过拷贝原型创建新的对象 拔一根猴毛，吹出千万个 高效创建对象 克隆 建造者模式（Builder Pattern） 用来创建复杂的复合对象 高配中配和低配，想选哪配就哪配 开放个性配置步骤 选配 结构型设计模式 （关注类和对象的组合） 代理模式（Proxy Pattern） 为其他对象提供一种代理以控制对这个对象的访问 没有资源没时间，得找别人来帮忙 增强职责 媒婆 外观模式（Facade Pattern） 对外提供一个统一的接口用来访问子系统 打开一扇门，通向全世界 统一访问入口 前台 装饰器模式（Decorator Pattern） 为对象添加新功能 他大舅他二舅都是他舅 灵活扩展、同宗同源 煎饼 享元模式（Flyweight Pattern） 使用对象池来减少重复对象的创建 优化资源配置，减少重复浪费 共享资源池 全国社保联网 组合模式（Composite Pattern） 将整体与局部（树形结构）进行递归组合，让客户端能够以一种的方式对其进行处理 人在一起叫团伙，心在一起叫团队 统一整体和个体 组织架构树 适配器模式（Adapter Pattern） 将原来不兼容的两个类融合在一起 万能充电器 兼容转换 电源适配 桥接模式（Bridge Pattern） 将两个能够独立变化的部分分离开来 约定优于配置 不允许用继承 桥 行为型设计模式 （关注对象之间的通信） 模板模式（Template Pattern） 定义一套流程模板，根据需要实现模板中的操作 流程全部标准化，需要微调请覆盖 逻辑复用 把大象装进冰箱 策略模式（Strategy Pattern） 封装不同的算法，算法之间能互相替换 条条大道通罗马，具体哪条你来定 把选择权交给用户 选择支付方式 责任链模式（Chain of Responsibility Pattern 拦截的类都实现统一接口，每个接收者都包含对下一个接收者的引用。将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 各人自扫门前雪，莫管他们瓦上霜 解耦处理逻辑 踢皮球 迭代器模式（Iterator Pattern） 提供一种方法顺序访问一个聚合对象中的各个元素 流水线上坐一天，每个包裹扫一遍 统一对集合的访问方式 逐个检票进站 命令模式（Command Pattern） 将请求封装成命令，并记录下来，能够撤销与重做 运筹帷幄之中，决胜千里之外 解耦请求和处理 遥控器 状态模式（State Pattern 根据不同的状态做出不同的行为 状态驱动行为，行为决定状态 绑定状态和行为 订单状态跟踪 备忘录模式（Memento Pattern） 保存对象的状态，在需要时进行恢复 失足不成千古恨，想重来时就重来 备份、后悔机制 草稿箱 中介者模式（Mediator Pattern） 将对象之间的通信关联关系封装到一个中介类中单独处理，从而使其耦合松散 联系方式我给你，怎么搞定我不管 统一管理网状资源 朋友圈 解释器模式（Interpreter Pattern） 给定一个语言，定义它的语法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子 我想说”方言“，一切解释权都归我 实现特定语法解析 摩斯密码 观察者模式（Observer Pattern） 状态发生改变时通知观察者，一对多的关系 到点就通知我 解耦观察者与被观察者 闹钟 访问者模式（Visitor Pattern） 稳定数据结构，定义新的操作行为 横看成岭侧成峰，远近高低各不同 解耦数据结构和数据操作 KPI考核 #createPattern, #structurePattern, #behaviorPattern { font-weight: bold; } .yellowColor { color: orange; } .greenColor { color: forestgreen; } .blueColor { color: cornflowerblue; }","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"每日一练--观察者模式","slug":"设计模式--观察者模式","date":"2021-05-15T04:00:00.000Z","updated":"2022-05-26T18:18:19.913Z","comments":true,"path":"posts/22028/","link":"","permalink":"https://yugd.cn/posts/22028/","excerpt":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、责任链模式、策略模式、模板方法模式、迭代子模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下观察者模式：","text":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、责任链模式、策略模式、模板方法模式、迭代子模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下观察者模式： 写在前面 设计模式的六大原则 开闭原则、单一原则、 里式替换、依赖倒置、接口隔离、迪米特法则 在现实世界中，许多对象并不是独立存在的，其中一个对象的行为发生改变可能会导致一个或者多个其他对象的行为也发生改变，比如气象局的天气预报与听众。上述情况所对应的设计模式就是观察者模式（Observer Pattern）。它能够根据一个对象状态的改变来通知并更细依赖其的对象。 介绍定义 观察者（Observer）模式的定义：指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 这种模式有时又称作发布-订阅模式、模型-视图模式，它是对象行为型模式。 优点： 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则。 高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象 目标与观察者之间建立了一套触发机制。 缺点： 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用。 当观察者对象很多时，通知的发布会花费很多时间，影响程序的效率。 使用场景： 微信朋友圈动态通知、消息通知、邮件通知、广播通知、桌面程序的事件响应等 MQ，异步队列等 描述4 个角色： 抽象主题（Subject）角色：也叫抽象目标类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法。 具体主题（Concrete Subject）角色：也叫具体目标类，它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象。 抽象观察者（Observer）角色：它是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用。 具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态。 UML结构图 代码实现步骤 1，创建主题Subject 123456789101112131415161718192021222324/** * 主题 **/public class Subject &#123; //观察者数组 private Vector&lt;Observer&gt; oVector = new Vector&lt;&gt;(); //增加一个观察者 public void addObserver(Observer observer) &#123; this.oVector.add(observer); &#125; //删除一个观察者 public void deleteObserver(Observer observer) &#123; this.oVector.remove(observer); &#125; //通知所有观察者 public void notifyObserver() &#123; for (Observer observer : this.oVector) &#123; observer.update(); &#125; &#125;&#125; 步骤 2， 创建抽象观察者Observer 1234567/** * 抽象观察者 **/public interface Observer &#123; //更新 void update();&#125; 步骤 3，创建具体主题 12345678910/** * 具体主题 **/public class ConcreteSubject extends Subject &#123; //具体业务 public void doSomething() &#123; System.out.println(\"主题:执行具体业务\"); super.notifyObserver(); &#125;&#125; 步骤 4，创建具体观察者 12345678910/** * 具体观察者 **/public class ConcreteObserver implements Observer &#123; //实现Observer接口 @Override public void update() &#123; System.out.println(\"观察者:收到消息，进行处理\"); &#125;&#125; 步骤 5，创建 Client 客户端 123456789101112public class Client &#123; public static void main(String[] args) &#123; //创建一个主题 ConcreteSubject subject = new ConcreteSubject(); //定义一个观察者 Observer observer = new ConcreteObserver(); //观察 subject.addObserver(observer); //开始活动 subject.doSomething(); &#125;&#125; 结果 总结当一个对象的改变需要同时改变其它对象（具有连带关系的），并且它不知道具体有多少对象有待改变的时候，应该考虑使用观察者模式。 观察者模式所做的工作就是在解除耦合","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"结构型模式","slug":"结构型模式","permalink":"https://yugd.cn/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"每日一练--外观模式","slug":"设计模式--外观模式","date":"2021-05-14T01:00:00.000Z","updated":"2022-05-26T18:18:21.900Z","comments":true,"path":"posts/18482/","link":"","permalink":"https://yugd.cn/posts/18482/","excerpt":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、责任链模式、策略模式、模板方法模式、迭代子模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下外观模式：","text":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、责任链模式、策略模式、模板方法模式、迭代子模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下外观模式： 写在前面 设计模式的六大原则 开闭原则、单一原则、 里式替换、依赖倒置、接口隔离、迪米特法则 外观模式（Facade Pattern）又称为“门面模式”，是 Java 中最简单的设计模式之一。这种类型的设计模式属于结构型模式，涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。 介绍意图：目的不是给予子系统添加新的功能接口，而是为了让外部减少与子系统内多个模块的交互，松散耦合，从而让外部能够更简单地使用子系统。 主要解决：降低调用方的使用接口的复杂逻辑组合。 何时使用：希望隐藏系统的复杂性，并向客户端提供了一个可以访问系统的接口。 如何解决：提供一个高层次的接口,使得子系统更易于使用。 优点： 减少系统的相互依赖 提高了灵活性 提高安全性 缺点：不符合开闭原则 使用场景： 为一个复杂的模块或子系统提供一个供外界访问的接口 子系统相对独立——外界对子系统的访问只要黑箱操作即可 预防低水平人员带来的风险扩散 注意事项： 一个子系统可以有多个门面 门面已经庞大到不能忍受的程度 子系统可以提供不同访问路径 描述3 个角色： 门面 (Facade) 角色 ：客户端可以调用这个角色的方法。此角色知晓相关的（一个或者多个）子系统的功能和责任。在正常情况下，本角色会将所有从客户端发来的请求委派到相应的子系统去。 子系统 (SubSystem) 角色 ：可以同时有一个或者多个子系统。每个子系统都不是一个单独的类，而是一个类的集合。每个子系统都可以被客户端直接调用，或者被门面角色调用。子系统并不知道门面的存在，对于子系统而言，门面仅仅是另外一个客户端而已。 客户 (client) 角色：通过调用门面 (Facede) 来完成要实现的功能。 代码实现步骤 1，创建子系统的实现类 ModuleA、ModuleB、ModuleC 12345678910public class ModuleA &#123; // 对外提供的方法 public void testA() &#123; System.out.println(\"调用ModuleA中的testA方法\"); &#125; // 对内提供的方法 public void testAN() &#123; System.out.println(\"ModuleA中的testAN方法, 对内提供的方法\"); &#125;&#125; 1234567891011public class ModuleB &#123; // 对外提供的方法 public void testB() &#123; System.out.println(\"调用ModuleB中的testB方法\"); &#125; // 对内提供的方法 public void testBN() &#123; System.out.println(\"ModuleB中的testBN方法, 对内提供的方法\"); &#125;&#125; 1234567891011public class ModuleC &#123; // 对外提供的方法 public void testC() &#123; System.out.println(\"调用ModuleC中的testC方法\"); &#125; // 对内提供的方法 public void testCN() &#123; System.out.println(\"ModuleC中的testCN方法, 对内提供的方法\"); &#125;&#125; 步骤 2，创建门面类 Facade 1234567891011121314151617public class Facade &#123; private ModuleA moduleA = new ModuleA(); private ModuleB moduleB = new ModuleB(); private ModuleC moduleC = new ModuleC(); public void testFacadeA() &#123; moduleA.testA(); &#125; public void testFacadeB() &#123; moduleB.testB(); &#125; public void testFacadeC() &#123; moduleC.testC(); &#125;&#125; 步骤 3，创客户类 Client 1234567891011121314151617181920public class Client &#123; public static void main(String[] args) &#123; facadeA(); facadeB(); facadeC(); &#125; public static void facadeA() &#123; new Facade().testFacadeA(); &#125; public static void facadeB() &#123; new Facade().testFacadeB(); &#125; public static void facadeC() &#123; new Facade().testFacadeC(); &#125;&#125; 结果 123调用ModuleA中的testA方法调用ModuleB中的testB方法调用ModuleC中的testC方法 总结松散耦合: 门面模式松散了客户端与子系统的耦合关系，让子系统内部的模块能更容易扩展和维护。 简单易用: 门面模式让子系统更加易用，客户端不再需要了解子系统内部的实现，也不需要跟众多子系统内部的模块进行交互，只需要跟门面类交互就可以了。 更好的划分访问层次: 通过合理使用 Facade，可以帮助我们更好地划分访问的层次。 有些方法是对系统外的，有些方法是系统内部使用的。把需要暴露给外部的功能集中到门面中，这样既方便客户端使用，也很好地隐藏了内部的细节。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"结构型模式","slug":"结构型模式","permalink":"https://yugd.cn/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"每日一练--责任链模式","slug":"设计模式--责任链模式","date":"2021-05-13T01:00:00.000Z","updated":"2022-05-26T18:18:23.755Z","comments":true,"path":"posts/41561/","link":"","permalink":"https://yugd.cn/posts/41561/","excerpt":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、责任链模式、策略模式、模板方法模式、迭代子模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下责任链模式：","text":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、责任链模式、策略模式、模板方法模式、迭代子模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下责任链模式： 写在前面 设计模式的六大原则 开闭原则、单一原则、 里式替换、依赖倒置、接口隔离、迪米特法则 责任链模式（Chain of Responsibility Pattern）是 Java 中最无感知且常用的设计模式之一。这种类型的设计模式属于行为型模式，这种模式给予请求的类型，对请求的发送者和接收者进行解耦。 这种模式通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。 介绍意图：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 主要解决：职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 何时使用：在处理消息的时候以过滤很多道。 如何解决：拦截的类都实现统一接口。 关键代码：Handler 里面聚合它自己，在 HandlerRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。 应用实例： SpringMVC 中的拦截器（Interceptor）。 JS 中的事件冒泡。 JAVA WEB 中 Apache Tomcat 对 Encoding 的处理，Struts2 的拦截器，jsp servlet 的 Filter。 优点： 降低耦合度。它将请求的发送者和接收者解耦。 简化了对象。使得对象不需要知道链的结构。 增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 增加新的请求处理类很方便。 缺点： 不能保证请求一定被接收。 系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 可能不容易观察运行时的特征，有碍于除错。 使用场景： 有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。 可动态指定一组对象处理请求。 注意事项：在 JAVA WEB 中遇到很多应用。 描述责任链模式是一种行为设计模式，允许你将请求沿着处理链发送，然后处理者都可对其进行处理，完成后可以再将其传递给下一个处理者。下面将会举例说明什么是责任链模式，责任链模式该如何使用。 代码实现步骤 1，创建传入的对象 12345678910111213141516171819202122232425public class Times &#123; private int time; public Times() &#123; &#125; public Times(int time) &#123; this.time = time; &#125; public int getTime() &#123; return time; &#125; public void setTime(int time) &#123; this.time = time; &#125; @Override public String toString() &#123; return \"Times&#123;\" + \"time=\" + time + '&#125;'; &#125;&#125; 步骤 2，创建处理器抽象接口 12345678910111213public abstract class Handler &#123; protected Handler handler; public void setHandler(Handler handler)&#123; this.handler = handler; &#125; /** * 抽象的请求拦截方法 * @param times */ public abstract void handleRequest(Times times);&#125; 步骤 3，创建继承处理器抽象接口的实现类 1、2、3 12345678910111213141516171819202122232425262728293031323334353637383940414243public class FirstInterview extends Handler &#123; @Override public void handleRequest(Times times) &#123; // 条件判断是否是属于当前Handler的处理范围之内，不是则向下传递Handler处理器 if (times.getTime() == 1) &#123; // 假设这里是处理的业务逻辑代码 System.out.println(\"第一次面试\" + times.getTime()); return; &#125; handler.handleRequest(times); &#125;&#125;public class SecondInterview extends Handler &#123; @Override public void handleRequest(Times times) &#123; // 条件判断是否是属于当前Handler的处理范围之内，不是则向下传递Handler处理器 if (times.getTime() == 2) &#123; // 假设这里是处理的业务逻辑代码 System.out.println(\"第二次面试\" + times.getTime()); return; &#125; handler.handleRequest(times); &#125;&#125;public class ThreeInterview extends Handler &#123; @Override public void handleRequest(Times times) &#123; // 条件判断是否是属于当前Handler的处理范围之内，不是则向下传递Handler处理器 if (times.getTime() == 3) &#123; // 假设这里是处理的业务逻辑代码 System.out.println(\"第N次面试, 恭喜面试通过，HR会跟你联系！！！\"); &#125; else &#123; System.out.println(\"潜心修炼~ 再接再厉~\"); &#125; &#125;&#125; 步骤 4，编写测试类进行验证 123456789101112131415161718192021public class Test &#123; public static void main(String[] args) &#123; Handler first = new FirstInterview(); Handler second = new SecondInterview(); Handler three = new ThreeInterview(); //指定请求的处理的顺序 first.setHandler(second); second.setHandler(three); // 第一次面试 first.handleRequest(new Times(1)); // 第二次面试 first.handleRequest(new Times(2)); // time == 3,成功 // time &gt;=3 ,失败 // 第三次面试 first.handleRequest(new Times(5)); // 第N次面试 first.handleRequest(new Times(3)); &#125;&#125; 结果 1234第一次面试1第二次面试2潜心修炼~ 再接再厉~第N次面试, 恭喜面试通过，HR会跟你联系！！！ 总结如果业务需求需要很多很多的 if-else 结构或很长 switch-case 结构时候，并且后来还会在此基础上增加条件判断的时候，就需要使用责任链模式来进行重构，以便于日后代码的可维护性和可阅读性。 适用的场景 当必须按顺序执行多个处理者时，可以考虑使用责任链模式 如果处理者的顺序及其必须在运行时改变时，可以考虑使用责任链模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"行为型模式","slug":"行为型模式","permalink":"https://yugd.cn/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"每日一练--工厂模式","slug":"设计模式--工厂模式","date":"2021-05-11T03:58:58.000Z","updated":"2022-05-26T18:18:15.913Z","comments":true,"path":"posts/56835/","link":"","permalink":"https://yugd.cn/posts/56835/","excerpt":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、策略模式、模板方法模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下工厂模式：","text":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、策略模式、模板方法模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下工厂模式： 写在前面 设计模式的六大原则 开闭原则、单一原则、 里式替换、依赖倒置、接口隔离、迪米特法则 工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。 工厂模式可以分为三类： 简单工厂模式（Simple Factory） 工厂方法模式（Factory Method） 抽象工厂模式（Abstract Factory） 注意： 这三种工厂模式在设计模式的分类中都属于创建型模式，三种模式从上到下逐步抽象。 介绍意图：通过隐藏对象如何被创建和组合在一起达到使整个系统独立的目的。外界对于这些对象只需要知道它们共同的接口，而不清楚其具体的实现细节。 主要解决：工厂模式的主要功能就是帮助我们实例化对象。 何时使用：在任何需要生成复杂对象的地方。 如何解决：对象的实例化过程是通过工厂实现的，是用工厂代替 new 操作的。 优点 可以使代码结构清晰，有效地封装变化 在编程中，产品类的实例化有时候是比较复杂和多变的，通过工厂模式，将产品的实例化封装起来，使得调用者根本无需关心产品的实例化过程，只需依赖工厂即可得到自己想要的产品。 对调用者屏蔽具体的产品类 如果使用工厂模式，调用者只关心产品的接口就可以了，至于具体的实现，调用者根本无需关心。即使变更了具体的实现，对调用者来说没有任何影响。 降低耦合度 产品类的实例化通常来说是很复杂的，它需要依赖很多的类，而这些类对于调用者来说根本无需知道，如果使用了工厂方法，我们需要做的仅仅是实例化好产品类，然后交给调用者使用。对调用者来说，产品所依赖的类都是透明的。 工厂模式简单工厂模式为啥叫做简单工厂？ 因为原理真的很简单！ 先来想一个场景，当我们在做四则运算的时候，想要使用不同的运算的时候就要创建不同的类，并且要明确知道该类的名字。那么这种重复的创建类的工作其实可以放到一个统一的类中去管理。 这样的方法我们就叫做【简单工厂模式】，又被称为「静态工厂方法」模式。 定义提供一个创建对象实例的功能，而无需关心其具体实现。被创建实例的类型可以是接口、抽象类，也可以是具体的类。 优点 一个调用者想创建一个对象，只要知道其名称就可以了； 屏蔽产品的具体实现，调用者只关心产品的接口； 缺点当系统中的具体产品类不断增多时候，可能会出现要求工厂类根据不同条件创建不同实例的需求。 这种对条件的判断和对具体产品类型的判断交错在一起，很难避免模块功能的蔓延，对系统的维护和扩展非常不利； 简单工厂模式实现方式简单工厂模式包含 3 个角色（要素）： Factory：即工厂类， 简单工厂模式的核心部分，负责实现创建所有产品的内部逻辑；工厂类可以被外界直接调用，创建所需对象。 Product：抽象类产品， 它是工厂类所创建的所有对象的父类，封装了各种产品对象的公有方法，它的引入将提高系统的灵活性，使得在工厂类中只需定义一个通用的工厂方法，因为所有创建的具体产品对象都是其子类对象。 ConcreteProduct：具体产品， 它是简单工厂模式的创建目标，所有被创建的对象都充当这个角色的某个具体类的实例。它要实现抽象产品中声明的抽象方法。 UML 类图 代码示例IMask 接口 123public interface IMask &#123; void show();&#125; HighEndMask 类 123456public class HighEndMask implements IMask&#123; @Override public void show() &#123; System.out.println(\"我是高端口罩\"); &#125;&#125; LowEndMask 类 123456public class LowEndMask implements IMask &#123; @Override public void show() &#123; System.out.println(\"我的低端口罩\"); &#125;&#125; MaskFactory 类 1234567891011121314151617181920212223/** * &lt;p&gt; * 在创建方法中传入参数（这里的参数是type），根据参数来做条件判断，决定创建什么样的口罩、 * &lt;p&gt; * 所谓面向对象的开放-封闭原则，就是在程序中对“扩展”开放，对“修改”封闭。 * 如果每次业务改动都要增加新的 case，就涉及对旧有代码的修改，不但容易出错，可读性也不好 **/public class MaskFactory &#123; public IMask createMask(String type) &#123; IMask mask; switch (type) &#123; case \"高端口罩\": mask = new HighEndMask(); break; case \"低端口罩\": mask = new LowEndMask(); break; default: throw new UnsupportedOperationException(\"不支持该操作\"); &#125; return mask; &#125;&#125; Test 类 12345678910public class Test &#123; public static void main(String[] args) &#123; MaskFactory maskFactory = new MaskFactory(); IMask lowMask = maskFactory.createMask(\"高端口罩\"); IMask highMask = maskFactory.createMask(\"低端口罩\"); lowMask.show(); highMask.show(); &#125;&#125; 程序运行结果： 12我是高端口罩我的低端口罩 简单工厂模式存在的问题当我们需要增加一种口罩时，需要在MaskFactory类的代码，增加一个 case选项。这显然是违背开闭原则的。可想而知对于新产品的加入，工厂类是很被动的。 总结简单工厂模式所能创建的类只能是事先考虑到的，如果需要添加新的类，则就需要改变工厂类了。 工厂模式什么是工厂模式？ 我们常说的工厂模式，就是指【工厂方法模式】，也叫【虚拟构造器模式】或【多态工厂模式】。 定义定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类。工厂方法让类的实例化推迟到子类中进行。 优点 一个调用者想创建一个对象，只要知道其名称就可以了； 扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以； 屏蔽产品的具体实现，调用者只关心产品的接口； 缺点每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。 这并不是什么好事！ 工厂模式实现方式工厂方法模式包含 4 个角色（要素）： Product：抽象产品，定义工厂方法所创建的对象的接口，也就是实际需要使用的对象的接口； ConcreteProduct：具体产品，具体的 Product 接口的实现对象； Factory：工厂接口，也可以叫 Creator(创建器)，申明工厂方法，通常返回一个 Product 类型的实例对象； ConcreteFactory：工厂实现，或者叫 ConcreteCreator(创建器对象)，覆盖 Factory 定义的工厂方法，返回具体的 Product 实例； UML 类图 代码示例IMask 接口 123public interface IMask &#123; void show();&#125; HighEndMask 类 123456public class HighEndMask implements IMask &#123; @Override public void show() &#123; System.out.println(\"我是高端口罩\"); &#125;&#125; LowEndMask 类 123456public class LowEndMask implements IMask &#123; @Override public void show() &#123; System.out.println(\"我的低端口罩\"); &#125;&#125; MaskFactory 接口 12345678910/** * 口罩工厂 **/public interface MaskFactory &#123; /** * 制造口罩的工艺 * @return */ IMask createMask();&#125; HighMaskFactory 类 123456public class HighMaskFactory implements MaskFactory &#123; @Override public IMask createMask() &#123; return new HighEndMask(); &#125;&#125; LowMaskFactory 类 123456public class LowMaskFactory implements MaskFactory&#123; @Override public IMask createMask() &#123; return new LowEndMask(); &#125;&#125; Test 类 12345678public class Test &#123; public static void main(String[] args) &#123; MaskFactory highMaskFactory = new HighMaskFactory(); highMaskFactory.createMask().show(); MaskFactory lowMaskFactory = new LowMaskFactory(); lowMaskFactory.createMask().show(); &#125;&#125; 程序运行结果： 12我是高端口罩我的低端口罩 有没有发现，当我们需要新增一个口罩产品的时候，要为为相应的产品增加相应的工厂对象即可！ 总结 工厂方法模式是简单工厂模式的进一步抽象和推广； 由于使用了面向对象的多态性，工厂方法模式保持了简单工厂模式的优点，而且克服了它的缺点； 工厂方法模式可以允许系统在不修改工厂角色的情况下引进新产品；","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"创建型模式","slug":"创建型模式","permalink":"https://yugd.cn/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"每日一练--单例模式","slug":"设计模式--单例模式","date":"2021-05-10T03:58:58.000Z","updated":"2022-05-26T18:18:10.838Z","comments":true,"path":"posts/32074/","link":"","permalink":"https://yugd.cn/posts/32074/","excerpt":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、策略模式、模板方法模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下单例模式：","text":"每天一篇重点设计模式（Java版） 总体来说设计模式分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式 行为型模式（11种）：观察者模式、策略模式、模板方法模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 本篇着重介绍一下单例模式： 写在前面 设计模式的六大原则 开闭原则、单一原则、 里式替换、依赖倒置、接口隔离、迪米特法则 单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 注意： 1、单例类只能有一个实例。 2、单例类必须自己创建自己的唯一实例。 3、单例类必须给所有其他对象提供这一实例。 介绍意图：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 主要解决：一个全局使用的类频繁地创建与销毁。 何时使用：当您想控制实例数目，节省系统资源的时候。 如何解决：判断系统是否已经有这个单例，如果有则返回，如果没有则创建。 关键代码：构造函数是私有的。 单例模式的几种实现方式 1、懒汉式，线程不安全是否 Lazy 初始化：是 是否多线程安全：否 实现难度：易 描述：这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。 步骤 1，创建一个 Singleton 类 1234567891011121314public class Singleton1 &#123; private static Singleton1 instance; private Singleton1() &#123; System.out.println(\"懒汉式\"); &#125; public static synchronized Singleton1 getInstance() &#123; if (instance == null)&#123; instance = new Singleton1(); &#125; return instance; &#125;&#125; 步骤 2，从 singleton 类获取唯一的对象 1234567public class Test &#123; public static void main(String[] args) &#123; // 懒汉式 Singleton1 instance1 = Singleton1.getInstance(); System.out.println(instance1); &#125;&#125; 2、饿汉式是否 Lazy 初始化：否 是否多线程安全：是 实现难度：易 描述：这种方式比较常用，但容易产生垃圾对象。 优点：没有加锁，执行效率会提高。 缺点：类加载时就初始化，浪费内存。 它基于 classloader 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。 步骤 1，创建一个 Singleton 2类 1234567891011public class Singleton2 &#123; private static Singleton2 instance = new Singleton2(); private Singleton2() &#123; System.out.println(\"饿汉式\"); &#125; public static Singleton2 getInstance() &#123; return instance; &#125;&#125; 步骤 2，从 singleton2 类获取唯一的对象 1234567public class Test &#123; public static void main(String[] args) &#123; // 饿汉式 Singleton2 instance2 = Singleton2.getInstance(); System.out.println(instance2); &#125;&#125; 3、双检锁/双重校验锁（DCL）是否 Lazy 初始化：是 是否多线程安全：是 实现难度：较复杂 描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。 步骤 1，创建一个 Singleton3 类 123456789101112131415161718public class Singleton3 &#123; private volatile static Singleton3 instance; private Singleton3() &#123; System.out.println(\"双重检查模式 (DCL)\"); &#125; public static Singleton3 getInstance() &#123; if (instance == null) &#123; synchronized (Singleton3.class) &#123; if (instance == null) &#123; instance = new Singleton3(); &#125; &#125; &#125; return instance; &#125;&#125; 步骤 2，从 singleton3 类获取唯一的对象 1234567public class Test &#123; public static void main(String[] args) &#123; // 双重检查模式 (DCL) Singleton3 instance3 = Singleton3.getInstance(); System.out.println(instance3); &#125;&#125; 4、静态内部类是否 Lazy 初始化：是 是否多线程安全：是 实现难度：一般 步骤 1，创建一个 Singleton4 类 1234567891011121314public class Singleton4 &#123; private Singleton4() &#123; System.out.println(\"静态内部类\"); &#125; public static class SingletonHolder &#123; private static final Singleton4 INSTANCE = new Singleton4(); &#125; public static final Singleton4 getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 步骤 2，从 singleton4 类获取唯一的对象 1234567public class Test &#123; public static void main(String[] args) &#123; // 静态内部类 Singleton4 instance4 = Singleton4.getInstance(); System.out.println(instance4); &#125;&#125; 5、枚举是否 Lazy 初始化：否 是否多线程安全：是 实现难度：易 步骤 1，创建一个 Singleton5 类 12345678910111213141516171819202122public enum Singleton5 &#123; INSTANCE(\"枚举类\"); private String msg; Singleton5(String msg) &#123; this.msg = msg; System.out.println(getMsg()); &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; public void doOtherSomeThing() &#123; &#125;&#125; 步骤 2，从 singleton5类获取唯一的对象 1234567public class Test &#123; public static void main(String[] args) &#123; // 枚举 Singleton5 instance5 = Singleton5.INSTANCE; System.out.println(instance5); &#125;&#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"创建型模式","slug":"创建型模式","permalink":"https://yugd.cn/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"Nginx","slug":"面试--Nginx","date":"2021-04-18T14:18:30.000Z","updated":"2022-05-26T18:17:26.295Z","comments":true,"path":"posts/9355/","link":"","permalink":"https://yugd.cn/posts/9355/","excerpt":"说到 Nginx 我们脑海中随之出现的词汇想必是 反向代理 了 但是 Nginx 的作用不只只是反向代理，还有我们所熟悉的 负载均衡，动静分离 … … 话不多说，一起来看一下吧啦吧啦~","text":"说到 Nginx 我们脑海中随之出现的词汇想必是 反向代理 了 但是 Nginx 的作用不只只是反向代理，还有我们所熟悉的 负载均衡，动静分离 … … 话不多说，一起来看一下吧啦吧啦~ Nginx 介绍百度百科 Nginx (engine x) 是一个高性能的 HTTP 和 反向代理 web服务器，同时也提供了 IMAP/POP3/SMTP 服务。Nginx 是由伊戈尔·赛索耶夫为俄罗斯访问量第二的 Rambler.ru 站点（俄文：Рамблер）开发的，第一个公开版本 0.1.0 发布于 2004 年 10 月 4 日。 Nginx常用功能 反向代理 负载均衡 web缓存 一下将从这 3 个角度分别来说一下大名鼎鼎的 Nginx 反向代理1、无代理客户端直接访问服务器。 2、代理类似于客户端与服务端中间的媒介（简单） 3、正向代理访问 url : nginx 的 url (域名) 正向代理服务器位于客户端和服务器之间，为了向服务器获取数据，客户端要向代理服务器发送一个请求，并指定目标服务器，代理服务器将目标服务器返回的数据转交给客户端。 典型的例子：VPN 就是做正向代理的。 当我们电脑接入 VPN 后，我们对外 IP 地址就会变成 VPN 服务器的 公网 IP，我们请求或接受任何数据都会通过这个VPN 服务器然后传入到我们本机。 4、反向代理访问 url : target 的 url (域名) nginx.conf 配置文件中增加如下配置： 123456789server &#123; # 进入 nginx 服务器 listen 80; # 监听的是 80 端口 server_name https://music.youtube.com; # 访问域名为 music.youtube.com location / &#123; # nginx 所代理的相关信息 proxy_pass http://127.0.0.1:8080; # 转到 127.0.0.1:8080 路径 index index.html index.htm index.jsp; # 资源 &#125;&#125; 助记如果我们客户端自己用，就是正向代理。 如果实在服务器用，我们用户无感知，就是反向代理。 负载均衡负载均衡类型广义上的负载均衡器大概可以分为 3 类 DNS 方式实现负载均衡 硬件负载均衡 软件负载均衡。 1、DNS 实现负载均衡DNS 实现负载均衡是最基础简单的方式。 一个域名通过 DNS 解析到多个 IP，每个 IP 对应不同的服务器实例，这样就完成了流量的调度。 优点 实现简单，成本低，无需自己开发或维护负载均衡设备。 缺点 服务器故障切换延迟大，服务器升级不方便 流量调度不均衡，粒度太粗 流量分配策略太简单，支持的算法太少 DNS 支持的 IP 列表有限制 2、软件负载均衡 Nginx 为例 随机算法 (Random)算法将请求随机分发到候选服务器。 随机算法 适合服务器硬件相同的场景。当调用量较小的时候，可能负载并不均匀，调用量越大，负载越均衡。 加权随机算法 (Weighted Random)算法在随机算法的基础上，按照概率调整权重，进行负载分配。 轮询算法轮询 (Round Robin) 算法的策略是：将请求依次分发到候选服务器。 如下图所示，负载均衡器收到来自客户端的 6 个请求，[1, 3, 5] 的请求会被发送到服务器 1，[2, 4, 6] 的请求会被发送到服务器 2。 该算法适合场景 各服务器处理能力相近，且每个事务工作量差异不大。如果存在较大差异，那么处理较慢的服务器就可能会积压请求，最终无法承担过大的负载。 加权轮询算法加权轮询 (Weighted Round Robbin) 算法在轮询算法的基础上，增加了权重属性来调节转发服务器的请求数目。性能高、处理速度快的节点应该设置更高的权重，使得分发时优先将请求分发到权重较高的节点上。 如下图所示，服务器 1 设置权重为 4，服务器 2 设置权重为 2，负载均衡器收到来自客户端的 6 个请求，那么 [1, 2, 3, 4] 请求会被发送到服务器 1，[5, 6] 请求会被发送到服务器 2。 最小活跃数最小活跃数（Least Active）算法 将请求分发到连接数/请求数最少的候选服务器（目前处理请求最少的服务器）。 特点：根据候选服务器当前的请求连接数，动态分配。 场景：适用于对系统负载较为敏感或请求连接时长相差较大的场景。 由于每个请求的连接时长不一样，如果采用简单的轮循或随机算法，都可能出现某些服务器当前连接数过大，而另一些服务器的连接过小的情况，这就造成了负载并非真正均衡。 虽然，轮询或算法都可以通过加权重属性的方式进行负载调整，但加权方式难以应对动态变化。 例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 [1, 3] 很快就断开连接，此时只有 [5] 请求连接服务器 1；[2, 4, 6] 请求被发送到服务器 2，没有请求连接断开。该系统继续运行时，服务器 2 会承担过大的负载。 最小活跃数算法会记录当前时刻，每个候选节点正在处理的连接数，然后选择连接数最小的节点。 该策略能够动态、实时地反应服务器的当前状况，较为合理地将负责分配均匀，适用于对当前系统负载较为敏感的场景。 例如下图中，服务器 1 当前连接数最小 (无压力)，那么新到来的请求 6 就会被发送到服务器 1 上。 web缓存静态资源的服务器Nginx 本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用 Nginx 来做服务器，同时现在也很流行动静分离，就可以通过 Nginx 来实现，首先看看 Nginx 做静态资源服务器. 这样如果访问 http://localhost 就会默认访问到 D://www/data目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署 关键命令：root 当只有静态资源的时候，就可以使用Nginx来做服务器 123456789101112131415upstream test &#123; server localhost:8080; server localhost:8081;&#125;server &#123; listen 80; server_name localhost; client_max_body_size 1024M; location / &#123; proxy_pass http://test; proxy_set_header Host $host:$server_port; &#125;&#125; 动静分离动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来。 1234567891011121314151617181920212223242526272829upstream test&#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 80; server_name localhost; location / &#123; root e:/wwwroot; index index.html; &#125; # 所有静态请求都由nginx处理，存放目录为html location ~ .(gif|jpg|jpeg|png|bmp|swf|css|js)$ &#123; root e:/wwwroot; &#125; # 所有动态请求都转发给tomcat处理 location ~ .(do)$ &#123; proxy_pass http://test; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root e:/wwwroot; &#125; &#125; Nginx 操作查看版本号1[root@localhost sbin]# ./nginx -v Nginx的启动、停止与重启启动启动代码格式：nginx安装目录地址 -c nginx配置文件地址 1[root@localhost sbin]# ./nginx 例如： 1[root@localhost sbin]# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 关闭 Nginx1[root@localhost sbin]# ./nginx -s stop 停止nginx的停止有三种方式 从容停止1、查看进程号 1[root@localhost ~]# ps -ef|grep nginx 2、杀死进程 1[root@localhost ~]# kill -QUIT 29321 快速停止1、查看进程号 1[root@localhost ~]# ps -ef|grep nginx 2、杀死进程 123[root@localhost ~]# kill -TERM 29321 或[root@localhost ~]# kill -INT 29321 强制停止1[root@localhost ~]# pkill -9 nginx 重启1、验证nginx配置文件是否正确 进入nginx安装目录sbin下，输入命令./nginx -t 2、重启Nginx服务 进入nginx可执行目录sbin下，输入命令 ./nginx -s reload 即可 1[root@localhost ~]# ./nginx -s reload Nginx 文件结构123456789101112131415161718192021222324252627... #全局块events &#123; #events块 ...&#125;http #http块&#123; ... #http全局块 server #server块 &#123; ... #server全局块 location [PATTERN] #location块 &#123; ... &#125; location [PATTERN] &#123; ... &#125; &#125; server &#123; ... &#125; ... #http全局块&#125; 解释 1、全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。 2、events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。 3、http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 4、server块：配置虚拟主机的相关参数，一个http中可以有多个server。 5、location块：配置请求的路由，以及各种页面的处理情况。 123456789101112131415161718192021222324252627282930313233343536373839########### 每个指令必须有分号结束。##################user administrator administrators; #配置用户或者组，默认为nobody nobody。#worker_processes 2; #允许生成的进程数，默认为1#pid /nginx/pid/nginx.pid; #指定nginx进程运行文件存放地址error_log log/error.log debug; #制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别以此为：debug|info|notice|warn|error|crit|alert|emergevents &#123; accept_mutex on; #设置网路连接序列化，防止惊群现象发生，默认为on multi_accept on; #设置一个进程是否同时接受多个网络连接，默认为off #use epoll; #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport worker_connections 1024; #最大连接数，默认为512&#125;http &#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型，默认为text/plain #access_log off; #取消服务日志 log_format myFormat '$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for'; #自定义格式 access_log log/access.log myFormat; #combined为日志格式的默认值 sendfile on; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。 sendfile_max_chunk 100k; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。 keepalive_timeout 65; #连接超时时间，默认为75s，可以在http，server，location块。 upstream mysvr &#123; server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #热备 &#125; error_page 404 https://www.baidu.com; #错误页 server &#123; keepalive_requests 120; #单连接请求上限次数。 listen 4545; #监听端口 server_name 127.0.0.1; #监听地址 location ~*^.+$ &#123; #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。 #root path; #根目录 #index vv.txt; #设置默认页 proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 deny 127.0.0.1; #拒绝的ip allow 172.18.5.54; #允许的ip &#125; &#125;&#125; 上面是nginx的基本配置，需要注意的有以下几点： 1、几个常见配置项： 1.$remote_addr 与 $http_x_forwarded_for 用以记录客户端的ip地址； 2.$remote_user ：用来记录客户端用户名称； 3.$time_local ： 用来记录访问时间与时区； 4.$request ： 用来记录请求的url与http协议； 5.$status ： 用来记录请求状态；成功是200； 6.$body_bytes_s ent ：记录发送给客户端文件主体内容大小； 7.$http_referer ：用来记录从那个页面链接访问过来的； 8.$http_user_agent ：记录客户端浏览器的相关信息； 2、惊群现象：一个网路连接到来，多个睡眠的进程被同时叫醒，但只有一个进程能获得链接，这样会影响系统性能 3、每个指令必须有分号结束","categories":[{"name":"服务器","slug":"服务器","permalink":"https://yugd.cn/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"tags":[{"name":"反向代理","slug":"反向代理","permalink":"https://yugd.cn/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"}]},{"title":"RabbitMQ","slug":"面试--RabbitMQ","date":"2021-04-05T14:29:58.000Z","updated":"2022-05-26T18:17:28.143Z","comments":true,"path":"posts/33708/","link":"","permalink":"https://yugd.cn/posts/33708/","excerpt":"","text":"一、RabbitMQ 消息队列消息指的是两个应用间传递的数据。数据的类型有很多种形式，可能只包含文本字符串，也可能包含嵌入对象。 “消息队列(Message Queue)”是在消息的传输过程中保存消息的容器。在消息队列中，通常有生产者和消费者两个角色。生产者只负责发送数据到消息队列，谁从消息队列中取出数据处理，他不管。消费者只负责从消息队列中取出数据处理，他不管这是谁发送的数据。 1、AMQPPublisher 消息的生产者。也是一个向交换器Exchange发送消息的客户端应用程序。 Consumer 消息的消费者。表示一个从消息队列中取得消息的客户端应用程序。 Server/Broker 又称Broker，接受客户端的连接，实现AMQP实体服务。 Virtual host 虚拟地址，用于进行逻辑隔离，最上层的消息路由。 表示一批交换器，消息队列和相关对象。一个Virtual Host里面可以有若干个Exchange和Queue，同一个Virtual Host里面不能有相同名称的Exchange和Queue。 虚拟主机是共享相同的身份认证和加密环境的独立服务器域，每个vhost本质上就是一个mini版本的RabbitMQ服务器，拥有自己的队列、交换器、绑定和权限机制。vhost是AMQP概念的基础，必须在链接时指定，RabbitMQ默认的vhost是“/”。 Message 消息，服务器和应用程序之间传送的数据。消息是不具名的，由Properties和Body组成（消息头和消息体）。Properties可以对消息进行修饰，比如消息的优先级、延迟等高级特性；Body这就是消息体内容。 Exchange 交换机，接收生产者发送的消息，根据路由键转发消息到绑定的队列。 三种常见的交换机类型： 1、direct（发布与订阅，完全匹配） 2、fanout（广播） 3、topic（主题，规则匹配） Binding 绑定。Exchange和Queue之间的虚拟连接，binding中可以包含routing key。 一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Routing key 路由键。一个路由规则，虚拟机可用它来确定如何路由一个特定消息。 队列通过路由键绑定到交换机。 消息发送到MQ服务器时，消息将拥有一个路由键，即便是空的。RabbitMQ也会将其和绑定使用的路由键进行匹配。 如果匹配，消息将投递到该队列；如果不匹配，消息将会进入黑洞。 Connection 连接，应用程序与Broker的TCP网络连接。 Channel 网络信道，是TCP里面的虚拟连接。几乎所有的操作都在Channel中进行， Channel是进行消息读写的通道。客户端可以建立多个Channel，每个Channel代表一个会话任务（类似数据库中Connection中的session）。例如：电缆相当于TCP，信道是一个独立光纤束，一条TCP连接上创建多条信道是没有问题的。 TCP一旦打开，就会创建AMQP信道。 无论是发布消息、接收消息、订阅队列，这些动作都是通过信道完成的。 RabbitMQ为什么需要信道？为什么不是直接通信？ 1、TCP的创建和销毁开销特别大。创建需要3次握手，销毁需要4次分手； 2、如果不用信道，那应用程序就会以TCP连接RabbitMQ，高峰时每秒成千上万条连接会造成资源巨大浪费，而且操作系统每秒处理TCP连接数也是有限制的，必定造成性能瓶颈； 3、信道的原理是一条线程一条通道，多条线程多条通道同用一条TCP连接。一条TCP连接可以容纳无限的信道，即使每秒成千上万的请求也不会成为性能瓶颈。 Queue 也称为Message Queue（消费者创建），消息队列，保存消息并将它们转发给消费者。它是消息的容器，也是消息的终点。一个消息可以投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列上将其取走。 2、RabbitMQ 交换机 Exchange交换机，接收消息，并根据路由键转发消息所绑定的队列。 交换机属性： Name：交换机名称 Type：交换机类型direct、topic、fanout、headers Durability：是否需要持久化（true表示需要持久化） Auto Delete：当最后一个绑定到Exchange上的队列删除后，自动删除该Exchange Internal：当前Exchange是否用于RabbitMQ内部使用，默认为false（很多场景都不会用到该设置） Arguments：扩展参数，用于扩展AMQP协议自制定化使用 1、Direct Exchange所有发送到Direct Exchange的消息被转发到RouteKey中指定Queue。 注意：Direct模式可以使用RabbitMQ自带的Exchange：default Exchange，所以不需要将Exchange进行任何绑定（binding）操作，消息传递时，RouteKey必须完全匹配才会被队列接收，否则该消息会抛弃。 2、Topic Exchange所有发送到Topic Exchange的消息被转发到所有关心RouteKey中指定Topic的Queue上。 Exchange将RouteKey和某个Topic进行模糊匹配，此时队列需要绑定一个Topic。 注：可以使用通配符进行模糊匹配。 3、Fanout ExchangeFanout（群发）不处理路由键，只需要简单的将队列绑定到交换机上。 发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。 Fanout交换机转发消息是最快的。 3、RabbitMQ 消息可靠性1. 可靠性投递什么是生产端的可靠性投递？ 保障消息的成功发出； 保障MQ节点的成功接收； 发送端收到MQ节点（Broker）确认应答ACK； 完善的消息进行补偿机制。 2.解决方案1、消息落库/持久化消息信息落库（即消息持久化），对消息状态进行打标： 这种方案需要对数据库进行两次持久化操作 2.延迟投递消息落库在高并发场景下，数据库IO压力大，不适用。互联网大厂一般采用的是延迟投递，做二次检查，回调检查。 4、RabbitMQ 消息幂等性幂等性幂等性即对数据进行若干次操作，仍然保证正确。 消费端实现幂等性，就意味着，我们的消息永远不会消费多次，即使收到多条一样的消息。 二、RabbitMQ 消息队列的使用主要有三个作用： 解耦 异步 削峰 RabbitMQ几种典型模式 单模式Simple 工作模式Work 发布订阅模式Publish/Subscribe 路由模式Routing 通配符模式Topics 远程调用模式RPC 模式1：简单模式【Simple / HelloWorld 单生产单消费】 简单的发送与接收，没有特别的处理。 模式2：工作模式【Work单发送多接收，拿到消息即销毁】 一个生产者端，多个消费者端。示例中为了保证消息发送的可靠性，不丢失消息，使消息持久化了。同时为了防止接收端在处理消息时down掉，只有在消息处理完成后才发送消息确认。 模式3：发布、订阅模式【Publish/Subscribe】 使用场景：发布、订阅模式，生产者端发送消息，多个消费者同时接收所有的消息。 模式4：路由模式【Routing】（direct 直接的） 生产者按routing key发送消息，不同的消费者端按不同的routing key接收消息。 模式5：通配符（或主题）模式【Topics ，按topic发送接收】 生产者端不只按固定的routing key发送消息，而是按字符串“匹配”发送，消费者端同样如此。与之前的路由模式相比，它将信息的传输类型的key更加细化，以“key1.key2.keyN…”的模式来指定信息传输的key的大类型和大类型下面的小类型，让消费者端可以更加精细的确认自己想要获取的信息类型。而在消费者端，不用精确的指定具体到哪一个大类型下的小类型的key，而是可以使用类似正则表达式(但与正则表达式规则完全不同)的通配符在指定一定范围或符合某一个字符串匹配规则的key，来获取想要的信息。“通配符交换机”（Topic Exchange）将路由键和某模式进行匹配。此时队列需要绑定在一个模式上。符号“#”匹配一个或多个词，符号“*”仅匹配一个词。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://yugd.cn/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://yugd.cn/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"Kafka","slug":"面试--Kafka","date":"2021-04-03T14:29:58.000Z","updated":"2022-05-26T18:17:08.715Z","comments":true,"path":"posts/13749/","link":"","permalink":"https://yugd.cn/posts/13749/","excerpt":"","text":"一、Kafka 是什么？Kafka。在流式计算中，Kafka 一般用来缓存数据，例如 Flink 通过消费 Kafka 的数据进行计算。 kafka是什么？ Apache Kafka 是一个开源 「消息」 系统，由 Scala 写成。是由 Apache 软件基金会开发的 一个开源消息系统项目。 Kafka 最初是由 LinkedIn 公司开发，用作 LinkedIn 的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础，现在它已被多家不同类型的公司作为多种类型的数据管道和消息系统使用。 「Kafka 是一个分布式消息队列」。Kafka 对消息保存时根据 Topic 进行归类，发送消息 者称为 Producer，消息接受者称为 Consumer，此外 kafka 集群有多个 kafka 实例组成，每个 实例(server)称为 broker。 无论是 kafka 集群，还是 consumer 都依赖于 「Zookeeper」 集群保存一些 meta 信息， 来保证系统可用性。 二、为什么要有 Kafka?「kafka」 之所以受到越来越多的青睐，与它所扮演的三大角色是分不开的的： 「消息系统」：kafka与传统的消息中间件都具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。与此同时，kafka还提供了大多数消息系统难以实现的消息顺序性保障及回溯性消费的功能。 「存储系统」：kafka把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效的降低了消息丢失的风险。这得益于其消息持久化和多副本机制。也可以将kafka作为长期的存储系统来使用，只需要把对应的数据保留策略设置为“永久”或启用主题日志压缩功能。 「流式处理平台」：kafka为流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理框架，比如窗口、连接、变换和聚合等各类操作。 Kafka 特性 分布式 具备经济、快速、可靠、易扩充、数据共享、设备共享、通讯方便、灵活等，分布式所具备的特性 高吞吐量 同时为数据生产者和消费者提高吞吐量 高可靠性 支持多个消费者，当某个消费者失败的时候，能够自动负载均衡 离线 能将消息持久化，进行批量处理 解耦 作为各个系统连接的桥梁，避免系统之间的耦合 三、Kafka 基本概念在深入理解 Kafka 之前，可以先了解下 Kafka 的基本概念。 一个典型的 Kafka 包含若干Producer、若干 Broker、若干 Consumer 以及一个 Zookeeper 集群。Zookeeper 是 Kafka 用来负责集群元数据管理、控制器选举等操作的。Producer 是负责将消息发送到 Broker 的，Broker 负责将消息持久化到磁盘，而 Consumer 是负责从Broker 订阅并消费消息。Kafka体系结构如下所示： 概念一：生产者（Producer）与消费者（Consumer）对于 Kafka 来说客户端有两种基本类型：「生产者」（Producer）和 「消费者」（Consumer）。除此之外，还有用来做数据集成的 Kafka Connect API 和流式处理的 「Kafka Streams」 等高阶客户端，但这些高阶客户端底层仍然是生产者和消费者API，只不过是在上层做了封装。 「Producer」 ：消息生产者，就是向 Kafka broker 发消息的客户端； 「Consumer」 ：消息消费者，向 Kafka broker 取消息的客户端； 概念二：Broker 和集群（Cluster）一个 Kafka 服务器也称为 「Broker」，它接受生产者发送的消息并存入磁盘；Broker 同时服务消费者拉取分区消息的请求，返回目前已经提交的消息。使用特定的机器硬件，一个 Broker 每秒可以处理成千上万的分区和百万量级的消息。 若干个 Broker 组成一个 「集群」（「Cluster」），其中集群内某个 Broker 会成为集群控制器（Cluster Controller），它负责管理集群，包括分配分区到 Broker、监控 Broker 故障等。在集群内，一个分区由一个 Broker 负责，这个 Broker 也称为这个分区的 Leader；当然一个分区可以被复制到多个 Broker 上来实现冗余，这样当存在 Broker 故障时可以将其分区重新分配到其他 Broker 来负责。下图是一个样例： 概念三：主题（Topic）与分区（Partition） 在 Kafka 中，消息以 「主题」（「Topic」）来分类，每一个主题都对应一个「「消息队列」」，这有点儿类似于数据库中的表。但是如果我们把所有同类的消息都塞入到一个“中心”队列中，势必缺少可伸缩性，无论是生产者/消费者数目的增加，还是消息数量的增加，都可能耗尽系统的性能或存储。 我们使用一个生活中的例子来说明：现在 A 城市生产的某商品需要运输到 B 城市，走的是公路，那么单通道的高速公路不论是在「A 城市商品增多」还是「现在 C 城市也要往 B 城市运输东西」这样的情况下都会出现「吞吐量不足」的问题。所以我们现在引入 「分区」（「Partition」）的概念，类似“允许多修几条道”的方式对我们的主题完成了水平扩展。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://yugd.cn/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://yugd.cn/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}]},{"title":"实践一下--工作常用小技巧2","slug":"工作经验2","date":"2021-04-02T01:00:00.000Z","updated":"2022-05-26T18:16:38.833Z","comments":true,"path":"posts/32841/","link":"","permalink":"https://yugd.cn/posts/32841/","excerpt":"工作常用小技巧 ( 10条 / 篇 ) 本篇着重介绍一下工作常用小技巧 写在前面 工作中经常会用到的小技巧，来让我们一起来看看？","text":"工作常用小技巧 ( 10条 / 篇 ) 本篇着重介绍一下工作常用小技巧 写在前面 工作中经常会用到的小技巧，来让我们一起来看看？ Java 中的数据转换问题java 中 BigDecimal 和 0 比较在 java 中判断一个 BigDecimal 的金额是否大于 0，通常用于两个金额差的比较。 举个荔枝 方法一： 1234567891011121314BigDecimal num = new BigDecimal(\"10\"); int i = num.compareTo(BigDecimal.ZERO); if(i == -1)&#123; //num 小于 0 例如：num = -10.00 &#125; if(i == 0)&#123; //num 等于 0， num = 0.00 &#125; if(i == 1)&#123; //num 大于 0 例如：num = 10.00 &#125; //compareTo(Bigdecimal bigdecimal), 返回0表示等于0，返回1表示大于0，返回-1表示小于0; 方法二： 1234BigDecimal num = new BigDecimal(\"10\"); if(num.equals(BigDecimal.ZERO))&#123; &#125; BigDecimal 的相关用法构造器描述 1234BigDecimal(int) //创建一个具有参数所指定整数值的对象。BigDecimal(double) //创建一个具有参数所指定双精度值的对象。BigDecimal(long) //创建一个具有参数所指定长整数值的对象。BigDecimal(String) //创建一个具有参数所指定以字符串表示的数值的对象。 方法描述 12345678910add(BigDecimal) //BigDecimal对象中的值相加，然后返回这个对象。subtract(BigDecimal) //BigDecimal对象中的值相减，然后返回这个对象。multiply(BigDecimal) //BigDecimal对象中的值相乘，然后返回这个对象。divide(BigDecimal) //BigDecimal对象中的值相除，然后返回这个对象。 toString() //将BigDecimal对象的数值转换成字符串。doubleValue() //将BigDecimal对象中的值以双精度数返回。floatValue() //将BigDecimal对象中的值以单精度数返回。longValue() //将BigDecimal对象中的值以长整数返回。intValue() //将BigDecimal对象中的值以整数返回。 保留两位小数 12345678910111213141516171819202122 /** * 保留两位小数 */@Testpublic void BigDecimalTest() &#123; double num=13.154215; //方式一 String str = new DecimalFormat(\"0.00\").format(num); System.out.println(str); //13.15 //方式二 // #.00 表示两位小数 #.0000四位小数 String str2 = new DecimalFormat(\"#.00\").format(num); System.out.println(str2); //13.15 //方式三 //%.2f %. 表示 小数点前任意位数 2 表示两位小数 格式后的结果为f 表示浮点型 String result = String.format(\"%.2f\", num); System.out.println(result); //13.15&#125; 四舍五入 123456789101112/** * 四舍五入 */@Testpublic void BigDecimalTest2() &#123; double num = 3.1415926; //保留2位小数 double result = new BigDecimal(num).setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue(); System.out.println(result); //3.14&#125; BigDecimal.setScale() //方法用于格式化小数点 setScale(1) //表示保留一位小数，默认用四舍五入方式 setScale(1,BigDecimal.ROUND_DOWN) //直接删除多余的小数位，如2.35会变成2.3 setScale(1,BigDecimal.ROUND_UP) //进位处理，2.35变成2.4 setScale(1,BigDecimal.ROUND_HALF_UP) //四舍五入，2.35变成2.4 setScaler(1,BigDecimal.ROUND_HALF_DOWN) //四舍五入，2.35变成2.3，如果是5则向下舍 setScaler(1,BigDecimal.ROUND_CEILING) //接近正无穷大的舍入 setScaler(1,BigDecimal.ROUND_FLOOR) //接近负无穷大的舍入，数字&gt;0和ROUND_UP作用一样，数字&lt;0和ROUND_DOWN作用一样 setScaler(1,BigDecimal.ROUND_HALF_EVEN) //向最接近的数字舍入，如果与两个相邻数字的距离相等，则向相邻的偶数舍入。 科学计数法 涉及到从Excel导入数据，但如果Excel里单元格类型为数值，但内容数据太长时（如银行账号），导入时，会默认读取为科学计数法。 12345@Testpublic void BigDecimalTest3() &#123; String result = new BigDecimal(\"3.40256010353E11\").toPlainString(); System.out.println(result); //340256010353&#125; MyBatis-Plus 链式调用 Lambda 式使用了lambda表达式 可以通过方法引用的方式来使用实体字段名的操作，避免直接写数据库表字段名时的错写名字； QueryWrapper12345// 查询条件构造器QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;();wrapper.eq(\"user_id\", id);// 查询操作List&lt;User&gt; userList = userMapper.selectList(wrapper); 引入lambda, 避免在代码中写类似的于user_id的硬编码 123QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;();wrapper.lambda().eq(User::getUserId, id);List&lt;User&gt; userList = userMapper.selectList(wrapper); LambdaQueryWrapper123LambdaQueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;User&gt;().lambda();wrapper.eq(User::getUserId, id);List&lt;User&gt; userList = userMapper.selectList(wrapper); 链式查询查询一组数据, 使用.list() 123List&lt;User&gt; user = new LambdaQueryChainWrapper&lt;&gt;(userMapper) .eq(User::getUserId, id) .list(); 如果只想查询一条记录，例如通过id查询某条记录的详情，使用.one() 123User user = new LambdaQueryChainWrapper&lt;&gt;(userMapper) .eq(User::getUserId, id) .one(); MySql 窗口函数 PARTITION BY确认MySQL服务器是否支持分区表命令： 1show plugins; 有此插件的话 和其功能很像的group by 1group by是分组函数，partition by是分析函数（然后像sum()等是聚合函数）； 明确常用sql关键字的优先级 1from &gt; where &gt; group by &gt; having &gt; order by 而partition by应用在以上关键字之后，实际上就是在执行完select之后，在所得结果集之上进行partition 但是partition by相比较于group by，能够在保留全部数据！基础上只对其中某些字段做分组排序，而group by则只保留参与分组的字段和聚合函数的结果。 基本语法over函数的写法： 12345OVER( [ PARTITION BY … ] [ ORDER BY … ] )eg:over（partition by cno order by degree ）# 先对cno 中相同的进行分区，在cno 中相同的情况下对degree 进行排序 OVER()函数不能单独使用，必须跟在 排名函数（ ROW_NUMBER、DENSE_RANK、RANK、NTILE） 或 5种聚合函数（SUM、MAX、MIN、AVG、COUNT）后边。 排名开窗函数语法结构： 1排名函数() OVER ( [ &lt;partition_by字段&gt; ] &lt;order_by字段&gt; ) 注意：在排名开窗函数中必须使用ORDER BY语句 ROW_NUMBER（）：为每一组的行记录按顺序生成一个唯一的行号。这个用的最多的是不连续的Id上下分页，重新生成id，也就是一行会生成一个连续的id值 如果是分组，则每个组里面的id是连续的 RANK（）也为每一组的行生成一个序号，与ROW_NUMBER()不同的是如果按照ORDERBY的排序，如果有相同的值会生成相同的序号，并且接下来的序号是不连序的。例如两个相同的行生成序号3，那么接下来会生成序号5 DENSE_RANK（）和RANK（）类似，不同的是如果有相同的序号，那么接下来的序号不会间断。也就是说如果两个相同的行生成序号3，那么接下来生成的序号还是4 NTILE (integer_expression) 按照指定的数目将数据进行分组，并为每一组生成一个序号 聚合开窗函数语法结构： 12聚合函数() OVER ( [ partition by 字段] [order by 字段]) ，其中【partition by字段】和【order by 字段】是可选择的 Max() 聚合函数，取最大值。 Sum() 聚合函数，求和，第一行和0相加，第二行和第一行相加，以此类推。 Count() 聚合函数，如果两行完全一样，Count值相同。 另外开窗函数和聚合函数的不同之处是：开窗函数对于每个组返回多行，而聚合函数对于每个组只返回一行 未完待续 … …","categories":[{"name":"工作","slug":"工作","permalink":"https://yugd.cn/categories/%E5%B7%A5%E4%BD%9C/"}],"tags":[{"name":"小技巧","slug":"小技巧","permalink":"https://yugd.cn/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"实践一下--工作常用小技巧","slug":"工作经验","date":"2021-03-30T01:00:00.000Z","updated":"2022-05-26T18:16:36.204Z","comments":true,"path":"posts/51404/","link":"","permalink":"https://yugd.cn/posts/51404/","excerpt":"工作常用小技巧 ( 10条 / 篇 ) 本篇着重介绍一下工作常用小技巧 写在前面 工作中经常会用到的小技巧，来让我们一起来看看？","text":"工作常用小技巧 ( 10条 / 篇 ) 本篇着重介绍一下工作常用小技巧 写在前面 工作中经常会用到的小技巧，来让我们一起来看看？ Java 正确 URL 解码方式 我们经常会遇到乱码的问题，那么首先可能想到的就是使用过滤器来处理，但是使用过滤器的话就会过滤所有请求，有的请求是不需要过滤的，所以如果需要过滤的请求不多的情况下，我们可以对请求进行特别处理。 urlEncoder 和 urlDecode使用指定的编码机制将字符串转换为 application/x-www-form-urlencoded 格式 1URLEncoder.encode(String s, String enc) [enc --&gt; \"utf-8\"] 使用指定的编码机制对 application/x-www-form-urlencoded 字符串解码。 1URLDecoder.decode(String s, String enc) [enc --&gt; \"utf-8\"] Mybatis 中查询时间段内数据数据库使用 Date 类型123456&lt;if test=\"minCreateTime != null and minCreateTime != ''\"&gt; &lt;![CDATA[ and g.create_time &gt;= to_date(#&#123;minCreateTime,jdbcType=DATE&#125;,'yyyy-MM-dd hh24:mi:ss')]]&gt;&lt;/if&gt;&lt;if test=\"maxCreateTime != null and maxCreateTime != ''\"&gt; &lt;![CDATA[ and g.create_time &lt;= to_date(#&#123;maxCreateTime,jdbcType=DATE&#125;,'yyyy-MM-dd hh24:mi:ss')]]&gt;&lt;/if&gt; 数据库使用字符串类型123456&lt;if test=\"createTime != null\"&gt; AND CREATE_TIME = CONCAT(CONCAT('%', #&#123;createTime,jdbcType=DATE&#125;), '%')&lt;/if&gt;&lt;if test=\"updateTime != null\"&gt; AND UPDATE_TIME = CONCAT(CONCAT('%', #&#123;updateTime,jdbcType=DATE&#125;), '%')&lt;/if&gt; Java Date 与 String 的相互转换Java String 转 Date接口之间数据的传输都是字符串，现在需要把数据存储在数据库中，定义对象的时候将日期定义为了Date，所以不得不把String转为Date对象。 123456// 获取当前时间（格式：yyyy-MM-dd HH:mm:ss）String time = \"2021-01-01 10:10:10\";// 设置日期格式SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");// 将字符串解析成日期Date date = simpleDateFormat.parse(time); Java Date 转 String123456// 获取当前时间（返回格式：yyyy-MM-dd HH:mm:ss）Date date = new Date();// 设置日期格式SimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");// new Date()为获取当前系统时间String time = df.format(date); 计算某天 n 天之后的日期12345678910111213141516171819public static String getBeforeAfterDateDay(String time, int day) throws Exception&#123; SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd\"); Date date = sdf.parse(time); Calendar cal = Calendar.getInstance(); cal.setTime(date); int Year = cal.get(Calendar.YEAR); int Month = cal.get(Calendar.MONTH); int Day = cal.get(Calendar.DAY_OF_MONTH); int NewDay = Day + day; cal.set(Calendar.YEAR, Year); cal.set(Calendar.MONTH, Month); cal.set(Calendar.DAY_OF_MONTH, NewDay); String newTime = sdf.format(new Date(cal.getTimeInMillis())); return newTime;&#125; Git 命令将最新的 master 分支代码更新到其他分支 将分支切换到master 1git checkout master 将代码pull到本地 1git pull 修改冲突 提交代码到本地 12git add .git commit -m \"msg\" 切换到要更新的分支上 1git checkout 分支名 merge 1git merge master 将本地跟新好的内容push到分支 1git push 优雅的代码总结1.static 成员变量“类名 . 静态变量名” 静态成员变量是属于类的，也就是说，该成员变量并不属于某个对象，即使有多个该类的对象实例，静态成员变量也只有一个； 只要静态成员变量所在的类被加载，这个静态成员变量就会被分配内存空间。因此在引用该静态成员变量时，通常不需要生成该类的对象，而是通过类名直接引用； 123456789public class Student &#123; // 静态成员变量 private static String schoolName; private static int nums; // 非静态成员变量 private String name; private int age;&#125; 2.static 成员方法静态成员方法是类方法，它属于类本身而不属于某个对象；因此静态成员方法不需要创建对象就可以被调用，而非静态成员方法则需要通过对象来调用； 在静态成员方法中不能使用 this、super 关键字，也不能调用非静态成员方法，同时不能引用非静态成员变量 123456789public class Student &#123; private static String SchoolName; private static int nums; // 静态成员方法 public static String getSchoolName() &#123; return Student.SchoolName; &#125;&#125; 3.static 代码块static 代码块又称为静态代码块，或静态初始化器。它是在类中独立于成员函数的代码块； static 代码块不需要程序主动调用，在JVM加载类时系统会执行 static 代码块，因此在static 代码块中可以做一些类成员变量的初始化工作； 如果一个类中有多个 static 代码块，JVM将会按顺序依次执行。需要注意的是，所有的static 代码块只能在JVM加载类时被执行一次； 12345678910public class Student &#123; private static String SchoolName; private static int nums; // 静态代码块 static &#123; Student.SchoolName = \"清华大学\"; Student.nums = 0; &#125;&#125; 4.static 内部类静态成员内部类的特点主要是它本身是类相关的内部类，所以它可以不依赖于外部类实例而被实例化 静态内部类不能访问其外部类的实例成员（包括普通的成员变量和方法），只能访问外部类的类成员（包括静态成员变量和静态方法）; 1234567891011public class Student &#123; private static String SchoolName; private static int nums; // 静态内部类 static class test&#123; public test() &#123; System.out.println(\"Hello Word!\" ); &#125; &#125;&#125; DeepinCopy 深拷贝123456789public class CpoyUtil &#123; public static List&lt;Object&gt; DeepinCopy(List&lt;Object&gt; list) &#123; return list.stream().map(res -&gt; &#123; Object entity = new Object(); BeanUtils.copyProperties(res, entity); return entity; &#125;).collect(Collectors.toList()); &#125;&#125; Object 可替换成相应的对象 Sql 中 limit 与 offset连用的区别1234567select * from table limit 2,1; -- 含义是跳过2条取出1条数据，limit后面是从第2条开始读，读取1条信息，即读取第3条数据 select * from table limit 2 offset 1; -- 含义是从第1条（不包括）数据开始取出2条数据，limit后面跟的是2条数据，offset后面是从第1条开始读取，即读取第2,3条 Java 对象与 JSON 数据的互相转换通过 FastJson（JSON类）解析 将 Java 对象转换为字符串 – (序列化)1234//将对象转换为字符串Book book = new Book(1001,\"Java\",\"Java基础\");String jsonString = JSON.toJSONString(book);System.out.println(jsonString); 结果： 1&#123;\"id\":1001,\"info\":\"Java基础\",\"name\":\"Java\"&#125; 将 JSON 格式字符串解析为 Java 对象 – (反序列化) 1234//将JSON字符串转换为Java对象String bookJson = \"&#123;\\\"id\\\":1001,\\\"name\\\":\\\"Java\\\",\\\"info\\\":\\\"Java基础\\\"&#125;\";Book book = JSON.parseObject(bookJson,Book.class);System.out.println(book); 结果： 1Book&#123;id=1001, name=\"Java\", info=\"Java基础\"&#125; 将 Json 转换复杂的 Bean 对象12345String jsonString = \"[&#123;\\\"id\\\":\\\"1\\\",\\\"name\\\":\\\"Json技术\\\"&#125;,&#123;\\\"id\\\":\\\"2\\\",\\\"name\\\":\\\"java技术\\\"&#125;]\";// 将json转换成ListList list = JSON.parseObject(jsonString, new TypeReference&lt;ARRAYLIST&gt;()&#123;&#125;);// 将json转换成SetSet set = JSON.parseObject(jsonString, new TypeReference&lt;HASHSET&gt;()&#123;&#125;); Gson 和 Fastjson 区别Bean 转换 Json：toJson12Gson gson = new Gson();String json = gson.toJson(obj); Json 转换 Bean：fromJson123Gson gson = new Gson();String json = \"&#123;\\\"id\\\":\\\"2\\\",\\\"name\\\":\\\"Json技术\\\"&#125;\";Book book = gson.fromJson(json, Book.class); Json 转换复杂的 Bean1234567// 将json转换成复杂类型的bean,需要使用TypeTokenGson gson = new Gson();String json = \"[&#123;\\\"id\\\":\\\"1\\\",\\\"name\\\":\\\"Json技术\\\"&#125;,&#123;\\\"id\\\":\\\"2\\\",\\\"name\\\":\\\"java技术\\\"&#125;]\";// 将json转换成ListList list = gson.fromJson(json, new TypeToken&lt;List&gt;() &#123;&#125;.getType());// 将json转换成SetSet set = gson.fromJson(json, new TypeToken&lt;Set&gt;() &#123;&#125;.getType()); 总结 如果只是功能要求，没有性能要求，可以使用 google 的 Gson， 如果有性能上面的要求可以使用 Gson 将 bean 转换 json 确保数据的正确 (序列化)，使用 FastJson 将 Json 转换 Bean (反序列化) Git忽略文件.gitignore常用匹配示例1234567891011121314151617bin&#x2F;: 忽略当前路径下的bin文件夹，该文件夹下的所有内容都会被忽略，不忽略 bin 文件&#x2F;bin: 忽略根目录下的bin文件&#x2F;*.c: 忽略 cat.c，不忽略 build&#x2F;cat.cdebug&#x2F;*.obj: 忽略 debug&#x2F;io.obj，不忽略 debug&#x2F;common&#x2F;io.obj 和 tools&#x2F;debug&#x2F;io.obj**&#x2F;foo: 忽略&#x2F;foo, a&#x2F;foo, a&#x2F;b&#x2F;foo等a&#x2F;**&#x2F;b: 忽略a&#x2F;b, a&#x2F;x&#x2F;b, a&#x2F;x&#x2F;y&#x2F;b等!&#x2F;bin&#x2F;run.sh: 不忽略 bin 目录下的 run.sh 文件*.log: 忽略所有 .log 文件config.php: 忽略当前路径的 config.php 文件 如果想添加一个文件到Git，但发现添加不了，原因是这个文件被 .gitignore 忽略了。 如果你确实想添加该文件，可以用 -f 强制添加到 Git 1$ git add -f App.class 用 git check-ignore 命令可以检查 哪个 .gitignore 写得有问题 12$ git check-ignore -v App.class.gitignore:3:*.class App.class .gitignore 的第3行规则忽略了该文件 Java 项目中常用的 .gitignore 文件12345678910111213141516171819202122232425262728293031323334353637383940# Compiled class file*.class# Eclipse.project.classpath.settings&#x2F;# Intellij*.ipr*.iml*.iws.idea&#x2F;# Maventarget&#x2F;# Gradlebuild.gradle# Log file*.loglog&#x2F;# out**&#x2F;out&#x2F;# Mac.DS_Store# others*.jar*.war*.zip*.tar*.tar.gz*.pid*.origtemp&#x2F; 未完待续 … …","categories":[{"name":"工作","slug":"工作","permalink":"https://yugd.cn/categories/%E5%B7%A5%E4%BD%9C/"}],"tags":[{"name":"小技巧","slug":"小技巧","permalink":"https://yugd.cn/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"PageHelper","slug":"学习--PageHelper","date":"2021-03-15T11:41:13.000Z","updated":"2021-10-26T14:26:00.127Z","comments":true,"path":"posts/25888/","link":"","permalink":"https://yugd.cn/posts/25888/","excerpt":"PageHelper是一款好用的开源免费的Mybatis第三方物理分页插件 Github地址:https://github.com/pagehelper/Mybatis-PageHelper 官方地址：https://pagehelper.github.io/** 如何使用分页插件使用 Maven 在 pom.xml 中添加如下依赖： 12345678910111213141516&lt;!-- 引入PageHelper依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt;","text":"PageHelper是一款好用的开源免费的Mybatis第三方物理分页插件 Github地址:https://github.com/pagehelper/Mybatis-PageHelper 官方地址：https://pagehelper.github.io/** 如何使用分页插件使用 Maven 在 pom.xml 中添加如下依赖： 12345678910111213141516&lt;!-- 引入PageHelper依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; 配置PageHelper相关属性 方法一：在application.yml文件中配置123456# 配置pagehelper参数pagehelper: helperDialect: mysql reasonable: true supportMethodsArguments: true params: count=countSql 方法二：创建一个配置类配置 PageHelper1234567891011121314@Configurationpublic class PageHelperConfig &#123; @Bean public PageHelper getPageHelper()&#123; PageHelper pageHelper=new PageHelper(); Properties properties=new Properties(); properties.setProperty(\"helperDialect\",\"mysql\"); properties.setProperty(\"reasonable\",\"true\"); properties.setProperty(\"supportMethodsArguments\",\"true\"); properties.setProperty(\"params\",\"count=countSql\"); pageHelper.setProperties(properties); return pageHelper; &#125;&#125; PageInfo类源码的属性如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class PageInfo&lt;T&gt; implements Serializable &#123; private static final long serialVersionUID = 1L; //当前页 private int pageNum; //每页的数量 private int pageSize; //当前页的数量 private int size; //由于startRow和endRow不常用，这里说个具体的用法 //可以在页面中\"显示startRow到endRow 共size条数据\" //当前页面第一个元素在数据库中的行号 private int startRow; //当前页面最后一个元素在数据库中的行号 private int endRow; //总记录数 private long total; //总页数 private int pages; //结果集 private List&lt;T&gt; list; //前一页 private int prePage; //下一页 private int nextPage; //是否为第一页 private boolean isFirstPage = false; //是否为最后一页 private boolean isLastPage = false; //是否有前一页 private boolean hasPreviousPage = false; //是否有下一页 private boolean hasNextPage = false; //导航页码数 private int navigatePages; //所有导航页号 private int[] navigatepageNums; //导航条上的第一页 private int navigateFirstPage; //导航条上的最后一页 private int navigateLastPage;&#125; 前端请求接口方法 12345678910@RequestMapping(value = \"/getPerson\") public List&lt;TbPersonPO&gt; getSomePerson(@RequestParam(value = \"pageNum\",defaultValue=\"1\") int pageNum )&#123; //pageNum:表示第几页 pageSize:表示一页展示的数据 PageHelper.startPage(pageNum,3); List&lt;TbPersonPO&gt; list=tbPersonDao.queryPerosn(); //将查询到的数据封装到PageInfo对象 PageInfo&lt;TbPersonPO&gt; pageInfo=new PageInfo(list,3); //分割数据成功 return list; &#125; PageHelper是不是用起来感觉为我们节省了不少的时间呢？","categories":[{"name":"工具","slug":"工具","permalink":"https://yugd.cn/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"分页插件","slug":"分页插件","permalink":"https://yugd.cn/tags/%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6/"}]},{"title":"整理项目","slug":"整理项目","date":"2021-02-26T14:58:30.000Z","updated":"2022-05-26T18:19:30.644Z","comments":true,"path":"posts/28149/","link":"","permalink":"https://yugd.cn/posts/28149/","excerpt":"整理项目​ 这两天闲着没事（其实是不知道干啥）想整理一下GitHub上的项目说明（readme.md） ​ 发现需要将一些项目结构，所涉及到的技术栈……什么的整理好所以就效仿着其他大佬的项目说明进行的整 理，经过一番整理就算是总结一下过去的经历吧~ 首先运行项目，嗯要不然咋能有相应的截图呢 然后再把截好的图上传到图床上（我用的免费版的GitHub的图床，通过CDN加速加载也没有那么慢）","text":"整理项目​ 这两天闲着没事（其实是不知道干啥）想整理一下GitHub上的项目说明（readme.md） ​ 发现需要将一些项目结构，所涉及到的技术栈……什么的整理好所以就效仿着其他大佬的项目说明进行的整 理，经过一番整理就算是总结一下过去的经历吧~ 首先运行项目，嗯要不然咋能有相应的截图呢 然后再把截好的图上传到图床上（我用的免费版的GitHub的图床，通过CDN加速加载也没有那么慢） 管理系统 博客 其实做这个此项目的意义就在于，我在学习相应的技术后能不能够在实际操作中运用好，当然在实际操作的过程中还是遇到了或多或少的问题，感谢前人把之前遇到的问题+解决方案整理出来，使得我走了不少捷径，哈哈哈~","categories":[{"name":"生活篇","slug":"生活篇","permalink":"https://yugd.cn/categories/%E7%94%9F%E6%B4%BB%E7%AF%87/"}],"tags":[{"name":"折腾","slug":"折腾","permalink":"https://yugd.cn/tags/%E6%8A%98%E8%85%BE/"}]},{"title":"如何将Sass编译成CSS","slug":"学习--Sass","date":"2021-02-18T11:57:30.000Z","updated":"2021-10-26T14:26:00.128Z","comments":true,"path":"posts/1627/","link":"","permalink":"https://yugd.cn/posts/1627/","excerpt":"命令编译命令编译就是在终端中输入 sass 命令来编译 Sass 代码，这种编译方式使用起来很简单。 示例： 假设现在有一个Sass文件，文件名为 style.scss （Sass 文件的扩展名名 .scss），我们需要将这个文件中的代码编译成 CSS 代码，可以执行如下命令： 1sass style.scss style.css","text":"命令编译命令编译就是在终端中输入 sass 命令来编译 Sass 代码，这种编译方式使用起来很简单。 示例： 假设现在有一个Sass文件，文件名为 style.scss （Sass 文件的扩展名名 .scss），我们需要将这个文件中的代码编译成 CSS 代码，可以执行如下命令： 1sass style.scss style.css 命令执行成功后，会自动创建一个 style.css 文件。但是这样有一个问题，就是每次更改了 style.scss 文件中的内容，都需要执行一次编译命令，就会很麻烦。 如果要解决上述问题，可以使用监听命令 --watch ，例如： 1sass --watch style.scss:style.css 如果项目中有很多的 sass 文件，可以监听整个目录： 1sass --watch app/sass:public/stylesheets Sass四种输出格式在编译 Sass 代码时，我们可以指定 Sass 的编译输出格式，这需要用到 --style 指令，这个指定后面可接如下四种 Sass 输出格式： nested：嵌套输出格式，默认格式。 expanded：展开输出方式。 compact：紧凑输出方式 。 compressed：压缩输出方式 。 示例： 例如以 style.scss 文件为例，内容如下所示： 12345678910.xkd&#123; font-size: 14px; color: #ccc; .box&#123; width: 100px; height: 100px; border: 1px solid #000; border-radius: 5px; &#125;&#125; 第一种：使用 nested 编译排版格式输出，可以执行如下命令：1sass style.scss:style.css --style nested 编译后的 CSS 代码： 12345678.xkd &#123; font-size: 14px; color: #ccc; &#125; .xkd .box &#123; width: 100px; height: 100px; border: 1px solid #000; border-radius: 5px; &#125; 第二种：使用 expanded 编译排版格式输出，可以执行如下命令：1sass style.scss:style.css --style expanded 编译后的 CSS 代码： 12345678910.xkd &#123; font-size: 14px; color: #ccc;&#125;.xkd .box &#123; width: 100px; height: 100px; border: 1px solid #000; border-radius: 5px;&#125; 第三种：使用 compact 编译排版格式输出，可以执行如下命令：1sass style.scss:style.css --style compact 编译后的 CSS 代码： 12.xkd &#123; font-size: 14px; color: #ccc; &#125;.xkd .box &#123; width: 100px; height: 100px; border: 1px solid #000; border-radius: 5px; &#125; 第四种：使用 compressed 编译排版格式输出，可以执行如下命令：1sass style.scss:style.css --style compressed 编译后的 CSS 代码： 1.xkd&#123;font-size:14px;color:#ccc&#125;.xkd .box&#123;width:100px;height:100px;border:1px solid #000;border-radius:5px&#125; 这四种输出格式中，一般我会选择使用第二种输出格式，也就是 expanded 格式。这种格式和我们手写的 CSS 样式差不多，选择器、属性等各占用一行，属性根据选择器缩进，而选择器不做任何缩进。","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://yugd.cn/tags/Web/"}]},{"title":"Junit测试","slug":"实践--Junit测试","date":"2021-02-13T13:58:58.000Z","updated":"2021-10-26T17:08:32.563Z","comments":true,"path":"posts/38653/","link":"","permalink":"https://yugd.cn/posts/38653/","excerpt":"写在前面在最开始的时候，我做程序的时候通常都是在实现一个功能后启动整个项目，然后对此功能进行自测，但是随着项目的体量主键庞大后，测试的时间效率反而越来越低了，那么有没有不启动项目就可以进行专项功能测试的方法呢？ 当然是有的啦，单元测试（Junit testing）就很好的解决了上述的问题。","text":"写在前面在最开始的时候，我做程序的时候通常都是在实现一个功能后启动整个项目，然后对此功能进行自测，但是随着项目的体量主键庞大后，测试的时间效率反而越来越低了，那么有没有不启动项目就可以进行专项功能测试的方法呢？ 当然是有的啦，单元测试（Junit testing）就很好的解决了上述的问题。 概念： 单元测试（unit testing），是指对软件中的最小可测试单元进行检查和验证。在Java中单元测试的最小单元是类。 单元测试是开发者编写的一小段代码，用于检验被测代码的一个很小的、很明确的功能是否正确。执行单元测试，就是为了证明这 段代码的行为和我们期望是否一致。 实践单元测试引用： 通过spring initialize创建的Spring Boot项目会在Maven中自动携带很多starter依赖，其中包含了一个名为spring-boot-starter-test的依赖 Spring Boot中引入单元测试很简单，添加如下依赖（即spring-boot-starter-test依赖） 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 单元测试的作用在没有接触单元测试之前我们是怎么做测试的？一般有两个方法： 方法 弊端 1、启动整个项目，模拟正常的用户操作，点击之类的操作，调用API 测试的时候需要启动整个项目 2、在代码的某个地方写一个临时的入口，用于测试某个类或某个方法 入口用完需要删除，否则会影响运行速度或效率 我认为写单元测试的两个目的： 保证或验证实现功能。 保护已经实现的功能不被破坏。 Service层的单元测试位置：Spring Boot中单元测试类写在src/test/java目录下； 举个荔枝： 1234567891011121314@SpringBootTest@RunWith(SpringRunner.class)public class JUtServiceTest &#123;@Resourceprivate JUtService jUtService;@Testpublic void conflictTime() &#123; DateTimeFormatter dtf = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"); LocalDate start = LocalDate.parse(\"2020-10-26\", dtf); LocalDate end = LocalDate.parse(\"2020-10-31\", dtf); Integer integer = XXXService.ConflictTime(\"10000001\", start, end); Assert.assertThat(integer, Matchers.notNullValue()); &#125;&#125; 注解解释： @SpringBootTest：获取启动类，加载配置，寻找主配置启动类（被 @SpringBootApplication 注解的） @RunWith(SpringRunner.class)：让JUnit运行Spring的测试环境,获得Spring环境的上下文的支持 Controller层的单元测试位置：Spring Boot中单元测试类写在src/test/java目录下； 举个荔枝1： 12345678910111213@SpringBootTest@RunWith(SpringRunner.class)@AutoConfigureMockMvcpublic class JutControllerTest &#123;@Autowiredprivate MockMvc mockMvc;@Beforepublic void setUp() throws Exception &#123; System.out.println(\"---------------start---------------\"); save();get(); System.out.println(\"================end================\"); &#125; 注解解释： @SpringBootTest：获取启动类，加载配置，寻找主配置启动类（被 @SpringBootApplication 注解的） @RunWith(SpringRunner.class)：让JUnit运行Spring的测试环境,获得Spring环境的上下文的支持 @AutoConfigureMockMvc：用于自动配置MockMvc,配置后MockMvc类可以直接注入,相当于new MockMvc @Before:初始化方法 ,对于每一个测试方法都要执行一次 举个荔枝2： 1234567891011@Testpublic void get() throws Exception&#123; ResultActions resultActions = mockMvc.perform(MockMvcRequestBuilders .get(\"/balabala/get\") .param(\"id\", \"**********\") .header(\"Authorization\", \"Bearer ********-****-****-****-************\") ); resultActions.andReturn().getResponse().setCharacterEncoding(\"UTF-8\"); resultActions.andExpect(MockMvcResultMatchers.status().isOk()).andDo(print()); &#125;&#125; 注解解释： mockMvc.perform：执行一个请求 MockMvcRequestBuilders.get(“/balabala/get”)：构造一个请求，如果是Post请求使用.post方法 contentType(MediaType.APPLICATION_JSON_VALUE)：代表发送端发送的数据格式是application/json;charset=UTF-8 accept(MediaType.APPLICATION_JSON)：代表客户端希望接受的数据类型为application/json;charset=UTF-8 header(“Authorization”,“Bearer XXXX”)：代表在报文头添加一些必须的信息，这里添加的是token ResultActions.andExpect：添加执行完成后的断言 ResultActions.andExpect(MockMvcResultMatchers.status().isOk())：方法看请求的状态响应码是否为200如果不是则抛异常，测试不通过 ResultActions.andDo：添加一个结果处理器，表示要对结果做点什么事情，比如此处使用print()：输出整个响应结果信息 JUnit 5测试JUnit 生命周期12345678910111213141516171819202122232425262728293031public class JUnit5Test &#123; @BeforeAll static void beforeAll() &#123; System.out.println(\"Before All\"); &#125; @AfterAll static void afterAll() &#123; System.out.println(\"After All\"); &#125; @BeforeEach void before() &#123; System.out.println(\"Before\"); &#125; @AfterEach void after() &#123; System.out.println(\"After\"); &#125; @Test void test1() &#123; System.out.println(\"Test 1\"); &#125; @Test void test2() &#123; System.out.println(\"Test 2\"); &#125;&#125; 解释： @Test：表示方法是测试方法； @BeforeAll：表示被注解的方法应该在当前类的所有@Test方法之前执行； @AfterAll：表示被注解的方法应该在当前类的所有@Test方法之后执行； @BeforeEach：表示被注解的方法应在当前类的每个@Test方法之前执行； @AfterEach：表示被注解的方法应在当前类的每个@Test方法之后执行； 编写断言 简单断言 方法 说明 assertEquals 判断两个对象或两个原始类型是否相等 assertNotEquals 判断两个对象或两个原始类型是否不相等 assertSame 判断两个对象引用是否指向同一个对象 assertNotSame 判断两个对象引用是否指向不同的对象 assertTrue 判断给定的布尔值是否为 true assertFalse 判断给定的布尔值是否为 false assertNull 判断给定的对象引用是否为 null assertNotNull 判断给定的对象引用是否不为 null 举个荔枝： 123456@Testvoid testAssertion() &#123; assertEquals(10, 10); assertTrue(true); assertEquals(100, 100, \"两个数相等\");&#125; 前面断言失败，后面不会继续执行 数组断言 12345@Test@DisplayName(\"array assertion\")public void array() &#123; assertArrayEquals(new int[]&#123;1, 2&#125;, new int[] &#123;1, 2&#125;);&#125; 组合断言 12345678@Test@DisplayName(\"assert all\")public void all() &#123; assertAll(\"Math\", () -&gt; assertEquals(2, 1 + 1), () -&gt; assertTrue(1 &gt; 0) );&#125; 异常断言 1234567@Test@DisplayName(\"异常测试\")public void exceptionTest() &#123; ArithmeticException exception = assertThrows( //扔出断言异常 ArithmeticException.class, () -&gt; System.out.println(1 % 0));&#125; 超时断言 123456@Test@DisplayName(\"超时测试\")public void timeoutTest() &#123; //如果测试方法时间超过1s将会异常 assertTimeout(Duration.ofMillis(1000), () -&gt; Thread.sleep(500));&#125; 快速断言 12345@Test@DisplayName(\"fail\")public void shouldFail() &#123; fail(\"This should fail\");&#125; 常用注解显示名称【@DisplayName】 12345678910111213141516171819@DisplayName(\"A special test case\")class DisplayNameDemo &#123; @Test @DisplayName(\"Custom test name containing spaces\") void testWithDisplayNameContainingSpaces() &#123; &#125; @Test @DisplayName(\"╯°□°）╯\") void testWithDisplayNameContainingSpecialCharacters() &#123; &#125; @Test @DisplayName(\"😱\") void testWithDisplayNameContainingEmoji() &#123; &#125;&#125; 禁用测试【@Disabled】 123456@Disabledpublic class DisabledTestDemo &#123; @Test //@Disabled void testDisabled() &#123; &#125;&#125; 重复测试【@RepeatedTest】 12345public class RepeatedTestDemo &#123; @RepeatedTest(10) void testRepeated10Times() &#123; &#125;&#125; 附带标签【@RepeatedTest】 123456789101112@Tag(\"taggedTest\")public class TagDemo &#123; @Test @Tag(\"taggedTest1\") void testWithTag1() &#123; &#125; @Test @Tag(\"taggedTest2\") void testWithTag2() &#123; &#125;&#125; 嵌套测试【@Nested】 1234567891011121314@DisplayName(\"外层测试\")public class NestedDemo &#123; @Test void testOuter() &#123; &#125; @Nested @DisplayName(\"内层测试\") class InnerTestDemo &#123; @Test void testInner() &#123; &#125; &#125;&#125; 工作使用因为 Test 单元测试一般用来检验某个模块的特定功能，然后通过断言来验证其结果是否达到了我们的预期。 但是如果是使用的数据库测试库中的数据来进行验证只能够保证当时的正确性，一旦其他人修改了测试库中的数据，那么就会导致测试单元的不通过。 所以，为了避免上述问题，也为了写出一次测试，随时可测的的单元测试代码，我们需要自己伪造数据来帮助我们对功能的验证，我选择使用 @Transactional 和 @Rollback 注解。 举个荔枝 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@SpringBootTest@AutoConfigureMockMvcclass ASEMobileRedisApplicationTests &#123; @Autowired private MockMvc mockMvc; @BeforeEach static void setUp() &#123; System.out.println(\"Before All\"); &#125; @Test @Transactional @Rollback void contextLoads() throws Exception &#123; // saveTest (造数据), 测试完毕后 Rollback (回滚) saveTest(); queryTest(); &#125; @Test @DisplayName(\"添加用户\") void saveTest() throws Exception &#123; String stringJson = new String(Files.readAllBytes(Paths.get(\"src\", \"test\", \"java\", \"com\", \"ase\", \"mobile\", \"User.json\"))); String jsonString = JSON.toJSONString(stringJson); // 构建请求 mockMvc.perform(MockMvcRequestBuilders .post(\"/test/post\") .content(jsonString) .header(\"Authorization\", \"Bearer ********-****-****-****-************\") .contentType(MediaType.APPLICATION_JSON_VALUE) //代表发送端发送的数据格式是 application/json;charset=UTF-8 .accept(MediaType.APPLICATION_JSON)) //代表客户端希望接受的数据类型为 application/json;charset=UTF-8 .andDo(print()) .andExpect(status().isOk()) .andExpect(MockMvcResultMatchers.jsonPath(\"$.code\").value(\"200\")) .andExpect(MockMvcResultMatchers.jsonPath(\"$.data\").value(\"1\")) .andReturn(); &#125; @Test @DisplayName(\"查询用户\") void queryTest() throws Exception &#123; String name = \"tom\"; // 构建请求 mockMvc.perform(MockMvcRequestBuilders .post(\"/test/get\") .param(\"name\", name) .contentType(MediaType.APPLICATION_JSON_VALUE) .accept(MediaType.APPLICATION_JSON)) .andDo(print()) .andExpect(status().isOk()) .andExpect(MockMvcResultMatchers.jsonPath(\"$.code\").value(\"200\")) .andExpect(MockMvcResultMatchers.jsonPath(\"$.data\").value(\"xxx\")) .andReturn(); &#125;&#125;","categories":[{"name":"规范","slug":"规范","permalink":"https://yugd.cn/categories/%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"测试","slug":"测试","permalink":"https://yugd.cn/tags/%E6%B5%8B%E8%AF%95/"}]},{"title":"Vue系列--Webpack","slug":"Vue系列--Webpack","date":"2021-01-16T11:58:58.000Z","updated":"2022-05-26T18:19:51.921Z","comments":true,"path":"posts/13521/","link":"","permalink":"https://yugd.cn/posts/13521/","excerpt":"Webpack是什么、为什么要使用它简单来说，Webpack是一个打包工具 成为一个优秀的前端工程师，除了要会写页面样式和动态效果之外，还需要会用主流的单页面框架、Node.js、简单的前端的性能优化等等。加上现在一部分服务器的逻辑移到了前端上，所以实际上前端的复杂度也是提升了很多。 而Webpack可以帮助我们完成一些任务。比如js压缩、css压缩、编译模板文件等等，从而减少前端的工作量。当然，Webpack功能很强大 安装Webpack安装: 12npm install webpack -gnpm install webpack-cli -g","text":"Webpack是什么、为什么要使用它简单来说，Webpack是一个打包工具 成为一个优秀的前端工程师，除了要会写页面样式和动态效果之外，还需要会用主流的单页面框架、Node.js、简单的前端的性能优化等等。加上现在一部分服务器的逻辑移到了前端上，所以实际上前端的复杂度也是提升了很多。 而Webpack可以帮助我们完成一些任务。比如js压缩、css压缩、编译模板文件等等，从而减少前端的工作量。当然，Webpack功能很强大 安装Webpack安装: 12npm install webpack -gnpm install webpack-cli -g 测试安装成功: 12webpack -vwebpack-cli -v 配置创建 webpack.config.js 配置文件 entry：入口文件，指定 WebPack 用哪个文件作为项目的入口 output：输出，指定 WebPack 把处理完成的文件放置到指定路径 module：模块，用于处理各种类型的文件 plugins：插件，如：热更新、代码重用等 resolve：设置路径指向 watch：监听，用于设置文件改动后直接打包 使用webpack 创建项目 创建一个名为 modules 的目录，用于放置 JS 模块等资源文件 在modules下创建模块文件，如 hello.js，用于编写 JS 模块相关代码 1234//暴露一个方法:sayHiexports.sayHi = function () &#123; document.write(\"&lt;div&gt;Hello WebPack&lt;/div&gt;\");&#125;; 在modules下创建一个名为 main.js 的入口文件，用于打包时设置 entry 属性 123//require 导入一个模块,就可以调用这个模块中的方法了var hello = require(\"./hello\");hello.sayHi(); 在项目目录下创建 webpack.config.js 配置文件，使用 webpack 命令打包 123456module.exports = &#123; entry: \"./modules/main.js\", output: &#123; filename: \"./js/bundle.js\" &#125;&#125;; 在项目目录下创建 HTML 页面，如 index.html，导入 WebPack 打包后的 JS 文件 12345678910&lt;!doctype html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Vue&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;script src=\"dist/js/bundle.js\"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 在IDEA控制台中直接执行webpack;如果失败的话,就使用管理员权限运行即可 运行 HTML 看效果 说明: 12# 参数 --watch 用于监听变化webpack --watch","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://yugd.cn/tags/vue/"}]},{"title":"Vue系列--Axios","slug":"Vue系列--Axios","date":"2021-01-15T11:58:58.000Z","updated":"2021-10-26T14:26:00.103Z","comments":true,"path":"posts/13590/","link":"","permalink":"https://yugd.cn/posts/13590/","excerpt":"Axios 文档 GitHub：https://github.com/axios/axios 中文文档：http://www.axios-js.com/ 安装:CommonJS: 1$ npm install --save axios vue-axios","text":"Axios 文档 GitHub：https://github.com/axios/axios 中文文档：http://www.axios-js.com/ 安装:CommonJS: 1$ npm install --save axios vue-axios 将下面代码加入入口文件: 12345import Vue from 'vue'import axios from 'axios'import VueAxios from 'vue-axios'Vue.use(VueAxios, axios) 你可以按照以下方式使用: 1234567891011Vue.axios.get(api).then((response) =&gt; &#123; console.log(response.data)&#125;)this.axios.get(api).then((response) =&gt; &#123; console.log(response.data)&#125;)this.$http.get(api).then((response) =&gt; &#123; console.log(response.data)&#125;) vue axios 封装index.js 12345678910111213141516import Axios from './request';import qs from 'qs';export default &#123; /** * API * @param reqData * @returns &#123;AxiosPromise&lt;any&gt;&#125; */ //登录验证 login(reqData) &#123; return Axios.post('/api/login', qs.stringify(reqData)); &#125;,&#125; api.js 123456789101112import Api from './index';/** * API * @param reqData * @returns &#123;AxiosPromise&lt;any&gt;&#125; *///登录export async function login(reqData) &#123; return Api.login(reqData);&#125; login.vue 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;script&gt; &#x2F;&#x2F;解构函数 import &#123;login&#125; from &#39;..&#x2F;service&#x2F;api&#39;; ... methods: &#123; &#x2F;&#x2F;提交表单 async login() &#123; let res &#x3D; await login(&#123; nickname: this.userInfo.nickname, username: this.userInfo.username, role: &#39;user&#39;, gender: this.userInfo.gender, password: this.userInfo.password &#125;); if (res.data &#x3D;&#x3D;&#x3D; 1) &#123; this.$refs.userInfo.resetFields(); this.$router.push(&#39;&#x2F;index&#39;); this.$message(&#123; message: &#39;恭喜你，注册成功&#39;, type: &#39;success&#39;, duration: 1500 &#125;); &#125; else &#123; this.$refs.userInfo.resetFields(); &#x2F;&#x2F;添加user失败 this.$message(&#123; type: &#39;error&#39;, message: &#39;不好意思，注册失败&#39;, duration: 1500 &#125;); &#125; &#125;, &#x2F;&#x2F;重置表单 reset() &#123; this.$refs.userInfo.resetFields(); &#125;, &#x2F;&#x2F;返回主页 topBlog()&#123; this.$router.push(&#39;&#x2F;index&#39;); &#125; &#125; &lt;&#x2F;script&gt; axios APIaxios(config)123456789// 发送 POST 请求axios(&#123; method: 'post', url: '/user/12345', data: &#123; firstName: 'Fred', lastName: 'Flintstone' &#125;&#125;); axios(url[, config])12// 发送 GET 请求（默认的方法）axios('/user/12345'); 使用 then 时，你将接收下面这样的响应： 12345678axios.get('/user/12345') .then( res =&gt; &#123; console.log(res.data); console.log(res.status); console.log(res.statusText); console.log(res.headers); console.log(res.config); &#125;); 这些是创建请求时可以用的配置选项, 只有 url 是必需的, 如果没有指定 method，请求将默认使用 get 方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125&#123; // `url` 是用于请求的服务器 URL url: '/user', // `method` 是创建请求时使用的方法 method: 'get', // 默认是 get // `baseURL` 将自动加在 `url` 前面，除非 `url` 是一个绝对 URL。 // 它可以通过设置一个 `baseURL` 便于为 axios 实例的方法传递相对 URL baseURL: 'https://some-domain.com/api/', // `transformRequest` 允许在向服务器发送前，修改请求数据 // 只能用在 'PUT', 'POST' 和 'PATCH' 这几个请求方法 // 后面数组中的函数必须返回一个字符串，或 ArrayBuffer，或 Stream transformRequest: [function (data) &#123; // 对 data 进行任意转换处理 return data; &#125;], // `transformResponse` 在传递给 then/catch 前，允许修改响应数据 transformResponse: [function (data) &#123; // 对 data 进行任意转换处理 return data; &#125;], // `headers` 是即将被发送的自定义请求头 headers: &#123;'X-Requested-With': 'XMLHttpRequest'&#125;, // `params` 是即将与请求一起发送的 URL 参数 // 必须是一个无格式对象(plain object)或 URLSearchParams 对象 params: &#123; ID: 12345 &#125;, // `paramsSerializer` 是一个负责 `params` 序列化的函数 // (e.g. https://www.npmjs.com/package/qs, http://api.jquery.com/jquery.param/) paramsSerializer: function(params) &#123; return Qs.stringify(params, &#123;arrayFormat: 'brackets'&#125;) &#125;, // `data` 是作为请求主体被发送的数据 // 只适用于这些请求方法 'PUT', 'POST', 和 'PATCH' // 在没有设置 `transformRequest` 时，必须是以下类型之一： // - string, plain object, ArrayBuffer, ArrayBufferView, URLSearchParams // - 浏览器专属：FormData, File, Blob // - Node 专属： Stream data: &#123; firstName: 'Fred' &#125;, // `timeout` 指定请求超时的毫秒数(0 表示无超时时间) // 如果请求话费了超过 `timeout` 的时间，请求将被中断 timeout: 1000, // `withCredentials` 表示跨域请求时是否需要使用凭证 withCredentials: false, // 默认的 // `adapter` 允许自定义处理请求，以使测试更轻松 // 返回一个 promise 并应用一个有效的响应 (查阅 [response docs](#response-api)). adapter: function (config) &#123; /* ... */ &#125;, // `auth` 表示应该使用 HTTP 基础验证，并提供凭据 // 这将设置一个 `Authorization` 头，覆写掉现有的任意使用 `headers` 设置的自定义 `Authorization`头 auth: &#123; username: 'janedoe', password: 's00pers3cret' &#125;, // `responseType` 表示服务器响应的数据类型，可以是 'arraybuffer', 'blob', 'document', 'json', 'text', 'stream' responseType: 'json', // 默认的 // `xsrfCookieName` 是用作 xsrf token 的值的cookie的名称 xsrfCookieName: 'XSRF-TOKEN', // default // `xsrfHeaderName` 是承载 xsrf token 的值的 HTTP 头的名称 xsrfHeaderName: 'X-XSRF-TOKEN', // 默认的 // `onUploadProgress` 允许为上传处理进度事件 onUploadProgress: function (progressEvent) &#123; // 对原生进度事件的处理 &#125;, // `onDownloadProgress` 允许为下载处理进度事件 onDownloadProgress: function (progressEvent) &#123; // 对原生进度事件的处理 &#125;, // `maxContentLength` 定义允许的响应内容的最大尺寸 maxContentLength: 2000, // `validateStatus` 定义对于给定的HTTP 响应状态码是 resolve 或 reject promise 。如果 `validateStatus` 返回 `true` (或者设置为 `null` 或 `undefined`)，promise 将被 resolve; 否则，promise 将被 rejecte validateStatus: function (status) &#123; return status &gt;= 200 &amp;&amp; status &lt; 300; // 默认的 &#125;, // `maxRedirects` 定义在 node.js 中 follow 的最大重定向数目 // 如果设置为0，将不会 follow 任何重定向 maxRedirects: 5, // 默认的 // `httpAgent` 和 `httpsAgent` 分别在 node.js 中用于定义在执行 http 和 https 时使用的自定义代理。允许像这样配置选项： // `keepAlive` 默认没有启用 httpAgent: new http.Agent(&#123; keepAlive: true &#125;), httpsAgent: new https.Agent(&#123; keepAlive: true &#125;), // 'proxy' 定义代理服务器的主机名称和端口 // `auth` 表示 HTTP 基础验证应当用于连接代理，并提供凭据 // 这将会设置一个 `Proxy-Authorization` 头，覆写掉已有的通过使用 `header` 设置的自定义 `Proxy-Authorization` 头。 proxy: &#123; host: '127.0.0.1', port: 9000, auth: : &#123; username: 'mikeymike', password: 'rapunz3l' &#125; &#125;, // `cancelToken` 指定用于取消请求的 cancel token // （查看后面的 Cancellation 这节了解更多） cancelToken: new CancelToken(function (cancel) &#123; &#125;)&#125; 某个请求的响应包含以下信息 12345678910111213141516&#123; // `data` 由服务器提供的响应 data: &#123;&#125;, // `status` 来自服务器响应的 HTTP 状态码 status: 200, // `statusText` 来自服务器响应的 HTTP 状态信息 statusText: 'OK', // `headers` 服务器响应的头 headers: &#123;&#125;, // `config` 是为请求提供的配置信息 config: &#123;&#125;&#125; 错误处理 12345678910111213axios.get('/user/12345') .catch(function (error) &#123; if (error.response) &#123; // 请求已发出，但服务器响应的状态码不在 2xx 范围内 console.log(error.response.data); console.log(error.response.status); console.log(error.response.headers); &#125; else &#123; // Something happened in setting up the request that triggered an Error console.log('Error', error.message); &#125; console.log(error.config); &#125;); 可以使用 validateStatus 配置选项定义一个自定义 HTTP 状态码的错误范围 12345axios.get('/user/12345', &#123; validateStatus: function (status) &#123; return status &lt; 500; // 状态码在大于或等于500时才会 reject &#125;&#125;)","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://yugd.cn/tags/vue/"}]},{"title":"Vue系列--基本语法","slug":"Vue系列--程序","date":"2021-01-13T11:58:58.000Z","updated":"2022-05-26T18:19:45.549Z","comments":true,"path":"posts/56103/","link":"","permalink":"https://yugd.cn/posts/56103/","excerpt":"Vue.js 使用了基于 HTML 的模板语法，允许开发者声明式地将 DOM 绑定至底层 Vue 实例的数据。 Vue.js 的核心是一个允许你采用简洁的模板语法来声明式的将数据渲染进 DOM 的系统。 结合响应系统，在应用状态改变时， Vue 能够智能地计算出重新渲染组件的最小代价并应用到 DOM 操作上。","text":"Vue.js 使用了基于 HTML 的模板语法，允许开发者声明式地将 DOM 绑定至底层 Vue 实例的数据。 Vue.js 的核心是一个允许你采用简洁的模板语法来声明式的将数据渲染进 DOM 的系统。 结合响应系统，在应用状态改变时， Vue 能够智能地计算出重新渲染组件的最小代价并应用到 DOM 操作上。 文本插值123&lt;div id&#x3D;&quot;app&quot;&gt; &lt;p&gt;&#123;&#123; message &#125;&#125;&lt;&#x2F;p&gt;&lt;&#x2F;div&gt;v Html使用 v-html 指令用于输出 html 代码： 123456789101112&lt;div id&#x3D;&quot;app&quot;&gt; &lt;div v-html&#x3D;&quot;message&quot;&gt;&lt;&#x2F;div&gt;&lt;&#x2F;div&gt; &lt;script&gt;new Vue(&#123; el: &#39;#app&#39;, data: &#123; message: &#39;&lt;h1&gt;vue&lt;&#x2F;h1&gt;&#39; &#125;&#125;)&lt;&#x2F;script&gt; 属性HTML 属性中的值应使用 v-bind 指令 1234567891011121314&lt;div id&#x3D;&quot;app&quot;&gt; &lt;span v-bind:title&#x3D;&quot;message&quot;&gt; 鼠标悬停几秒钟查看此处动态绑定的提示信息！ &lt;&#x2F;span&gt;&lt;&#x2F;div&gt;&lt;script type&#x3D;&quot;text&#x2F;javascript&quot;&gt;new Vue(&#123; el: &#39;#app&#39;, data: &#123; message: &#39;页面加载于 &#39; + new Date().toLocaleString() &#125;&#125;)&lt;&#x2F;script&gt; 表达式Vue.js 都提供了完全的 JavaScript 表达式支持 1234567891011121314151617&lt;div id&#x3D;&quot;app&quot;&gt; &#123;&#123;5+5&#125;&#125;&lt;br&gt; &#123;&#123; ok ? &#39;YES&#39; : &#39;NO&#39; &#125;&#125;&lt;br&gt; &#123;&#123; message.split(&#39;&#39;).reverse().join(&#39;&#39;) &#125;&#125; &lt;div v-bind:id&#x3D;&quot;&#39;list-&#39; + id&quot;&gt;vue&lt;&#x2F;div&gt;&lt;&#x2F;div&gt; &lt;script&gt;new Vue(&#123; el: &#39;#app&#39;, data: &#123; ok: true, message: &#39;RUNOOB&#39;, id : 1 &#125;&#125;)&lt;&#x2F;script&gt; v-bind12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html xmlns:v-bind=\"http://www.w3.org/1999/xhtml\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Vue&lt;/title&gt; &lt;script src=\"https://gcore.jsdelivr.net/npm/vue@2.5.21/dist/vue.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"app\"&gt; &lt;span v-bind:title=\"message\"&gt; 鼠标悬停几秒钟查看此处动态绑定的提示信息！ &lt;/span&gt;&lt;/div&gt;&lt;script type=\"text/javascript\"&gt; var app = new Vue(&#123; el: '#app', data: &#123; message: '页面加载于 ' + new Date().toLocaleString() &#125; &#125;)&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-if,v-else123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Vue&lt;/title&gt; &lt;script src=\"https://gcore.jsdelivr.net/npm/vue@2.5.21/dist/vue.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"vue\"&gt; &lt;h1 v-if=\"ok\"&gt;YES&lt;/h1&gt; &lt;h1 v-else&gt;NO&lt;/h1&gt;&lt;/div&gt;&lt;script type=\"text/javascript\"&gt; var vm = new Vue(&#123; el: '#vue', data: &#123; ok: true &#125; &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-for12345&lt;div id=\"vue\"&gt; &lt;li v-for=\"item in items\"&gt; &#123;&#123; item.message &#125;&#125; &lt;/li&gt;&lt;/div&gt; items 是数组，item是数组元素迭代的别名 , 与Thymeleaf模板引擎的语法和这个十分的相似 1234567891011121314151617181920212223242526272829&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Vue&lt;/title&gt; &lt;script src=\"https://gcore.jsdelivr.net/npm/vue@2.5.21/dist/vue.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"vue\"&gt; &lt;li v-for=\"item in items\"&gt; &#123;&#123; item.message &#125;&#125; &lt;/li&gt;&lt;/div&gt;&lt;script type=\"text/javascript\"&gt; var vm = new Vue(&#123; el: '#vue', data: &#123; //items数组 items: [ &#123;message: 'Java'&#125;, &#123;message: 'Python'&#125; ] &#125; &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-on1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html xmlns:v-on=\"\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Vue&lt;/title&gt; &lt;script src=\"https://gcore.jsdelivr.net/npm/vue@2.5.21/dist/vue.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"vue\"&gt; &lt;!--在这里我们使用了 v-on 绑定了 click 事件，并指定了名为 sayHi 的方法--&gt; &lt;button v-on:click=\"sayHi\"&gt;点我&lt;/button&gt;&lt;/div&gt;&lt;script type=\"text/javascript\"&gt; var vm = new Vue(&#123; el: '#vue', data: &#123; message: 'Hello World' &#125;, // 方法必须定义在 Vue 实例的 methods 对象中 methods: &#123; sayHi: function (event) &#123; // `this` 在方法里指向当前 Vue 实例 alert(this.message); &#125; &#125; &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://yugd.cn/tags/vue/"}]},{"title":"Vue系列--创建项目","slug":"Vue系列--创建项目","date":"2021-01-10T11:58:58.000Z","updated":"2022-05-26T18:19:47.501Z","comments":true,"path":"posts/64634/","link":"","permalink":"https://yugd.cn/posts/64634/","excerpt":"第一个vue-cli项目确认nodejs安装成功: cmd 下输入 node -v,查看是否能够正确打印出版本号即可!（v12.14.0） cmd 下输入 npm -v,查看是否能够正确打印出版本号即可!（6.13.4） 12345# -g 就是全局安装$ npm install cnpm -g# 或使用如下语句解决 npm 速度慢的问题，启用淘宝镜像$ npm install --registry=https://registry.npm.taobao.org 安装 vue-cli 12345$ cnpm install vue-cli -g# 测试是否安装成功# 查看可以基于哪些模板创建 vue 应用程序，通常我们选择 webpack$ vue list","text":"第一个vue-cli项目确认nodejs安装成功: cmd 下输入 node -v,查看是否能够正确打印出版本号即可!（v12.14.0） cmd 下输入 npm -v,查看是否能够正确打印出版本号即可!（6.13.4） 12345# -g 就是全局安装$ npm install cnpm -g# 或使用如下语句解决 npm 速度慢的问题，启用淘宝镜像$ npm install --registry=https://registry.npm.taobao.org 安装 vue-cli 12345$ cnpm install vue-cli -g# 测试是否安装成功# 查看可以基于哪些模板创建 vue 应用程序，通常我们选择 webpack$ vue list 第一个 vue-cli 应用程序 创建一个Vue项目,我们随便建立一个空的文件夹在电脑上,我这里在D盘下新建一个目录，例如：D:\\Project\\vue\\vue-study; 创建一个基于 webpack 模板的 vue 应用程序 12# 这里的 myvue 是项目名称，可以根据自己的需求起名$ vue init webpack myvue 一路都选择no即可; Project name：项目名称，默认 回车 即可 Project description：项目描述，默认 回车 即可 Author：项目作者，默认 回车 即可 Install vue-router：是否安装 vue-router，选择 n 不安装（后期需要再手动添加） Use ESLint to lint your code：是否使用 ESLint 做代码检查，选择 n 不安装（后期需要再手动添加） Set up unit tests：单元测试相关，选择 n 不安装（后期需要再手动添加） Setup e2e tests with Nightwatch：单元测试相关，选择 n 不安装（后期需要再手动添加） Should we run npm install for you after the project has been created：创建完成后直接初始化，选择 n，我们手动执行;运行结果! 初始化并运行 123$ cd myvue$ npm install$ npm run dev 安装并运行成功后在浏览器输入：http://localhost:8080 build 和 config：WebPack 配置文件 node_modules：用于存放 npm install 安装的依赖文件 src： 项目源码目录 static：静态资源文件 .babelrc：Babel 配置文件，主要作用是将 ES6 转换为 ES5 .editorconfig：编辑器配置 eslintignore：需要忽略的语法检查配置文件 .gitignore：git 忽略的配置文件 .postcssrc.js：css 相关配置文件，其中内部的 module.exports 是 NodeJS 模块化语法 index.html：首页，仅作为模板页，实际开发时不使用 package.json：项目的配置文件 name：项目名称 version：项目版本 description：项目描述 author：项目作者 scripts：封装常用命令 dependencies：生产环境依赖 devDependencies：开发环境依赖 main.js项目的入口文件，我们知道所有的程序都会有一个入口 12345678910111213&#x2F;&#x2F; The Vue build version to load with the &#96;import&#96; command&#x2F;&#x2F; (runtime-only or standalone) has been set in webpack.base.conf with an alias.import Vue from &#39;vue&#39;import App from &#39;.&#x2F;App&#39;Vue.config.productionTip &#x3D; false;&#x2F;* eslint-disable no-new *&#x2F;new Vue(&#123; el: &#39;#app&#39;, components: &#123; App &#125;, template: &#39;&lt;App&#x2F;&gt;&#39;&#125;); App.vue12345678910111213141516171819202122232425262728&lt;template&gt; &lt;div id&#x3D;&quot;app&quot;&gt; &lt;img src&#x3D;&quot;.&#x2F;assets&#x2F;logo.png&quot;&gt; &lt;HelloWorld&#x2F;&gt; &lt;&#x2F;div&gt;&lt;&#x2F;template&gt;&lt;script&gt;import HelloWorld from &#39;.&#x2F;components&#x2F;HelloWorld&#39;export default &#123; name: &#39;App&#39;, components: &#123; HelloWorld &#125;&#125;&lt;&#x2F;script&gt;&lt;style&gt;#app &#123; font-family: &#39;Avenir&#39;, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px;&#125;&lt;&#x2F;style&gt; 第一个Vue页面1、创建一个 HTML 文件 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 2、引入 Vue.js 1&lt;script src=\"https://gcore.jsdelivr.net/npm/vue@2.5.21/dist/vue.js\"&gt;&lt;/script&gt; 3、创建一个 Vue 的实例 12345678&lt;script type=\"text/javascript\"&gt; var vm = new Vue(&#123; el: '#vue', data: &#123; message: 'Hello Vue!' &#125; &#125;);&lt;/script&gt; 123el:'#vue'：绑定元素的 IDdata:&#123;message:'Hello Vue!'&#125;`：数据对象中有一个名为 message 的属性，并设置了初始值 Hello Vue! 4、将数据绑定到页面元素 123&lt;div id=\"vue\"&gt; &#123;&#123;message&#125;&#125;&lt;/div&gt; 完整的 HTML12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;第一个 Vue 应用程序&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;!--View--&gt;&lt;div id=\"vue\"&gt; &#123;&#123;message&#125;&#125;&lt;/div&gt;&lt;script src=\"https://gcore.jsdelivr.net/npm/vue@2.5.21/dist/vue.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\"&gt; // var vm = new Vue(&#123;&#125;); //ViewModel var vm = new Vue(&#123; el: '#vue', data: &#123; //Model message: 'Hello Vue!' &#125; &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 彩蛋一、新建项目123456789101112131.查看 node和npm是不是已经安装好命令：node -v npm -v (没有安装的先安装环境);2.$ npm install -g cnpm --registry=https://registry.npm.taobao.org (安装国内的淘宝镜像文件，后面的安装npm可以全部改为cnpm)3.安装 vue-cli 脚手架 1、$ cnpm install -g vue 2、$ cnpm install -g vue-cli //检测是否安装成功 vue --version4. 安装 webpack $ cnpm install -g webpack 5.cd 你的运行目录6.新建基于webpack的vue项目 $ vue init webpack vuedemo7.进入项目目录 $ cd vuedemo8.安装依赖 $ cnpm install9.运行项目 $ cnpm run dev10.发布项目 $ cnpm run build注：mac电脑需要在安装淘宝镜像前执行： sudo chown -R $USER /usr/local 二、使用element-ui前需安装修改的配置：12345678//1. 安装 loader 模块： $ cnpm install style-loader -D $ cnpm install css-loader -D $ cnpm install file-loader -D//2. 安装 Element-UI 模块 $ cnpm install element-ui --save //3. 修改 webpack.base.conf.js 的配置","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://yugd.cn/tags/vue/"}]},{"title":"Adroid Util","slug":"学习--Android-Utila","date":"2020-08-09T13:26:06.000Z","updated":"2022-05-26T18:18:59.169Z","comments":true,"path":"posts/53798/","link":"","permalink":"https://yugd.cn/posts/53798/","excerpt":"Android中的日志工具类是Log（android.util.Log），这个类中提供了如下5个方法来供我们打印日志。 Log.v()。用于打印那些最为琐碎的、意义最小的日志信息。对应级别verbose，是Android日志里面级别最低的一种。 Log.d()。用于打印一些调试信息，这些信息对你调试程序和分析问题应该是有帮助的。对应级别debug，比verbose高一级。 Log.i()。用于打印一些比较重要的数据，这些数据应该是你非常想看到的、可以帮你分析用户行为数据。对应级别info，比debug高一级。 Log.w()。用于打印一些警告信息，提示程序在这个地方可能会有潜在的风险，最好去修复一下这些出现警告的地方。对应级别warn，比info高一级。 Log.e()。用于打印程序中的错误信息，比如程序进入到了catch语句当中。当有错误信息打印出来的时候，一般都代表你的程序出现严重问题了，必须尽快修复。对应级别error，比warn高一级。","text":"Android中的日志工具类是Log（android.util.Log），这个类中提供了如下5个方法来供我们打印日志。 Log.v()。用于打印那些最为琐碎的、意义最小的日志信息。对应级别verbose，是Android日志里面级别最低的一种。 Log.d()。用于打印一些调试信息，这些信息对你调试程序和分析问题应该是有帮助的。对应级别debug，比verbose高一级。 Log.i()。用于打印一些比较重要的数据，这些数据应该是你非常想看到的、可以帮你分析用户行为数据。对应级别info，比debug高一级。 Log.w()。用于打印一些警告信息，提示程序在这个地方可能会有潜在的风险，最好去修复一下这些出现警告的地方。对应级别warn，比info高一级。 Log.e()。用于打印程序中的错误信息，比如程序进入到了catch语句当中。当有错误信息打印出来的时候，一般都代表你的程序出现严重问题了，必须尽快修复。对应级别error，比warn高一级。 其实很简单，一共就5个方法，当然每个方法还会有不同的重载，但那对你来说肯定不是什么难理解的地方了。我们现在就在HelloWorld项目中试一试日志工具好不好用吧。 1234567891011public class MainActivity extends AppCompatActivity &#123; String Tag; @Override protected void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Log.d(Tag,\"OnCreate execute!\"); &#125;&#125; Log.d()方法中传入了两个参数：第一个参数是tag，一般传入当前的类名就好，主要用于对打印信息进行过滤；第二个参数是msg，即想要打印的具体的内容。 这里还有一个小技巧，我们在onCreate()方法的外面输入logt，然后按下Tab键，这时就会以当前的类名作为值自动生成一个TAG常量。","categories":[{"name":"Android","slug":"Android","permalink":"https://yugd.cn/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://yugd.cn/tags/Android/"}]},{"title":"Android Knowledge (Start)","slug":"学习--Android-Knowledge","date":"2020-08-09T13:20:18.000Z","updated":"2022-05-26T18:18:57.129Z","comments":true,"path":"posts/8261/","link":"","permalink":"https://yugd.cn/posts/8261/","excerpt":"JDK JDK是java语言的软件开发工具包，它包含了java的运行环境，工具集合，基础类库等内容 Android SDK 是谷歌提供的 Android 开发包，在开发Android 项目的时候 我们需要引入Android SDK 来使用Android 的相关API","text":"JDK JDK是java语言的软件开发工具包，它包含了java的运行环境，工具集合，基础类库等内容 Android SDK 是谷歌提供的 Android 开发包，在开发Android 项目的时候 我们需要引入Android SDK 来使用Android 的相关API 分析你的第一个Android程序 根目录 1 . gradle和.idea 这两个目录下放置的都是Android Studio自动生成的一些文件，我们无须关心，也不要去手动编辑。 2 . app 项目中的代码、资源等内容几乎都是放置在这个目录下的，我们后面的开发工作也基本都是在这个目录下进行的，待会儿还会对这个目录单独展开进行讲解。 3 . build 这个目录你也不需要过多关心，它主要包含了一些在编译时自动生成的文件。 4 . gradle 类似php的composer 这个目录下包含了gradle wrapper的配置文件，使用gradle wrapper的方式不需要提前将gradle下载好，而是会自动根据本地的缓存情况决定是否需要联网下载gradle。Android Studio默认没有启用gradle wrapper的方式，如果需要打开，可以点击Android Studio导航栏→File→Settings→Build, Execution, Deployment→Gradle，进行配置更改。 5 . .gitignore 这个文件是用来将指定的目录或文件排除在版本控制之外的，关于版本控制我们将在第5章中开始正式的学习。 6 . build.gradle 这是项目全局的gradle构建脚本，通常这个文件中的内容是不需要修改的。稍后我们将会详细分析gradle构建脚本中的具体内容。 7 . gradle.properties 这个文件是全局的gradle配置文件，在这里配置的属性将会影响到项目中所有的gradle编译脚本。 8 . gradlew和gradlew.bat 这两个文件是用来在命令行界面中执行gradle命令的，其中gradlew是在Linux或Mac系统中使用的，gradlew.bat是在Windows系统中使用的。 9 . HelloWorld.iml iml文件是所有IntelliJ IDEA项目都会自动生成的一个文件（Android Studio是基于IntelliJ IDEA开发的），用于标识这是一个IntelliJ IDEA项目，我们不需要修改这个文件中的任何内容。 10 . local.properties 这个文件用于指定本机中的Android SDK路径，通常内容都是自动生成的，我们并不需要修改。除非你本机中的Android SDK位置发生了变化，那么就将这个文件中的路径改成新的位置即可。 11 . settings.gradle 这个文件用于指定项目中所有引入的模块。由于HelloWorld项目中就只有一个app模块，因此该文件中也就只引入了app这一个模块。通常情况下模块的引入都是自动完成的，需要我们手动去修改这个文件的场景可能比较少。 app目录 1 . build 这个目录和外层的build目录类似，主要也是包含了一些在编译时自动生成的文件，不过它里面的内容会更多更杂，我们不需要过多关心。 2 . libs 如果你的项目中使用到了第三方jar包，就需要把这些jar包都放在libs目录下，放在这个目录下的jar包都会被自动添加到构建路径里去。 3 . androidTest 此处是用来编写Android Test测试用例的，可以对项目进行一些自动化测试。 4 . java 毫无疑问，java目录是放置我们所有Java代码的地方，展开该目录，你将看到我们刚才创建的HelloWorldActivity文件就在里面。 5 . res 这个目录下的内容就有点多了。简单点说，就是你在项目中使用到的所有图片、布局、字符串等资源都要存放在这个目录下。当然这个目录下还有很多子目录， 图片放在drawable目录下， 布局放在layout目录下， 字符串放在values目录下， 所以你不用担心会把整个res目录弄得乱糟糟的。 6 . AndroidManifest.xml 这是你整个Android项目的配置文件，你在程序中定义的所有四大组件都需要在这个文件里注册，另外还可以在这个文件中给应用程序添加权限声明。由于这个文件以后会经常用到，我们用到的时候再做详细说明。 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;manifest xmlns:android=\"http://schemas.android.com/apk/res/android\" package=\"com.ase\"&gt; &lt;application android:allowBackup=\"true\" android:icon=\"@mipmap/ic_launcher\" android:label=\"@string/app_name\" android:roundIcon=\"@mipmap/ic_launcher_round\" android:supportsRtl=\"true\" android:theme=\"@style/AppTheme\"&gt; &lt;activity android:name=\".MainActivity\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"android.intent.action.MAIN\" /&gt; &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;/application&gt;&lt;/manifest&gt; 7 . test 此处是用来编写Unit Test测试用例的，是对项目进行自动化测试的另一种方式。 8 . .gitignore 这个文件用于将app模块内的指定的目录或文件排除在版本控制之外，作用和外层的.gitignore文件类似。 9 . app.iml IntelliJ IDEA项目自动生成的文件，我们不需要关心或修改这个文件中的内容。 10 . build.gradle 这是app模块的gradle构建脚本，这个文件中会指定很多项目构建相关的配置，我们稍后将会详细分析gradle构建脚本中的具体内容。 123456789101112131415161718192021222324252627282930313233apply plugin: 'com.android.application'android &#123; compileSdkVersion 30 buildToolsVersion \"30.0.1\" defaultConfig &#123; applicationId \"com.ase\" minSdkVersion 17 targetSdkVersion 30 versionCode 1 versionName \"1.0\" testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\" &#125; buildTypes &#123; release &#123; minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro' &#125; &#125;&#125;dependencies &#123; implementation fileTree(dir: \"libs\", include: [\"*.jar\"]) implementation 'androidx.appcompat:appcompat:1.1.0' implementation 'androidx.constraintlayout:constraintlayout:1.1.3' testImplementation 'junit:junit:4.12' androidTestImplementation 'androidx.test.ext:junit:1.1.1' androidTestImplementation 'androidx.test.espresso:espresso-core:3.2.0'&#125; 第一行应用了一个插件，一般有两种值可选：com.android.application表示这是一个应用程序模块，com.android.library表示这是一个库模块。应用程序模块和库模块的最大区别在于，一个是可以直接运行的，一个只能作为代码库依附于别的应用程序模块来运行。 接下来是一个大的android闭包，在这个闭包中我们可以配置项目构建的各种属性。其中， compileSdkVersion 用于指定项目的编译版本，这里指定成30表示使用Android 7.0系统的SDK编译。 buildToolsVersion 用于指定项目构建工具的版本，目前最新的版本就是30.0.1， 如果有更新的版本时，Android Studio会进行提示。 然后我们看到，这里在android闭包中又嵌套了一个defaultConfig闭包，defaultConfig闭包中可以对项目的更多细节进行配置。","categories":[{"name":"Android","slug":"Android","permalink":"https://yugd.cn/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://yugd.cn/tags/Android/"}]},{"title":"ssm整合","slug":"实践--ssm整合","date":"2020-08-09T13:18:01.000Z","updated":"2021-10-26T14:26:00.145Z","comments":true,"path":"posts/49098/","link":"","permalink":"https://yugd.cn/posts/49098/","excerpt":"环境： IDEA MySQL 5.7.19 Tomcat 9 Maven 3.6","text":"环境： IDEA MySQL 5.7.19 Tomcat 9 Maven 3.6 数据库环境创建一个存放书籍数据的数据库表 ssmbuild 123456789101112131415161718CREATE DATABASE `ssmbuild`;USE `ssmbuild`;DROP TABLE IF EXISTS `books`;CREATE TABLE `books` ( `bookID` INT(10) NOT NULL AUTO_INCREMENT COMMENT '书id', `bookName` VARCHAR(100) NOT NULL COMMENT '书名', `bookCounts` INT(11) NOT NULL COMMENT '数量', `detail` VARCHAR(200) NOT NULL COMMENT '描述', KEY `bookID` (`bookID`)) ENGINE=INNODB DEFAULT CHARSET=utf8INSERT INTO `books`(`bookID`,`bookName`,`bookCounts`,`detail`)VALUES (1,'Java',1,'从入门到放弃'),(2,'MySQL',10,'从删库到跑路'),(3,'Linux',5,'从进门到进牢'); 基本环境搭建1、新建一个Maven项目 ssmbuild ， 添加web的支持 2、导入相关的pom依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;dependencies&gt; &lt;!--Junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!--数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 数据库连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.mchange&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Servlet - JSP --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Spring--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.1.9.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3、Maven资源过滤设置 1234567891011121314151617181920&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 4、建立基本结构和配置框架 com.guo.controller com.guo.dao com.guo.pojo com.guo.service mybatis-config.xml 1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt;&lt;/configuration&gt; applicationContext.xml 1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt;&lt;/beans&gt; Mybatis层编写1、数据库配置文件 database.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/(数据库名)?useSSL=true&amp;useUnicode=true&amp;characterEncoding=utf8jdbc.username=rootjdbc.password=root 2、IDEA关联数据库 3、编写MyBatis的核心配置文件 mybatis-config.xml 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;package name=\"com.guo.pojo\"/&gt; &lt;/typeAliases&gt; &lt;mappers&gt; &lt;mapper resource=\"com/guo/dao/XxxMapper.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 4、编写数据库对应的实体类 com.guo.pojo.Xxx使用lombok插件！ 1234567891011121314151617package com.guo.pojo;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;@Data@AllArgsConstructor@NoArgsConstructorpublic class Xxx &#123; private int ID; private String Name; private int Counts; private String detail; &#125; 5、编写Dao层的 Mapper接口 1234567891011121314151617181920212223package com.guo.dao;import com.guo.pojo.Xxx;import java.util.List;public interface XxxMapper &#123; //增加一个Xxx int addXxx(Xxx xxx); //根据id删除一个Xxx int deleteXxxById(int id); //更新Xxx int updateXxx(Xxx xxx); //根据id查询,返回一个Xxx Books queryXxxById(int id); //查询全部Xxx,返回list集合 List&lt;Xxx&gt; queryAllXxx();&#125; 6、编写接口对应的 Mapper.xml 文件，需要导入MyBatis的包 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.guo.dao.XxxMapper\"&gt; &lt;!--增加一个Xxx--&gt; &lt;insert id=\"addXxx\" parameterType=\"Xxx\"&gt; insert into ssmbuild.xxx(xxxName,xxxCounts,detail) values (#&#123;xxxName&#125;, #&#123;xxxCounts&#125;, #&#123;detail&#125;) &lt;/insert&gt; &lt;!--根据id删除一个Xxx--&gt; &lt;delete id=\"deletexxById\" parameterType=\"int\"&gt; delete from ssmbuild.xxx where xxxID=#&#123;xxxID&#125; &lt;/delete&gt; &lt;!--更新Xxx--&gt; &lt;update id=\"updateXxx\" parameterType=\"Xxx\"&gt; update ssmbuild.Xxx set xxxName = #&#123;xxxName&#125;,xxxCounts = #&#123;xxxCounts&#125;,detail = #&#123;detail&#125; where xxxID = #&#123;xxxID&#125; &lt;/update&gt; &lt;!--根据id查询,返回一个Xxx--&gt; &lt;select id=\"queryXxxById\" resultType=\"Xxx\"&gt; select * from ssmbuild.books where xxxID = #&#123;xxxID&#125; &lt;/select&gt; &lt;!--查询全部Xxx--&gt; &lt;select id=\"queryAllXxx\" resultType=\"Xxx\"&gt; SELECT * from ssmbuild.xxx &lt;/select&gt;&lt;/mapper&gt; 7、编写Service层的接口和实现类 接口: 12345678910111213141516171819package com.guo.service;import com.guo.pojo.Xxx;import java.util.List;//XxxService:底下需要去实现,调用dao层public interface XxxService &#123; //增加一个Xxx int addXxx(Xxx xxx); //根据id删除一个Xxx int deleteXxxById(int id); //更新Xxx int updateXxx(Xxx xxx); //根据id查询,返回一个Xxx Xxx queryXxxById(int id); //查询全部Xxx,返回list集合 List&lt;Xxx&gt; queryAllXxx();&#125; 实现类： 1234567891011121314151617181920212223242526272829303132333435package com.guo.service;import com.guo.dao.XxxMapper;import com.guo.pojo.Xxx;import java.util.List;public class XxxServiceImpl implements XxxService &#123; //调用dao层的操作，设置一个set接口，方便Spring管理 private XxxMapper XxxMapper; public void setXxxMapper(XxxMapper xxxMapper) &#123; this.xxxMapper = xxxMapper; &#125; public int addXxx(Xxx xxx) &#123; return xxxMapper.addXxx(xxx); &#125; public int deleteXxxById(int id) &#123; return xxxMapper.deleteXxxById(id); &#125; public int updateXxx(Xxx xxx) &#123; return xxxMapper.updateXxx(xxx); &#125; public Books queryXxxById(int id) &#123; return xxxMapper.queryXxxById(id); &#125; public List&lt;Xxx&gt; queryAllXxx() &#123; return xxxMapper.queryAllXxx(); &#125;&#125; Spring层编写Spring整合Mybatis的相关的配置文件 spring-dao.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexthttps://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 配置整合mybatis --&gt; &lt;!-- 1.关联数据库文件 --&gt; &lt;context:property-placeholder location=\"classpath:database.properties\"/&gt; &lt;!-- 2.数据库连接池 --&gt; &lt;!--数据库连接池 dbcp 半自动化操作 不能自动连接 c3p0 自动化操作（自动的加载配置文件 并且设置到对象里面） --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;!-- 配置连接池属性 --&gt; &lt;property name=\"driverClass\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"jdbcUrl\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"user\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;!-- c3p0连接池的私有属性 --&gt; &lt;property name=\"maxPoolSize\" value=\"30\"/&gt; &lt;property name=\"minPoolSize\" value=\"10\"/&gt; &lt;!-- 关闭连接后不自动commit --&gt; &lt;property name=\"autoCommitOnClose\" value=\"false\"/&gt; &lt;!-- 获取连接超时时间 --&gt; &lt;property name=\"checkoutTimeout\" value=\"10000\"/&gt; &lt;!-- 当获取连接失败重试次数 --&gt; &lt;property name=\"acquireRetryAttempts\" value=\"2\"/&gt; &lt;/bean&gt; &lt;!-- 3.配置SqlSessionFactory对象 --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!-- 配置MyBaties全局配置文件:mybatis-config.xml --&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;/bean&gt; &lt;!-- 4.配置扫描Dao接口包，动态实现Dao接口注入到spring容器中 --&gt; &lt;!--解释 ： https://www.cnblogs.com/jpfss/p/7799806.html--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;!-- 注入sqlSessionFactory --&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt; &lt;!-- 给出需要扫描Dao接口包 --&gt; &lt;property name=\"basePackage\" value=\"com.guo.dao\"/&gt; &lt;/bean&gt;&lt;/beans&gt; Spring整合service层 spring-service.xml 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 扫描service相关的bean --&gt; &lt;context:component-scan base-package=\"com.guo.service\" /&gt; &lt;!--XxxServiceImpl注入到IOC容器中--&gt; &lt;bean id=\"XxxServiceImpl\" class=\"com.guo.service.XxxServiceImpl\"&gt; &lt;property name=\"xxxMapper\" ref=\"xxxMapper\"/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;/bean&gt;&lt;/beans&gt; SpringMVC层web.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"&gt; &lt;!--DispatcherServlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--encodingFilter--&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt; org.springframework.web.filter.CharacterEncodingFilter &lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--Session过期时间--&gt; &lt;session-config&gt; &lt;session-timeout&gt;15&lt;/session-timeout&gt; &lt;/session-config&gt; &lt;/web-app&gt; spring-mvc.xml 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!-- 配置SpringMVC --&gt; &lt;!-- 1.开启SpringMVC注解驱动 --&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- 2.静态资源默认servlet配置--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 3.配置jsp 显示ViewResolver视图解析器 --&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"viewClass\" value=\"org.springframework.web.servlet.view.JstlView\" /&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/views/\" /&gt; &lt;property name=\"suffix\" value=\".jsp\" /&gt; &lt;/bean&gt; &lt;!-- 4.扫描web相关的bean --&gt; &lt;context:component-scan base-package=\"com.guo.controller\" /&gt;&lt;/beans&gt; Spring配置整合文件，applicationContext.xml 1234567891011&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;import resource=\"spring-dao.xml\"/&gt; &lt;import resource=\"spring-service.xml\"/&gt; &lt;import resource=\"spring-mvc.xml\"/&gt; &lt;/beans&gt; Controller 和 视图层编写 1、XxxController 类编写 123456789101112131415@Controller@RequestMapping(\"/xxx\")public class XxxController &#123; @Autowired @Qualifier(\"XxxServiceImpl\") private XxxService xxxService; @RequestMapping(\"/allXxx\") public String list(Model model) &#123; List&lt;Xxx&gt; list = xxxService.queryAllXxx(); model.addAttribute(\"list\", list); return \"allXxx\"; &#125;&#125; *2、编写首页 index.jsp * 1234567891011121314151617181920212223242526272829&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\" %&gt;&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;首页&lt;/title&gt; &lt;style type=\"text/css\"&gt; a &#123; text-decoration: none; color: black; font-size: 18px; &#125; h3 &#123; width: 180px; height: 38px; margin: 100px auto; text-align: center; line-height: 38px; background: deepskyblue; border-radius: 4px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt; &lt;a href=\"$&#123;pageContext.request.contextPath&#125;/xxx/allxxx\"&gt;点击进入列表页&lt;/a&gt;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"后端","slug":"后端","permalink":"https://yugd.cn/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://yugd.cn/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"Restful","slug":"面试--Restful","date":"2020-07-06T11:41:13.000Z","updated":"2021-10-26T14:26:00.209Z","comments":true,"path":"posts/43426/","link":"","permalink":"https://yugd.cn/posts/43426/","excerpt":"什么是RESTful？REST：指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是RESTful。 如何设计RESTful应用程序的API?路径设计：数据库设计完毕之后，基本上就可以确定有哪些资源要进行操作，相对应的路径也可以设计出来。 动词设计：也就是针对资源的具体操作类型，有HTTP动词表示，常用的HTTP动词如下：POST、DELETE、PUT、GET","text":"什么是RESTful？REST：指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是RESTful。 如何设计RESTful应用程序的API?路径设计：数据库设计完毕之后，基本上就可以确定有哪些资源要进行操作，相对应的路径也可以设计出来。 动词设计：也就是针对资源的具体操作类型，有HTTP动词表示，常用的HTTP动词如下：POST、DELETE、PUT、GET 几个注解在讲述使用之前，想要理解SpringMVC的几个常用注解： @Controller：修饰class，用来创建处理http请求的对象 @RestController：Spring4之后加入的注解，原来在@Controller中返回json需要- - @ResponseBody来配合，如果直接用@RestController替代@Controller就不需要再配置@ResponseBody，默认返回json格式。 @RequestMapping：配置url映射 @PostMapping: 这个是@RequestMapping+POST方法的简写 @RequestHeader: 请求Header参数 @PathVariable: URL路径参数，比如/user/{id}中的id参数 @RequestParam: URL请求参数，比如/user?id=1中的id参数 @RequestBody: 请求Body参数 常用响应状态码（在RESTful 中有重要应用） 响应状态码 解释 200 OK //客户端请求成功 400 Bad Request //客户端请求有语法错误，不能被服务器所理解 401 Unanthorized //服务器收到请求，但是服务器拒绝提供服务 404 404 Not Found //请求资源不存在 500 Internal Serval Error //服务器发生不可预期的错误 503 Server Unavailable // 服务器当前不能处理客户端的请求 RESTful API设计示例 模块 功能 URL HTTP请求方式 用户 用户注册 http://api.demo.com/1.0/users/register POST 用户 用户登录 http://api.demo.com/1.0/users/login POST 文章 发表文章 http://api.demo.com/1.0/articles POST 文章 查看文章 http://api.demo.com/1.0/articles/:id GET 文章 修改文章 http://api.demo.com/1.0/articles/:id PUT 文章 删除文章 http://api.demo.com/1.0/aritcles/:id DELETE RequestHTTP方法通过标准HTTP方法对资源CRUD： GET：查询 123GET /zoosGET /zoos/1GET /zoos/1/employees POST：创建单个资源。POST一般向“资源集合”型uri发起 12POST /animals //新增动物POST /zoos/1/employees //为id为1的动物园雇佣员工 PUT：更新单个资源（全量），客户端提供完整的更新后的资源。与之对应的是 PATCH，PATCH 负责部分更新，客户端提供要更新的那些字段。PUT/PATCH一般向“单个资源”型uri发起 12PUT /animals/1PUT /zoos/1 DELETE：删除 123DELETE /zoos/1/employees/2DELETE /zoos/1/employees/2;4;5DELETE /zoos/1/animals //删除id为1的动物园内的所有动物 API设计RESTful API具体设计如下： 请求类型 URL 功能说明 GET /users 查询用户列表 POST /users 创建一个用户 GET /users/{id} 根据id查询用户 PUT /users/{id} 根据id更新用户 DELTE /users/{id} 更加id删除用户 1.POST 12345678910111213141516171819//POST方式$(function () &#123; //请求参数 var list = &#123;&#125;; $.ajax(&#123; type: \"POST\", //accepts: \"application/json\", contentType: \"application/json\", url: \"\", data: JSON.stringify(list), success: function (result) &#123; //。。。 &#125;, error: function (e) &#123; console.log(e.status); console.log(e.responseText); &#125; &#125;);&#125;); 2.GET方式 12345678910111213141516//GET方式$(function () &#123; //请求参数 var list = &#123;&#125;; $.ajax(&#123; type: \"GET\", //自动添加时间戳，避免缓存。 cache: false, url: \"\", success: function (data) &#123; $.each(data, function (key, item) &#123; //数据处理 &#125;); &#125; &#125;);&#125;); 3.PUT方式 12345678910111213141516171819//PUT方式$(function () &#123; //请求参数 var item = &#123;&#125;; $.ajax(&#123; type: \"PUT\", url: uri + \"/\" + $(\"#edit-id\").val(), //accepts: \"application/json\", contentType: \"application/json\", data: JSON.stringify(item), success: function (result) &#123; //。。。 &#125;, error: function (e) &#123; console.log(e.status); console.log(e.responseText); &#125; &#125;);&#125;); 4.Delete方式 123456789$(function()&#123; $.ajax(&#123; url: uri + \"/\" + id, type: \"DELETE\", success: function (result) &#123; getData(); &#125; &#125;);&#125;);","categories":[{"name":"规范","slug":"规范","permalink":"https://yugd.cn/categories/%E8%A7%84%E8%8C%83/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://yugd.cn/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"SpringBoot+MyBatis整合","slug":"实践--SpringBoot-MyBatis","date":"2020-06-09T10:12:17.000Z","updated":"2021-10-26T14:26:00.137Z","comments":true,"path":"posts/58659/","link":"","permalink":"https://yugd.cn/posts/58659/","excerpt":"首先我们需要在pom.xml中引入两个依赖，依赖如下： 123456&lt;!-- mybatis逆向工程jar包 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.4&lt;/version&gt;&lt;/dependency&gt; 123456789&lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;configurationFile&gt;src/main/resources/generator/generatorConfig.xml&lt;/configurationFile&gt; &lt;/configuration&gt;&lt;/plugin&gt;","text":"首先我们需要在pom.xml中引入两个依赖，依赖如下： 123456&lt;!-- mybatis逆向工程jar包 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.4&lt;/version&gt;&lt;/dependency&gt; 123456789&lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;configurationFile&gt;src/main/resources/generator/generatorConfig.xml&lt;/configurationFile&gt; &lt;/configuration&gt;&lt;/plugin&gt; 需要注意的是，src/main/resources/generator/generatorConfig.xml中的内容一定要写generatorConfig.xml从src开始的全路径，因为在执行逆向工程的时候会根据这个路径去读取generatorConfig.xml中的配置。 在resources包下创建一个generator文件夹，然后在文件夹中创建generatorConfig.xml文件，即：src/main/resources/generator/generatorConfig.xmlgeneratorConfig.xml中的配置人如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;generatorConfiguration&gt; &lt;!-- 数据库驱动:选择你的本地硬盘上面的数据库驱动包--&gt; &lt;classPathEntry location=\"E:/REPOSITORY/repository/mysql/mysql-connector-java/5.1.30/mysql-connector-java-5.1.30.jar\"/&gt; &lt;context id=\"DB2Tables\" targetRuntime=\"MyBatis3\"&gt; &lt;!-- JavaBean 实现 序列化 接口 --&gt; &lt;plugin type=\"org.mybatis.generator.plugins.SerializablePlugin\" /&gt; &lt;!-- 生成toString --&gt; &lt;plugin type=\"org.mybatis.generator.plugins.ToStringPlugin\" /&gt; &lt;!-- optional，旨在创建class时，对注释进行控制 --&gt; &lt;commentGenerator&gt; &lt;property name=\"suppressDate\" value=\"true\"/&gt; &lt;!-- &lt;property name=\"suppressAllComments\" value=\"true\"/&gt;--&gt; &lt;/commentGenerator&gt; &lt;!--数据库链接URL，用户名、密码 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://127.0.0.1:3306/test1\" userId=\"root\" password=\"root\"&gt; &lt;/jdbcConnection&gt; &lt;!-- 类型转换 --&gt; &lt;javaTypeResolver &gt; &lt;!-- 是否使用bigDecimal, false: 把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer(默认) true: 把JDBC DECIMAL 和 NUMERIC 类型解析为java.math.BigDecimal --&gt; &lt;property name=\"forceBigDecimals\" value=\"false\" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- 生成模型的包名和位置--&gt; &lt;javaModelGenerator targetPackage=\"com.heqiang.springboot_user.pojo\" targetProject=\"src/main/java\"&gt; &lt;!-- 默认false 是否允许子包 --&gt; &lt;property name=\"enableSubPackages\" value=\"true\" /&gt; &lt;!-- 默认false 是否对model添加 构造函数 --&gt; &lt;property name=\"constructorBased\" value=\"false\"/&gt; &lt;!-- 默认false 建立的Model对象是否 不可改变 即生成的Model对象不会有 setter方法，只有构造方法 --&gt; &lt;property name=\"immutable\" value=\"false\"/&gt; &lt;!-- 默认false 是否对类CHAR类型的列的数据进行trim操作 --&gt; &lt;property name=\"trimStrings\" value=\"true\" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成映射文件的包名和位置--&gt; &lt;sqlMapGenerator targetPackage=\"Mapper\" targetProject=\"src/main/resources\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 生成DAO的包名和位置--&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"com.heqiang.springboot_user.dao\" targetProject=\"src/main/java\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 要生成的表 tableName是数据库中的表名或视图名 domainObjectName是实体类名--&gt; &lt;!-- &lt;table tableName=\"risk_model_order\" domainObjectName=\"DSRiskModelOrder\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"&gt;&lt;/table&gt; &lt;table tableName=\"tel_bill_record\" domainObjectName=\"DSTelBillRecord\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" selectByExampleQueryId=\"false\"&gt;&lt;/table&gt;--&gt; &lt;table tableName=\"user\"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 如果逆向工程配置完毕 一、mapper.xml在src/main/java目录下 12//下面在启动类里加上注解用于给出需要扫描的mapper文件路径@MapperScan(\"com.gyh.mapper\") SpringBootApplication.class 1234567891011121314package com.example; import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; @MapperScan(\"com.gyh.mapper\") //扫描的mapper@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 配置完了之后，我们就可执行逆向工程了，点击右侧的Maven，就能看到下面的结构，然后根据如果的路径找到mybatis-generator,双击运行即可 application.yml 1234567891011121314151617181920212223242526 # Tomcat 服务器端口号server: port: 8080spring: thymeleaf: mode: HTML5 encoding: UTF-8 content-type: text/html # 开发禁用缓存 cache: false datasource: url: jdbc:mysql://localhost:3306/ssmDb?characterEncoding=UTF-8&amp;useSSL=true username: root password: password # 可省略驱动配置, sprin-boot 会由url检测出驱动类型 # driver-class-name: com.mysql.jdbc.Driver hikari: connection-timeout: 60000 mybatis: # 配置实体类包别名 typeAliasesPackage: cn.gyh.entity# spring-boot默认打印输出info级别以上的，可在此处修改输出级别logging: level: root: info 二、mapper.xml在src/main/resources目录下 （1）spring-boot配置 不少人都Properties资源文件来配置，不过这种文件在idea编码的默认设置是ISO-8859-1，需要修改idea的设置才能显示中文。因此我比较喜欢用yml文件来配置，一个是结构明显，另外一个不用考虑编码的问题。 application.yml 12345678910111213141516171819202122232425spring: thymeleaf: mode: HTML5 encoding: UTF-8 content-type: text/html # 开发禁用缓存 cache: false datasource: url: jdbc:mysql://localhost:3306/ssmDb?characterEncoding=UTF-8&amp;useSSL=true username: root password: password # 可省略驱动配置, sprin-boot 会由url检测出驱动类型 # driver-class-name: com.mysql.jdbc.Driver hikari: connection-timeout: 60000 mybatis: #配置mapper mapperLocations: classpath:mapper/*.xml #配置实体类 typeAliasesPackage: com.gyh.entity# spring-boot默认打印输出info级别以上的，可在此处修改输出级别logging: config: classpath:logback-spring.xml level: root: info 2）日志打印logback-spring.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;%date [%thread] %-5level %logger&#123;80&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出 level为 INFO 日志 --&gt; &lt;appender name=\"file-info\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY &lt;/onMismatch&gt; &lt;/filter&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt;./logs/info.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date [%thread] %-5level %logger&#123;80&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出 level为 DEBUG 日志 --&gt; &lt;appender name=\"file-debug\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;DEBUG&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY &lt;/onMismatch&gt; &lt;/filter&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt;./logs/debug.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date [%thread] %-5level %logger&#123;80&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 时间滚动输出 level为 ERROR 日志 --&gt; &lt;appender name=\"file—error\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY &lt;/onMismatch&gt; &lt;/filter&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;FileNamePattern&gt;./logs/error.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date [%thread] %-5level %logger&#123;80&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;logger name=\"org.apache.ibatis\" level=\"INFO\"/&gt; &lt;logger name=\"java.sql.Connection\" level=\"debug\" /&gt; &lt;logger name=\"java.sql.Statement\" level=\"debug\" /&gt; &lt;logger name=\"java.sql.PreparedStatement\" level=\"debug\" /&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"stdout\" /&gt; &lt;appender-ref ref=\"file-info\" /&gt; &lt;/root&gt;&lt;/configuration&gt; 打包工程使用package命令给工程打包成jar包 1mvn package 此时会在target下生成一个jar包，启动即可： 1java -jar target\\testSpringBoot-0.0.1-SNAPSHOT.jar 输出如下： 123456789λ java -jar target\\testSpringBoot-0.0.1-SNAPSHOT.jar . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.5.9.RELEASE) 热部署在pom.xml中添加依赖 1234567891011121314151617181920212223&lt;dependencies&gt; &lt;!--devtools热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;scope&gt;true&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!--热部署配置--&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--fork:如果没有该项配置,整个devtools不会起作用--&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在application.yml中配置一下devtools 12345678spring: devtools: restart: enabled: true #设置开启热部署 additional-paths: src/main/java #重启目录 exclude: WEB-INF/** freemarker: cache: false #页面不加载缓存，修改即时生效 设置IDEA的自动编译： （1）File-Settings-Compiler勾选 Build Project automatically （2）快捷键 ctrl + shift + alt + /,选择Registry,勾上 Compiler autoMake allow when app running","categories":[{"name":"后端","slug":"后端","permalink":"https://yugd.cn/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"框架","slug":"框架","permalink":"https://yugd.cn/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"MySQL 存储过程","slug":"面试--Mysql存储过程","date":"2020-05-27T13:58:58.000Z","updated":"2022-01-07T18:58:19.621Z","comments":true,"path":"posts/13911/","link":"","permalink":"https://yugd.cn/posts/13911/","excerpt":"写在前面 什么是Mysql存储过程？ 存储过程是一组为了完成特定功能的 SQL 语句集合。MySQL 5.0 已经支持存储过程，它是数据库中最重要的功能。 本篇着重介绍一下 MySQL 创建存储过程：","text":"写在前面 什么是Mysql存储过程？ 存储过程是一组为了完成特定功能的 SQL 语句集合。MySQL 5.0 已经支持存储过程，它是数据库中最重要的功能。 本篇着重介绍一下 MySQL 创建存储过程： 目的将常用或复杂的工作预先用 SQL 语句写好并用一个指定名称存储起来，这个过程经编译和优化后存储在数据库服务器中，因此称为存储过程。 优点 封装性 存储过程被创建后，可以在程序中被多次调用，而不必重新编写该存储过程的 SQL 语句，并且数据库专业人员可以随时对存储过程进行修改，而不会影响到调用它的应用程序源代码。 可增强 SQL 语句的功能和灵活性 存储过程可以用流程控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。 可减少网络流量 由于存储过程是在服务器端运行的，且执行速度快，因此当客户计算机上调用该存储过程时，网络中传送的只是该调用语句，从而可降低网络负载。 高性能 存储过程执行一次后，产生的二进制代码就驻留在缓冲区，在以后的调用中，只需要从缓冲区中执行二进制代码即可，从而提高了系统的效率和性能。 提高数据库的安全性和数据的完整性 使用存储过程可以完成所有数据库操作，并且可以通过编程的方式控制数据库信息访问的权限。 缺点 如果使用大量存储过程，那么使用这些存储过程的每个连接的内存使用量将会大大增加。 存储过程的构造使得开发具有复杂业务逻辑的存储过程变得更加困难； 很难调试存储过程。只有少数数据库管理系统允许您调试存储过程。 开发和维护存储过程并不容易。 开发和维护存储过程通常需要一个不是所有应用程序开发人员拥有的专业技能。这可能会导致应用程序开发和维护阶段的问题。 创建存储过程声明语句结束符，可以自定义: 123DELIMITER $$或DELIMITER &#x2F;&#x2F; 声明存储过程: 1CREATE PROCEDURE demo_in_parameter(IN p_in int) 存储过程开始和结束符号: 1BEGIN .... END 变量赋值: 1SET @p_in&#x3D;1 变量定义: 1DECLARE l_int int unsigned default 100; 创建mysql存储过程、存储函数: 1create procedure 存储过程名(参数) 存储过程体: 1create function 存储函数名(参数) 举个荔枝： 123456789mysql&gt; delimiter $$ #将语句的结束符号从分号;临时改为两个$$(可以是自定义) mysql&gt; CREATE PROCEDURE &#96;mySun&#96;(IN &#96;salary&#96; INT ,OUT sum INT) -&gt; BEGIN -&gt; DECLARE a int unsigned default 10; -&gt; SET a &#x3D; 100; -&gt; SET sum &#x3D; Salary * a; -&gt; END$$ Query OK, 0 rows affected (0.01 sec) mysql&gt; delimiter; #将语句的结束符号恢复为分号 注意： 存储过程体 存储过程体包含了在过程调用时必须执行的语句，例如：dml、ddl语句，if-then-else和while-do语句、声明变量的declare语句等 过程体格式：以begin开始，以end结束(可嵌套) 每个嵌套块及其中的每条语句，必须以分号结束，表示过程体结束的begin-end块，则不需要分号。 存储过程的参数MySQL存储过程的参数用在存储过程的定义，共有三种参数类型,IN,OUT,INOUT,形式如： 1CREATEPROCEDURE 存储过程名([[IN |OUT |INOUT ] 参数名 数据类形...]) IN 输入参数：表示调用者向过程传入值（传入值可以是字面量或变量） OUT 输出参数：表示过程向调用者传出值(可以返回多个值)（传出值只能是变量） INOUT 输入输出参数：既表示调用者向过程传入值，又表示过程向调用者传出值（值只能是变量） 12345678CREATE DEFINER&#x3D;&#96;root&#96;@&#96;localhost&#96; PROCEDURE &#96;mysun&#96;(INOUT salary INT,INOUT sum INT)BEGIN DECLARE a int unsigned default 10; SELECT salary as &#39;计算前的数据&#39;; SET a &#x3D; 100; SET sum &#x3D; salary * a; SELECT sum as &#39;计算后的数据&#39;;END 变量变量定义1DECLAREvariable_name [,variable_name...] datatype [DEFAULT value]; declare用于声明变量； variable_name表示变量名称； datatype为 MySQL 的数据类型； default用于声明默认值; 举个荔枝: 1234567DECLARE l_int int unsigned default 100; DECLARE l_numeric number(8,2) DEFAULT 9.95; DECLARE l_date date DEFAULT &#39;1999-12-31&#39;; DECLARE l_datetime datetime DEFAULT &#39;1999-12-31 23:59:59&#39;; DECLARE l_varchar varchar(255) DEFAULT &#39;This will not be padded&#39;; 变量赋值1SET 变量名 &#x3D; 表达式值 [,variable_name &#x3D; expression ...] 举个荔枝: 1SET a &#x3D; 100; 注释两个横杆 –：该风格一般用于单行注释 控制语句if 条件语句IF 语句包含多个条件判断，根据结果为 TRUE、FALSE执行语句 定义存储过程，输入一个整数，使用 if 语句判断是正数还是负数 举个荔枝： 12345678910111213-- 创建过程create procedure mypro2(in num int)beginif num&lt;0 then -- 条件开始select &#39;负数&#39;;elseif num&#x3D;0 thenselect &#39;不是正数也不是负数&#39;;elseselect &#39;正数&#39;;end if;-- 条件结束end;-- 调用过程call mypro2(-1); case 条件语句case是另一个条件判断的语句 定义存储过程，输入一个整数，使用 case 语句判断是正数还是负数 举个荔枝： 1234567891011-- 创建过程create procedure mypro3(in num int)begincase -- 条件开始when num&lt;0 then select &#39;负数&#39;;when num&#x3D;0 then select &#39;不是正数也不是负数&#39;;else select &#39;正数&#39;;end case; -- 条件结束end;-- 调用过程call mypro3(1); while 循环语句while语句的用法和 java中的 while循环类似 定义存储过程，使用 while 循环输出 1 到 10 的累加和 举个荔枝： 1234567891011121314-- 创建过程create procedure mypro5(out sum int)begindeclare num int default 0;set sum &#x3D; 0;while num&lt;10 do -- 循环开始set num &#x3D; num+1;set sum &#x3D; sum+num;end while; -- 循环结束end;-- 调用过程call mypro5(@sum);-- 查询变量值select @sum; repeat 循环语句repeat语句的用法和 java中的 do…while 语句类似 定义存储过程，使用 repeat 循环输出 1 到 10 的累加和 举个荔枝： 123456789101112131415-- 创建过程create procedure mypro6(out sum int)begindeclare num int default 0;set sum &#x3D; 0;repeat-- 循环开始set num &#x3D; num+1;set sum &#x3D; sum+num;until num&gt;&#x3D;10end repeat; -- 循环结束end;-- 调用过程call mypro6(@sum);-- 查询变量值select @sum; loop 循环语句循环语句，用来重复执行某些语句 执行过程中可使用 leave语句或 iterate 跳出循环，也可以嵌套 IF等判断语句。 leave语句效果相当于 java 中的 break，用来终止循环； iterate语句效果相当于 java 中的 continue，用来结束本次循环操作，进入下一次循环。 定义存储过程，使用 loop 循环输出 1 到 10 的累加和 1234567891011121314151617-- 创建过程create procedure mypro7(out sum int)begindeclare num int default 0;set sum &#x3D; 0;loop_sum:loop-- 循环开始set num &#x3D; num+1;set sum &#x3D; sum+num;if num&gt;&#x3D;10 thenleave loop_sum;end if;end loop loop_sum; -- 循环结束end;-- 调用过程call mypro7(@sum);-- 查询变量值select @sum; 存储过程的管理显示存储过程 1SHOW PROCEDURE STATUS; 显示特定数据库的存储过程 1SHOW PROCEDURE status where db &#x3D; &#39;test&#39;; 显示特定模式的存储过程，要求显示名称中包含“my”的存储过程 1SHOW PROCEDURE status where name like &#39;%my%&#39;; 显示存储过程“mypro1”的源码 1SHOW CREATE PROCEDURE mypro1; 删除存储过程“mypro1” 1drop PROCEDURE mypro1;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://yugd.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yugd.cn/tags/MySQL/"}]},{"title":"JSON","slug":"学习--JSON","date":"2020-05-23T04:58:40.000Z","updated":"2021-10-26T14:26:00.120Z","comments":true,"path":"posts/3410/","link":"","permalink":"https://yugd.cn/posts/3410/","excerpt":"什么是 JSON？ JSON(JavaScript Object Notation, JS 对象标记) 是一种轻量级的数据交换格式，目前使用特别广泛。 采用完全独立于编程语言的文本格式来存储和表示数据。 对象表示为键值对，数据由逗号分隔 花括号保存对象 方括号保存数组 JSON 数据的书写格式是：名称/值对。 名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值： 123&#123;\"name\" : \"乔治\"&#125;&#123;\"age\": \"23\"&#125;&#123;\"sex\": \"男\"&#125;","text":"什么是 JSON？ JSON(JavaScript Object Notation, JS 对象标记) 是一种轻量级的数据交换格式，目前使用特别广泛。 采用完全独立于编程语言的文本格式来存储和表示数据。 对象表示为键值对，数据由逗号分隔 花括号保存对象 方括号保存数组 JSON 数据的书写格式是：名称/值对。 名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值： 123&#123;\"name\" : \"乔治\"&#125;&#123;\"age\": \"23\"&#125;&#123;\"sex\": \"男\"&#125; JSON 对象在大括号（{}）中书写： 对象可以包含多个名称/值对： 1&#123; \"name\":\"乔治\" , \"url\":\"www.pg.com\" &#125; JSON 数组JSON 数组在中括号中书写： 数组可包含多个对象： 1234567&#123; \"sites\": [ &#123; \"name\":\"乔治\" , \"url\":\"www.pg.com\" &#125;, &#123; \"name\":\"google\" , \"url\":\"www.google.com\" &#125;, &#123; \"name\":\"百度\" , \"url\":\"www.baidu.com\" &#125; ]&#125; JSON 布尔值JSON 布尔值可以是 true 或者 false： 1&#123; \"flag\":true &#125; JSON nullJSON 可以设置 null 值： 1&#123; \"name\":null &#125; JSON 和 JavaScript 对象互转 要实现从JSON字符串转换为JavaScript 对象，使用 JSON.parse() 方法： 12var obj = JSON.parse('&#123;\"a\": \"Hello\", \"b\": \"World\"&#125;'); //结果是 &#123;a: 'Hello', b: 'World'&#125; 要实现从JavaScript 对象转换为JSON字符串，使用 JSON.stringify() 方法： 12var json = JSON.stringify(&#123;a: 'Hello', b: 'World'&#125;);//结果是 '&#123;\"a\": \"Hello\", \"b\": \"World\"&#125;' fastjson （pom.xml）12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.60&lt;/version&gt;&lt;/dependency&gt; 乱码统一解决1234567891011121314&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters register-defaults=\"true\"&gt; &lt;bean class=\"org.springframework.http.converter.StringHttpMessageConverter\"&gt; &lt;constructor-arg value=\"UTF-8\"/&gt; &lt;/bean&gt; &lt;bean class=\"org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\"&gt; &lt;property name=\"objectMapper\"&gt; &lt;bean class=\"org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean\"&gt; &lt;property name=\"failOnEmptyBeans\" value=\"false\"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; *取消timestamps形式 ， 自定义时间格式 *(封装工具类)123456789101112131415161718192021222324252627282930package com.guo.utils;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.SerializationFeature;import java.text.SimpleDateFormat;public class JsonUtils &#123; public static String getJson(Object object) &#123; return getJson(object,\"yyyy-MM-dd HH:mm:ss\"); &#125; public static String getJson(Object object,String dateFormat) &#123; ObjectMapper mapper = new ObjectMapper(); //不使用时间戳的方式 mapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false); //自定义日期格式对象 SimpleDateFormat sdf = new SimpleDateFormat(dateFormat); //指定日期格式 mapper.setDateFormat(sdf); try &#123; return mapper.writeValueAsString(object); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 123456@RequestMapping(\"/json\")public String json() throws JsonProcessingException &#123; Date date = new Date(); String json = JsonUtils.getJson(date); return json;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"数据格式","slug":"数据格式","permalink":"https://yugd.cn/tags/%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/"}]},{"title":"AJAX 技术","slug":"学习--AJAX","date":"2020-05-23T04:57:30.000Z","updated":"2021-10-26T14:26:00.109Z","comments":true,"path":"posts/20484/","link":"","permalink":"https://yugd.cn/posts/20484/","excerpt":"AJAX 技术 AJAX = Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。 AJAX 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。 Ajax 不是一种新的编程语言，而是一种用于创建更好更快以及交互性更强的Web应用程序的技术。","text":"AJAX 技术 AJAX = Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。 AJAX 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。 Ajax 不是一种新的编程语言，而是一种用于创建更好更快以及交互性更强的Web应用程序的技术。 jQuery（AJAX） jQuery 不是生产者，而是大自然搬运工。 jQuery Ajax本质就是 XMLHttpRequest，对他进行了封装，方便调用！ 123456789101112131415161718192021jQuery.ajax(...) 部分参数： url：请求地址 type：请求方式，GET、POST（1.9.0之后用method） headers：请求头 data：要发送的数据 contentType：即将发送信息至服务器的内容编码类型(默认: \"application/x-www-form-urlencoded; charset=UTF-8\") async：是否异步 timeout：设置请求超时时间（毫秒） beforeSend：发送请求前执行的函数(全局) complete：完成之后执行的回调函数(全局) success：成功之后执行的回调函数(全局) error：失败之后执行的回调函数(全局) accepts：通过请求头发送给服务器，告诉服务器当前客户端课接受的数据类型 dataType：将服务器端返回的数据转换成指定类型 \"xml\": 将服务器端返回的内容转换成xml格式 \"text\": 将服务器端返回的内容转换成普通文本格式 \"html\": 将服务器端返回的内容转换成普通文本格式，在插入DOM中时，如果包含JavaScript标签，则 会尝试去执行。 \"script\": 尝试将返回值当作JavaScript去执行，然后再将服务器端返回的内容转换成普通文本格式 \"json\": 将服务器端返回的内容转换成相应的JavaScript对象 \"jsonp\": JSONP 格式使用 JSONP 形式调用函数时，如 \"myurl?callback=?\" jQuery 将自动替换 为正确的函数名，以执行回调函数 1、配置web.xml 和 springmvc的配置文件 123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!-- 自动扫描指定的包，下面所有注解类交给IOC容器管理 --&gt; &lt;context:component-scan base-package=\"com.guo.controller\"/&gt; &lt;mvc:default-servlet-handler /&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- 视图解析器 --&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" id=\"internalResourceViewResolver\"&gt; &lt;!-- 前缀 --&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\" /&gt; &lt;!-- 后缀 --&gt; &lt;property name=\"suffix\" value=\".jsp\" /&gt; &lt;/bean&gt;&lt;/beans&gt; 2、导入jquery ， 可以使用在线的CDN ， 也可以下载导入 12345&lt;!-- 在线的CDN --&gt;&lt;script src=\"https://code.jquery.com/jquery-3.1.1.min.js\"&gt;&lt;/script&gt;&lt;!-- 下载导入 --&gt;&lt;script src=\"$&#123;pageContext.request.contextPath&#125;/statics/js/jquery-3.1.1.min.js\"&gt;&lt;/script&gt; 3、jQuery ajax 123456789101112131415&lt;script src=\"$&#123;pageContext.request.contextPath&#125;/statics/js/jquery-3.1.1.min.js\"&gt;&lt;/script&gt;&lt;script&gt; function method()&#123; $.post(&#123; url:\"$&#123;pageContext.request.contextPath&#125;/methods\", type:\"POST\", dataType: \"json\", contentType:\"application/json;charset=UTF-8\", data:&#123;'name':$(\"#name\").val()&#125;, success:function (data) &#123; console.log('success') &#125; &#125;); &#125;&lt;/script&gt; 12345678910@Controllerpublic class AjaxController &#123; @responseBody @RequestMapping(\"/methods\", method = RequestMethod.POST) public Map&lt;String, String&gt; ajax1(String name)&#123; Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(\"info\", name); return map; &#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://yugd.cn/tags/Web/"}]},{"title":"MySQL(语句)","slug":"学习--MySQL-2","date":"2020-05-23T04:53:38.000Z","updated":"2021-10-26T14:26:00.125Z","comments":true,"path":"posts/45802/","link":"","permalink":"https://yugd.cn/posts/45802/","excerpt":"select 完整语句12345678910111213写的顺序: select ... from... where.... group by... having... order by.. 执行顺序: from... where... group by... having.... select ... order by...","text":"select 完整语句12345678910111213写的顺序: select ... from... where.... group by... having... order by.. 执行顺序: from... where... group by... having.... select ... order by... 组函数常用的组函数 AVG COUNT MAX MIN SUM 组函数的语法:（Group By） 12345SELECT [column,]group_function(column),...FORM table[WHERE condition][GROUP BY column][ORDER BY column] 注意: 组函数不能在WHERE子句中使用 在组函数中可以使用 Distinct 关键字用于去重 过滤分组：HAVING 子句 使用 HAVING 过滤分组 1、行已使用被分组 2、使用了组函数 3、满足 HAVING 子句中条件的分组将被显示 123456SELECT [column,]group_function(column),...FORM table[WHERE condition][GROUP BY group_by_expression][HAVING group_condition][ORDER BY column]; 注意: 组函数不能嵌套使用 子查询 为了给主要查询提供数据而先执行的查询称之为子查询 子查询要包含在括号内 将子查询放在比较条件的右侧 单行子查询 = / &gt; / &gt;= / &lt; / &lt;= / &lt;&gt; / != 多行子查询 IN / ANY /ALL 事务4个特性 A 原子性：事务必须是一个自动工作的单元，要么全部执行，要么全部不执行。 C 一致性：事务把数据库从一个一致状态带入到另一个一致状态，事务结束的时候，所有的内部数据都是正确的。 I 隔离性：并发多个事务时，一个事务的执行不受其他事务的影响。 D 持久性：事务提交之后，数据是永久性的，不可再回滚，不受关机等事件的影响。 事务在如下情况终止： 遇到rollback 或commit命令 遇到DDL或者DCL语句. 系统发生错误，崩溃或者退出。 序列的使用 MySQL 序列是以升序生成的一组整数：1，2，3，…，宇宇生成主要识别的唯一数字，即主键。 可以在列上设置AUTO_INCREMENT属性，这通常是主键列。 UUID UUID代表通用唯一表示符。UUID是基于 “RFC 4122” 通用唯一标识符定义的。 UUID被设计为在空间和时间全球独一无二的数组。预期两个UUID值是不同的。 在MySQL中，UUID值是一个128位的数字，表示为以下格式的十五进制数字的utf-8字符串： 1aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee 要生成UUID值，需要使用 UUID() 函数 1UUID() 注意: 如果是有效的字符串格式UUID，IS_UUID()函数将返回 1 。如果参数不是有效的字符串格式UUID，则IS_UUID函数返回 0，如果参数为 NULL ，则IS_UUID() 函数返回 NULL。 12SELECT BIN_TO_UUID(id) id, nameFROM customers; SQL 约束 NOT NULL =&gt; 约束强制列不接受 NULL 值 UNIQUE =&gt; 约束唯一标识数据库表中的每条记录 PRIMARY KEY =&gt; 约束唯一标识数据库表中的每条记录(主键必须包含唯一的值、主键列不能包含 NULL 值) FOREIGN KEY =&gt; 一个表中的 FOREIGN KEY 指向另一个表中的 PRIMARY KEY CHECK =&gt; CHECK 约束用于限制列中的值的范围 DEFAULT =&gt; DEFAULT 约束用于向列中插入默认值（如果没有规定其他的值，那么会将默认值添加到所有的新记录） 客户端连接设置字符集 MySQL连接器允许设置字符集： 1jdbc:mysql://127.0.0.1:3306/?characterEncoding=utf-8&amp;useSSL=true 复制表结构 12345CREATE TABLE dept_copyASSELECT *FROM departmentWHERE 1=0;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://yugd.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yugd.cn/tags/MySQL/"}]},{"title":"MySQL(初识MySQL)","slug":"学习--MySQL-1","date":"2020-05-23T04:53:32.000Z","updated":"2021-12-12T18:09:30.893Z","comments":true,"path":"posts/6154/","link":"","permalink":"https://yugd.cn/posts/6154/","excerpt":"什么是数据库数据库 （DB， DataBase） 数据库分类关系型数据库:(SQL) MySQL，Oracle，DB2 通过表和表之间，行和行之间的关系进行数据存储 非关系型数据库:(NoSQL) Redis，MongoDB 菲关系型数据库，对象存储，通过对象的自身属性来决定 DBMS（数据库管理系统） 数据库管理软件","text":"什么是数据库数据库 （DB， DataBase） 数据库分类关系型数据库:(SQL) MySQL，Oracle，DB2 通过表和表之间，行和行之间的关系进行数据存储 非关系型数据库:(NoSQL) Redis，MongoDB 菲关系型数据库，对象存储，通过对象的自身属性来决定 DBMS（数据库管理系统） 数据库管理软件 操作数据库MySQL 数据量不区分大小写 1、创建数据库 1CREATE DATABASE 数据库名; 2、删除数据库 1DROP DATABASE &lt;数据库名&gt;; 3、查看数据库 1SHOW DATABASE; --查看所有数据库 4、选择数据库 1USE 数据库名; 数据库列的类型 数值 （常用） 1int 标准的整数 4个字节 字符串 （常用） 12char 字符串固定大小 0~255varchar 可变字符串 0~65535 常用变量String 日期 （常用） java.utile.Date 123date YYYY-MM-DD 日期time HH:mm:ss 时间格式datetime YYYY-MM-DD HH:mm:ss 最常用的时间格式 null 字段属性Unsigned 12无符号的整数声明该列不能声明为负数 zerofill 120填充的不足的位数用0来填充 int(3) 005 自增 12自增，+1（默认）可以自定义设计主键的起始值和步长 NULL not null 12如果不给他赋值，就会报错！sex，默认值为如果不指定其列值，则会有默认值！ 1、创建数据库表 1CREATE TABLE table_name (column_name column_type); 2、删除数据库表 1DROP TABLE table_name ; 3、查看数据库表 1SHOW TABLES; 索引索引的类型 1、普通索引 创建索引 这是最基本的索引，它没有任何限制 1CREATE INDEX indexName ON table_name (column_name) 修改表结构(添加索引) 1ALTER table tableName ADD INDEX indexName(columnName) 创建表的时候直接指定 123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, INDEX [indexName] (username(length)) ); 删除索引的语法 1DROP INDEX [indexName] ON mytable; 2、唯一索引 它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。 创建索引 1CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构 1ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定 123456789CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, UNIQUE [indexName] (username(length)) ); 数据库关联外键 123为表添加外键的语法：alter table 表名 add constraint 外键名称 foreign key (外键字段名称) references 外表表名(主键字段名称) 删除有外键的表的时候，必须要先删除从表，再删除主表 增删改查1、插入数据 12INSERT INTO table_name ( field1, field2,...fieldN )VALUES ( value1, value2,...valueN ) 2、删除数据 123DELETE FROM table_name [WHERE Clause] 3、更新数据 123UPDATE table_name SET field1=new-value1, field2=new-value2[WHERE Clause] 4、查询数据 123SELECT column_name,column_nameFROM table_name[WHERE Clause] 查询 - 别名 =&gt; AS 12SELECT COUNT('姓名:',name) AS 别名FROM table_name 注意: 如果数据是字符型或者日期，必须使用单引号或者双引号 去重 12SELECT DISTINCT nameFROM table_name Like子句 123SELECT field1, field2,...fieldN FROM table_nameWHERE field1 LIKE 'value1' [AND/ OR] filed2 = 'value2' MySQL 排序 123SELECT field1, field2,...fieldN FROM table_name1, table_name2...ORDER BY field1 [ASC /DESC] =&gt;[默认 ASC] GROUP BY 语法 1234SELECT column_name, function(column_name)FROM table_nameWHERE column_name operator valueGROUP BY column_name; MySQL WHERE 子句 操作符 描述 实例 = 等号，检测两个值是否相等，如果相等返回true (A = B) 返回false。 &lt;&gt;, != 不等于，检测两个值是否相等，如果不相等返回true (A != B) 返回 true。 &gt; 大于号，检测左边的值是否大于右边的值, 如果左边的值大于右边的值返回true (A &gt; B) 返回false。 &lt; 小于号，检测左边的值是否小于右边的值, 如果左边的值小于右边的值返回true (A &lt; B) 返回 true。 &gt;= 大于等于号，检测左边的值是否大于或等于右边的值, 如果左边的值大于或等于右边的值返回true (A &gt;= B) 返回false。 &lt;= 小于等于号，检测左边的值是否小于或等于右边的值, 如果左边的值小于或等于右边的值返回true (A &lt;= B) 返回 true。 分页和排序排序 ： 升序 ASC 降序DESC 1--ORDER BY 分页 1234--分页，每页显示的数据（几条）--语法: limit 当前页，页面大小LIMIT 1,5 1:起始 5:条数 语法: limit（查询起始下标，pageSize）","categories":[{"name":"数据库","slug":"数据库","permalink":"https://yugd.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yugd.cn/tags/MySQL/"}]},{"title":"JQuery","slug":"学习--jQuery","date":"2020-05-23T04:51:36.000Z","updated":"2022-05-26T18:19:13.000Z","comments":true,"path":"posts/63260/","link":"","permalink":"https://yugd.cn/posts/63260/","excerpt":"jQuery API (哪里不会点哪里) jQuery 库 CDN加速1&lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.js\"&gt;&lt;/script&gt; 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/core.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;","text":"jQuery API (哪里不会点哪里) jQuery 库 CDN加速1&lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.js\"&gt;&lt;/script&gt; 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/core.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 选择器12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;a href=\"\" id=\"test-jquery\"&gt;点击&lt;/a&gt;&lt;script&gt; //选择器就是 CSS 选择器 $('#test-jquery').click(function () &#123; alert('点击'); &#125;)&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 公式：$(selector).action() 123$('p').click(); //标签选择器$('#id').click(); //Id选择器$('.class').click(); //类选择器 鼠标事件 123456//当网页加载完毕之后，响应事件&lt;script&gt; $(function()&#123;&#125;);&lt;/script&gt; 操作DOM1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;ul id=\"test-ul\"&gt; &lt;li class=\"javascript\"&gt;javascript&lt;/li&gt; &lt;li name=\"python\"&gt;python&lt;/li&gt;&lt;/ul&gt;&lt;script&gt; $('#test-ul li[name = python]').text(); $('#test-ul').html(); console.log($('#test-ul li[name = python]').text()); console.log($('#test-ul').html());&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 节点文本操作1234$('#test-ul li[name = python]').text(); //获得值$('#test-ul li[name = python]').text('设置值'); //设置值$('#test-ul').html(); //获得值$('#test-ul').html('&lt;text&gt;123&lt;/text&gt;'); //设置值 结果 元素的显示与隐藏12$('#test-ul li[name = python]').show()$('#test-ul li[name = python]').hide() 使用 attr()123456//attr() 方法设置或返回被选元素的属性值$(selector).attr(attribute)//设置被选元素的属性和值 $(selector).attr(attribute,value)//设置被选元素的属性和值$(selector).attr(attribute,function(index,oldvalue)) 使用 change()123456#当元素的值改变时发生 change 事件（仅适用于表单字段）#change() 方法触发 change 事件，或规定当发生 change 事件时运行的函数#注意：当用于 select 元素时，change 事件会在选择某个选项时发生。当用于 text field 或 text area 时，#change 事件会在元素失去焦点时发生触发被选元素的 change 事件：$(selector).change() 点击 触发 事件 的 jQuery 写法样式 (Thymeleaf) on注册简单事件 123456// 表示给$(selector)绑定事件，并且由自己触发，不支持动态绑定。$(selector).on( 'click', function() &#123;&#125;);or$(selector).onclick(function() &#123;&#125;); on注册事件委托 12// 表示给$(selector)绑定代理事件，支持动态绑定$(document).on('click', '#id', function ()&#123;...&#125;); on注册事件的语法： 12345// 第一个参数：events，绑定事件的名称可以是由空格分隔的多个事件（标准事件或者自定义事件）// 第二个参数：selector, 执行事件的后代元素（可选），如果没有后代元素，那么事件将由自己执行。// 第三个参数：data，传递给处理函数的数据，事件触发的时候通过event.data来使用（不常使用）// 第四个参数：handler，事件处理函数$(selector).on(events[,selector][,data],handler); return false : 既能阻止事件冒泡，又能阻止浏览器默认行为。","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"脚本语言","slug":"脚本语言","permalink":"https://yugd.cn/tags/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"}]},{"title":"JavaScript(3)","slug":"学习--JavaScript-3","date":"2020-05-23T04:26:38.000Z","updated":"2021-10-26T14:26:00.123Z","comments":true,"path":"posts/22151/","link":"","permalink":"https://yugd.cn/posts/22151/","excerpt":"操作BOM对象location 代表当前页面的URL信息12document.write(location.href);chrome-extension://nnnkddnnlpamobajfibfdgfnbcnkgngh/pages/newtab.html","text":"操作BOM对象location 代表当前页面的URL信息12document.write(location.href);chrome-extension://nnnkddnnlpamobajfibfdgfnbcnkgngh/pages/newtab.html Window 对象123window.document.getElementById(\"header\");与此相同：document.getElementById(\"header\"); document()12345document.title\"百度一下，你就知道\"document.cookie\"BIDUPSID=B5A33A7723E31891D11081193B8BAD69; PSTM=1575547435; BD_UPN=12314753; sug=3; sugstore=0; ORIGIN=0; bdime=0; BAIDUID=B5A33A7723E31891C98C04C5D2C415D3:SL=0:NR=10:FG=1; BDORZ=FFFB88E999055A3F8A630C64834BD6D0; H_PS_PSSID=; BDRCVFR[BCzcNGRrF63]=mk3SLVN4HKm; delPer=0; BD_HOME=0; BD_CK_SAM=1; PSINO=7; H_PS_645EC=68ebIOGcQ%2F4HK5HwBH8P8L%2FiK8ixVLlPeV17sV9O3KKNDcFLWxrGpER1wrknAgyiyOwPI2U\" Window History12history.back() - 与在浏览器点击后退按钮相同history.forward() - 与在浏览器中点击向前按钮相同 操作BOM对象() 更新DOM节点 12345678910&lt;h1&gt;first&lt;/h1&gt;&lt;p id=\"p1\"&gt;p1&lt;/p&gt;&lt;p class=\"p2\"&gt;p2&lt;/p&gt; &lt;script&gt; var h1 = document.getElementsByTagName(\"h1\"); var p1 = document.getElementById(\"p1\"); var p2 = document.getElementsByClassName(\"p2\"); document.getElementById(\"p1\").innerHTML=\"新文本!\";&lt;/script&gt; 遍历DOM节点 12 删除DOM节点 12345678&lt;div id=\"father\"&gt; &lt;h1&gt;first&lt;/h1&gt; &lt;p id=\"p1\"&gt;p1&lt;/p&gt; &lt;p class=\"p2\"&gt;p2&lt;/p&gt;&lt;/div&gt;var father = document.getElementById(\"father\");father.removeChild(p1) 添加DOM节点 获得了DOM节点，假设dom节点是空的，我们可以通过innerHTML来增加一个元素，但是此DOM节点已经存在元素，我们就不能够这样做！ 操作表单123456789101.用document.getElementById(\"id名\").value来获取2.通过form表单中的id名或者name名来获取是否选中:&lt;input type=\"checkbox\" name=\"box\"&gt; var check = document.getElementsByTagName('input')[0];console.log(check.checked);//false MD5 加密1234567891011121314151617&lt;!-- MD5工具类 --&gt;&lt;script src=\"http://cdn.bootcss.com/blueimp-md5/1.1.0/js/md5.min.js\"&gt;&lt;/script&gt;用户名：&lt;input type=\"text\" name=\"username\" id=\"username\" /&gt;密码：&lt;input type=\"password\" name=\"password\" id=\"password\" /&gt;&lt;button type=\"submit\" onclick=\"submit()\" &gt;提交&lt;/button&gt;&lt;script&gt; function submit() &#123; var username = document.getElementById(\"username\"); var password = document.getElementById(\"password\"); console.log(username.value); //MD5 加密算法 password.value = md5(password.value); console.log(password.value) &#125;&lt;/script&gt; 定时器 12345678910111213141516171819202122232425262728293031setTimeout():方法用于在指定的毫秒数后调用函数或计算表达式。//只执行 code 一次setInterval():方法可按照指定的周期（以毫秒计）来调用函数或计算表达式。eg:&lt;script&gt; var myVar; function myFunction() &#123; myVar = setTimeout(alertFunc, 3000); &#125; function alertFunc() &#123; alert(\"Hello!\"); &#125;&lt;/script&gt;&lt;script&gt; var myVar; function myFunction() &#123; myVar = setInterval(alertFunc, 3000); &#125; function alertFunc() &#123; alert(\"Hello!\"); &#125;&lt;/script&gt;setTimeout用于延迟执行某方法或功能setInterval则一般用于刷新表单，对于一些表单的假实时指定时间刷新同步","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"脚本语言","slug":"脚本语言","permalink":"https://yugd.cn/tags/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"}]},{"title":"JavaScript(2)","slug":"学习--JavaScript-2","date":"2020-05-23T04:25:46.000Z","updated":"2021-10-26T14:26:00.122Z","comments":true,"path":"posts/50822/","link":"","permalink":"https://yugd.cn/posts/50822/","excerpt":"对象1、对象赋值1234person.name = \"gyh\"\"gyh\"person.name\"gyh\"","text":"对象1、对象赋值1234person.name = \"gyh\"\"gyh\"person.name\"gyh\" 2、使用一个不存在的对象属性，不会报错（undefined）12person.hahaundefined 3、动态的删减属性，通过delete删除对象的属性12delete person.name true JavaScript 循环123456789101112for (i = 0; i &lt; cars.length; i++) &#123; text += cars[i] + \"&lt;br&gt;\"; &#125;等价于text += cars[0] + \"&lt;br&gt;\"; text += cars[1] + \"&lt;br&gt;\"; text += cars[2] + \"&lt;br&gt;\"; text += cars[3] + \"&lt;br&gt;\"; text += cars[4] + \"&lt;br&gt;\"; text += cars[5] + \"&lt;br&gt;\"; for 循环for 循环的语法如下：123for (语句 1; 语句 2; 语句 3) &#123; 要执行的代码块&#125; for in 循环JavaScript for/in 语句遍历对象的属性：1234567var person &#x3D; &#123;fname:&quot;Bill&quot;, lname:&quot;Gates&quot;, age:62&#125;; var text &#x3D; &quot;&quot;;var x;for (x in person) &#123; text +&#x3D; person[x];&#125; DateDate 对象方法 方法 描述 Date() 返回当日的日期和时间。 getDate() 从 Date 对象返回一个月中的某一天 (1 ~ 31)。 getDay() 从 Date 对象返回一周中的某一天 (0 ~ 6)。 getMonth() 从 Date 对象返回月份 (0 ~ 11)。 getFullYear() 从 Date 对象以四位数字返回年份。 getTime() 返回 1970 年 1 月 1 日至今的毫秒数。 javascript Date format(js日期格式化)123456789101112131415161718192021222324// 对Date的扩展，将 Date 转化为指定格式的String // 月(M)、日(d)、小时(H)、分(m)、秒(s)、季度(q) 可以用 1-2 个占位符， // 年(y)可以用 1-4 个占位符，毫秒(S)只能用 1 个占位符(是 1-3 位的数字) // 例子： // (new Date()).Format(\"yyyy-MM-dd HH:mm:ss.S\") ==&gt; 2006-07-02 08:09:04.423 // (new Date()).Format(\"yyyy-M-d H:m:s.S\") ==&gt; 2006-7-2 8:9:4.18 Date.prototype.Format = function(fmt) &#123; //author: meizz var o = &#123; \"M+\" : this.getMonth()+1, //月份 \"d+\" : this.getDate(), //日 \"h+\" : this.getHours(), //小时 \"m+\" : this.getMinutes(), //分 \"s+\" : this.getSeconds(), //秒 \"q+\" : Math.floor((this.getMonth()+3)/3), //季度 \"S\" : this.getMilliseconds() //毫秒 &#125;; if(/(y+)/.test(fmt)) fmt=fmt.replace(RegExp.$1, (this.getFullYear()+\"\").substr(4 - RegExp.$1.length)); for(var k in o) if(new RegExp(\"(\"+ k +\")\").test(fmt)) fmt = fmt.replace(RegExp.$1, (RegExp.$1.length==1) ? (o[k]) : ((\"00\"+ o[k]).substr((\"\"+ o[k]).length))); return fmt; &#125; 调用方法： 123var time1 &#x3D; new Date().format(&quot;yyyy-MM-dd HH:mm:ss&quot;); var time2 &#x3D; new Date().format(&quot;yyyy-MM-dd&quot;); 1234now = new Date(XXXXXXXXX)now.toLocaleStringnow.toLocaleString()\"2020/2/18 上午10:49:35\" JSONjson.stringify() JSON.stringify()的作用是将 JavaScript 对象转换为 JSON 字符串，而JSON.parse()可以将JSON字符串转为一个对象。 我用 JSON.stringify() 将对象 a 变成了字符串 c ，那么我就可以用 JSON.parse() 将字符串 c 还原成对象 a。 1234567891011let arr = [1,2,3];JSON.stringify(arr); //'[1,2,3]' =&gt; 将对象 arr 变成了字符串 arr。typeof JSON.stringify(arr); //string =&gt; 输出类型let string = '[1,2,3]';console.log(JSON.parse(string)) //[1,2,3] =&gt; (3) [1, 2, 3] 0: 1 1: 2 2: 3console.log(typeof JSON.parse(string)) //object 在使用 JSON.parse() 需要注意一点，由于此方法是将JSON字符串转换成对象，所以你的字符串必须符合JSON格式，即键值都必须使用双引号包裹： 1234let a = '[\"1\",\"2\"]';let b = \"['1','2']\";console.log(JSON.parse(a));// Array [1,2]console.log(JSON.parse(b));// 报错 JSON.stringify()的几种妙用 1.判断数组是否包含某对象，或者判断对象是否相等。 12345678910111213//判断数组是否包含某对象let data = [ &#123;name:'echo'&#125;, &#123;name:'听风是风'&#125;, &#123;name:'天子笑'&#125;, ], val = &#123;name:'天子笑'&#125;;JSON.stringify(data).indexOf(JSON.stringify(val)) !== -1;//true//判断两数组/对象是否相等let a = [1,2,3], b = [1,2,3];JSON.stringify(a) === JSON.stringify(b);//true 2.让localStorage/sessionStorage可以存储对象。 123456789101112//存function setLocalStorage(key,val)&#123; window.localStorage.setItem(key,JSON.stringify(val));&#125;;//取function getLocalStorage(key)&#123; let val = JSON.parse(window.localStorage.getItem(key)); return val;&#125;;//测试setLocalStorage('demo',[1,2,3]);let a = getLocalStorage('demo');//[1,2,3] 3、JSON.stringify()与toString()的区别 这两者虽然都可以将目标值转为字符串，但本质上还是有区别的，比如 123let arr &#x3D; [1,2,3];JSON.stringify(arr);&#x2F;&#x2F;&#39;[1,2,3]&#39;arr.toString();&#x2F;&#x2F;1,2,3","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"脚本语言","slug":"脚本语言","permalink":"https://yugd.cn/tags/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"}]},{"title":"JavaScript(1)","slug":"学习--JavaScript-1","date":"2020-05-23T04:24:34.000Z","updated":"2021-10-26T14:26:00.121Z","comments":true,"path":"posts/13958/","link":"","permalink":"https://yugd.cn/posts/13958/","excerpt":"数据类型数值、文本、图形、音频、视频…1js不区分小数和整数 number 字符串1'a' 、\"a\"","text":"数据类型数值、文本、图形、音频、视频…1js不区分小数和整数 number 字符串1'a' 、\"a\" 布尔1true 、 false 逻辑运算123&amp;&amp; 都真为真|| 一个为真，结果为真! 真即假，假即真 比较123=== 等于(类型不同，值相同，结果判断为true)=== 绝对等于(类型相同，值相同，结果判断为true) 最好使用=== 1注意: NaN === NaN ,这个值与所有的值都不相等，包括自己 数组Java的数组中类型必须相同类型的对象，JS中不需要这样123var arr = [1,2,3,4,5,'hello word',null,true];new Arry(1,2,3,4,5,'hello word',null,true); 如果数组下标越界，显示 undefined 对象1对象是大括号，数组是中括号，最后一个不需要添加 取对象值1链式取值，通过对象·的方式 变量123var 全局变量let 局部变量 数据1、多行编写1234var msg = `hello word !` 2、字符串长度1str.length 3、substring123[) str.substring(1) //从第一个字符截取到最后一个字符 str.substring(1,3) //[1,3]) 数组Array可以包含任意类型的数据类型1var arr = [1,2,3,4,5] 1、长度1arr.length 注意：加入给 arr.length 赋值，数组大小会发生变化，如果数值小于元素个数，元素就会丢失 2、indexOf，通过元素下标获得索引12arr.indexOf(2)字符串 \"1\" 和数字 1 是不同的 3、slice() 截取Array的一部分，功能强大的方法，返回一个新的数字4、push() ，shift() 头部12unshift: 压入头部shift: 弹出头部的一个元素 5、排序 sort()123[\"B\",\"C\",\"A\"]arr.sort()[\"A\",\"B\",\"C\"] 6、元素反转 reverse()123[\"A\",\"B\",\"C\"]arr.reverse()[\"C\",\"B\",\"A\"] 7、concat()1234[\"A\",\"B\",\"C\"]arr.concat([1,2,3])[\"A\",\"B\",\"C\",1,2,3]注意: concat()并没有修改数据，只是返回一个新的数组 8、join()123[\"A\",\"B\",\"C\"]arr.join('-')\"A-B-C\"","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"脚本语言","slug":"脚本语言","permalink":"https://yugd.cn/tags/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"}]},{"title":"CSS","slug":"学习--CSS","date":"2020-05-23T04:23:21.000Z","updated":"2021-10-26T14:26:00.117Z","comments":true,"path":"posts/6541/","link":"","permalink":"https://yugd.cn/posts/6541/","excerpt":"css引入样式1.内联 1.内联1&lt;h1 style=\"color: red\"&gt;我是标题&lt;/h1&gt; 2.内部 12345&lt;style&gt; h1&#123; color: green; &#125;&lt;/style&gt;","text":"css引入样式1.内联 1.内联1&lt;h1 style=\"color: red\"&gt;我是标题&lt;/h1&gt; 2.内部 12345&lt;style&gt; h1&#123; color: green; &#125;&lt;/style&gt; 3.外联 1234567891011h1&#123; color: yellow;&#125;&lt;!-- 链接式 --&gt;&lt;link rel=\"stylesheet\" href=\"css/style.css\"&gt;&lt;!-- 导入式 --&gt;&lt;style&gt; @import url(\"css/style.css\");&lt;/style&gt; 优先级：行内样式&gt;内部样式&gt;外部样式 选择器类选择器：class=” “ Id选择器： id=” “ 全局唯一 标签选择器：a{} 优先级： id&gt;class&gt;标签 选择器1234567891011121314151617181920/*类选择器*//* 属性名 = 属性值 =绝对等于 *=包含 ^=以这个开头 $=以这个结尾*//*class中有item的元素*/a[class=\"item\"]&#123; background: antiquewhite;&#125;/*选中href中以www开头的元素*/a[href^=www]&#123; background: antiquewhite;&#125;&lt;a href=\"www.baidu.com\" class=\"item\"&gt;超链接&lt;/a&gt; CSS字体属性 Property 描述 font 在一个声明中设置所有的字体属性 font-family 指定文本的字体系列 font-size 指定文本的字体大小 font-style 指定文本的字体样式 font-variant 以小型大写字体或者正常字体显示文本。 font-weight 指定字体的粗细。 CSS伪类选择器 : 伪类名 { 属性 : 属性值 }123456789101112&lt;style type=\"text/css\"&gt; /*取消超链接下划线*/ a &#123; text-decoration:none;&#125; /*超链接样式*/ a:link &#123; color: blue;&#125; /*点击过的样式*/ a:visited &#123; color: purple;&#125; /*悬停时的样式*/ a:hover &#123; color: red;&#125; /*点击时的样式*/ a:active &#123; color: yellow;&#125;&lt;/style&gt; 12345&lt;a&gt;没有href的a标签,字体没有修饰，鼠标放上去也没反应&lt;/a&gt; &lt;/br&gt;&lt;a href=\"#\" target=\"_blank\"&gt; href为#的a标签，默认蓝色，带下划线，鼠标放上去变成手 &lt;/a&gt; &lt;/br&gt;&lt;a href=\"http://www.a.com\" target=\"_blank\" &gt;href为网址的a标签，效果同上&lt;/a&gt; 字体12345/*悬停时的样式*/a:hover &#123; color: red; font-size: 20px;&#125; 透明度1234567img&#123; opacity:0.4; /* filter:alpha(opacity=40); */ /* IE8 及其更早版本 */&#125; Opacity属性值从0.0 - 1.0。值越小，使得元素更加透明。","categories":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://yugd.cn/tags/Web/"}]},{"title":"Example","slug":"实践--Example mybatis","date":"2020-05-23T04:23:21.000Z","updated":"2021-10-26T14:26:00.133Z","comments":true,"path":"posts/10323/","link":"","permalink":"https://yugd.cn/posts/10323/","excerpt":"一、mapper接口中的方法解析mapper接口中的函数及方法 123456789101112 方法 功能说明int countByExample(UserExample example) thorws SQLException 按条件计数int deleteByPrimaryKey(Integer id) thorws SQLException 按主键删除int deleteByExample(UserExample example) thorws SQLException 按条件查询String&#x2F;Integer insert(User record) thorws SQLException 插入数据（返回值为ID）User selectByPrimaryKey(Integer id) thorws SQLException 按主键查询ListselectByExample(UserExample example) thorws SQLException 按条件查询ListselectByExampleWithBLOGs(UserExample example) thorws SQLException 按条件查询（包括BLOB字段）。int updateByPrimaryKey(User record) thorws SQLException 按主键更新int updateByPrimaryKeySelective(User record) thorws SQLException 按主键更新值不为null的字段int updateByExample(User record, UserExample example) thorws SQLException 按条件更新int updateByExampleSelective(User record, UserExample example) thorws SQLException 按条件更新值不为null的字段","text":"一、mapper接口中的方法解析mapper接口中的函数及方法 123456789101112 方法 功能说明int countByExample(UserExample example) thorws SQLException 按条件计数int deleteByPrimaryKey(Integer id) thorws SQLException 按主键删除int deleteByExample(UserExample example) thorws SQLException 按条件查询String&#x2F;Integer insert(User record) thorws SQLException 插入数据（返回值为ID）User selectByPrimaryKey(Integer id) thorws SQLException 按主键查询ListselectByExample(UserExample example) thorws SQLException 按条件查询ListselectByExampleWithBLOGs(UserExample example) thorws SQLException 按条件查询（包括BLOB字段）。int updateByPrimaryKey(User record) thorws SQLException 按主键更新int updateByPrimaryKeySelective(User record) thorws SQLException 按主键更新值不为null的字段int updateByExample(User record, UserExample example) thorws SQLException 按条件更新int updateByExampleSelective(User record, UserExample example) thorws SQLException 按条件更新值不为null的字段 二、example实例解析mybatis的逆向工程中会生成实例及实例对应的example，example用于添加条件，相当where后面的部分xxxExample example = new xxxExample();Criteria criteria = new Example().createCriteria(); 1234567891011121314151617 方法 说明example.setOrderByClause(“字段名 ASC”); 添加升序排列条件，DESC为降序example.setDistinct(false) 去除重复，boolean型，true为选择不重复的记录。criteria.andXxxIsNull 添加字段xxx为null的条件criteria.andXxxIsNotNull 添加字段xxx不为null的条件criteria.andXxxEqualTo(value) 添加xxx字段等于value条件criteria.andXxxNotEqualTo(value) 添加xxx字段不等于value条件criteria.andXxxGreaterThan(value) 添加xxx字段大于value条件criteria.andXxxGreaterThanOrEqualTo(value) 添加xxx字段大于等于value条件criteria.andXxxLessThan(value) 添加xxx字段小于value条件criteria.andXxxLessThanOrEqualTo(value) 添加xxx字段小于等于value条件criteria.andXxxIn(List&lt;？&gt;) 添加xxx字段值在List&lt;？&gt;条件criteria.andXxxNotIn(List&lt;？&gt;) 添加xxx字段值不在List&lt;？&gt;条件criteria.andXxxLike(“%”+value+”%”) 添加xxx字段值为value的模糊查询条件criteria.andXxxNotLike(“%”+value+”%”) 添加xxx字段值不为value的模糊查询条件criteria.andXxxBetween(value1,value2) 添加xxx字段值在value1和value2之间条件criteria.andXxxNotBetween(value1,value2) 添加xxx字段值不在value1和value2之间条件 1.查询 ① selectByPrimaryKey() User user = XxxMapper.selectByPrimaryKey(100); //相当于select * from user where id = 100 ② selectByExample() 和 selectByExampleWithBLOGs() 1234567UserExample example &#x3D; new UserExample();Criteria criteria &#x3D; example.createCriteria();criteria.andUsernameEqualTo(&quot;wyw&quot;);criteria.andUsernameIsNull();example.setOrderByClause(&quot;username asc,email desc&quot;);List&lt;?&gt;list &#x3D; XxxMapper.selectByExample(example);&#x2F;&#x2F;相当于：select * from user where username &#x3D; &#39;wyw&#39; and username is null order by username asc,email desc 注：在iBator逆向工程生成的文件XxxExample.java中包含一个static的内部类Criteria，Criteria中的方法是定义SQL 语句where后的查询条件。 2.插入数据①insert() 1234567User user &#x3D; new User();user.setId(&quot;dsfgsdfgdsfgds&quot;);user.setUsername(&quot;admin&quot;);user.setPassword(&quot;admin&quot;)user.setEmail(&quot;wyw@163.com&quot;);XxxMapper.insert(user);&#x2F;&#x2F;相当于：insert into user(ID,username,password,email) values (&#39;dsfgsdfgdsfgds&#39;,&#39;admin&#39;,&#39;admin&#39;,&#39;wyw@126.com&#39;); 3.更新数据①updateByPrimaryKey() 1234567User user &#x3D;new User();user.setId(&quot;dsfgsdfgdsfgds&quot;);user.setUsername(&quot;wyw&quot;);user.setPassword(&quot;wyw&quot;);user.setEmail(&quot;wyw@163.com&quot;);XxxMapper.updateByPrimaryKey(user);&#x2F;&#x2F;相当于：update user set username&#x3D;&#39;wyw&#39;, password&#x3D;&#39;wyw&#39;, email&#x3D;&#39;wyw@163.com&#39; where id&#x3D;&#39;dsfgsdfgdsfgds&#39; ②updateByPrimaryKeySelective() 12345User user &#x3D; new User();user.setId(&quot;dsfgsdfgdsfgds&quot;);user.setPassword(&quot;wyw&quot;);XxxMapper.updateByPrimaryKey(user);&#x2F;&#x2F;相当于：update user set password&#x3D;&#39;wyw&#39; where id&#x3D;&#39;dsfgsdfgdsfgds&#39; ③ updateByExample() 和 updateByExampleSelective() 1234567UserExample example &#x3D; new UserExample();Criteria criteria &#x3D; example.createCriteria();criteria.andUsernameEqualTo(&quot;admin&quot;);User user &#x3D; new User();user.setPassword(&quot;wyw&quot;);XxxMapper.updateByPrimaryKeySelective(user,example);&#x2F;&#x2F;相当于：update user set password&#x3D;&#39;wyw&#39; where username&#x3D;&#39;admin&#39; updateByExample()更新所有的字段，包括字段为null的也更新，建议使用 updateByExampleSelective()更新想更新的字段 4.删除数据①deleteByPrimaryKey() 1XxxMapper.deleteByPrimaryKey(1); &#x2F;&#x2F;相当于：delete from user where id&#x3D;1 ②deleteByExample() 12345UserExample example &#x3D; new UserExample();Criteria criteria &#x3D; example.createCriteria();criteria.andUsernameEqualTo(&quot;admin&quot;);XxxMapper.deleteByExample(example);&#x2F;&#x2F;相当于：delete from user where username&#x3D;&#39;admin&#39; 5.查询数据数量①countByExample() 12345UserExample example &#x3D; new UserExample();Criteria criteria &#x3D; example.createCriteria();criteria.andUsernameEqualTo(&quot;wyw&quot;);int count &#x3D; XxxMapper.countByExample(example);&#x2F;&#x2F;相当于：select count(*) from user where username&#x3D;&#39;wyw&#39;","categories":[{"name":"工具","slug":"工具","permalink":"https://yugd.cn/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"逆向工程（MyBatis）","slug":"逆向工程（MyBatis）","permalink":"https://yugd.cn/tags/%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%EF%BC%88MyBatis%EF%BC%89/"}]},{"title":"Git","slug":"实践--GitHelp","date":"2020-05-23T01:00:00.000Z","updated":"2022-05-26T18:18:32.505Z","comments":true,"path":"posts/25246/","link":"","permalink":"https://yugd.cn/posts/25246/","excerpt":"工作必备小技能 本篇着重介绍一下 Git 写在前面 Git 是什么？能干啥？ 很多人都以为 Git 就是 GitHub ，但是二者并不同一种东西，前者是版本控制工具，而后者则是代码的存储区。 在工作中我们经常会用到，简单说就是用于管理多人协同开发项目的技术。","text":"工作必备小技能 本篇着重介绍一下 Git 写在前面 Git 是什么？能干啥？ 很多人都以为 Git 就是 GitHub ，但是二者并不同一种东西，前者是版本控制工具，而后者则是代码的存储区。 在工作中我们经常会用到，简单说就是用于管理多人协同开发项目的技术。 Git 是什么官方回答 Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。 Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。 Git 与常用的版本控制工具 CVS, Subversion 等不同，它采用了分布式版本库的方式，不必服务器端软件支持。 Git 工作流程一般工作流程如下： 克隆 Git 资源作为工作目录。【 git clone 】 在克隆的资源上添加或修改文件。 如果其他人修改了，你可以更新资源。 在提交前查看修改。 提交修改。【 git push 】 在修改完成后，如果发现错误，可以撤回提交并再次修改并提交。 Git 工作区、暂存区和版本库我们先来理解下 Git 工作区、暂存区和版本库概念： 工作区：就是你在电脑里能看到的目录。 暂存区：英文叫 stage 或 index。一般存放在 .git 目录下的 index 文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。 版本库：工作区有一个隐藏目录 .git，这个不算工作区，而是 Git 的版本库。 下面这个图展示了工作区、版本库中的暂存区和版本库之间的关系： 解释 在版本库中标记为 “index” 的区域是暂存区（stage/index），标记为 “master” 的是 master 分支所代表的目录树。 “head” 实际是指向 master 分支的一个”游标”。所以图示的命令中出现 head 的地方可以用 master 来替换。 objects 标识的区域为 Git 的对象库，实际位于 “.git/objects” 目录下，里面包含了创建的各种对象及内容。 当对工作区修改（或新增）的文件执行 git add 命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象库中的一个新的对象中，而该对象的 id 被记录在暂存区的文件索引中。 当执行提交操作（ git commit ）时，暂存区的目录树写到版本库（对象库）中，master 分支会做相应的更新。即 master 指向的目录树就是提交时暂存区的目录树。 当执行 git reset HEAD 命令时，暂存区的目录树会被重写，被 master 分支指向的目录树所替换，但是工作区不受影响。 当执行 *git rm –cached * 命令时，会直接从暂存区删除文件，工作区则不做出改变。 当执行 git checkout . 或者 *git checkout – * 命令时，会用暂存区全部或指定的文件替换工作区的文件。这个操作很危险，会清除工作区中未添加到暂存区中的改动。 当执行 git checkout HEAD . 或者 *git checkout HEAD * 命令时，会用 HEAD 指向的 master 分支中的全部或者部分文件替换暂存区和以及工作区中的文件。这个命令也是极具危险性的，因为不但会清除工作区中未提交的改动，也会清除暂存区中未提交的改动。 工作流程 (工作常用) 使用 git 的工作流程一般是这样的： 在工作目录中添加、修改文件； 将需要进行版本管理的文件放入暂存区域； 将暂存区域的文件提交到 git 仓库。 因此，git管理的文件有三种状态：已修改（modified）, 已暂存（staged）,已提交（committed） 工作区 暂存区 本地仓库 远程仓库 Git 工作使用图解一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点。 当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交。 再把HEAD指向dev，就表示当前分支在dev上。 从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变。 假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并。 合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支。 实际工作中会多人同时协作开发，所以一条 master 分支上会有多条 dev 分支。 Git 常用命令工作最常用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# 下载一个项目和它的整个代码历史$ git clone [url]# 列出所有远程分支$ git branch -r# 切换到指定分支，并更新工作区$ git checkout [branch-name]================work================ # 添加指定文件到暂存区$ git add .# 提交暂存区到仓库区$ git commit -m [message]# 推送所有分支到远程仓库$ git push================cycle================# 下载远程仓库的所有变动$ git fetch# 取回远程仓库的变化，并与本地分支合并$ git pull# 添加指定文件到暂存区$ git add .# 提交暂存区到仓库区$ git commit -m [message]# 推送所有分支到远程仓库$ git push======complete / delete the branch=====# 列出所有本地分支git branch# 列出所有远程分支git branch -r# 新建一个分支，但依然停留在当前分支git branch [branch-name]# 新建一个分支，并切换到该分支git checkout -b [branch]# 代码先推到自己的分支上$ git pull$ git add .$ git commit -m ' 描述'$ git push# 合并指定分支到当前分支$ git merge [branch]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] Git 具体命令仓库12345678# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 配置123456789# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name \"[name]\"$ git config [--global] user.email \"[email address]\" 增加/删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 代码提交123456789101112131415161718# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 分支123456789101112131415161718192021222324252627282930313233343536373839404142# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其\"提交说明\"必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat \"@&#123;0 day ago&#125;\"# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 远程同步1234567891011121314151617181920212223# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop","categories":[{"name":"工具","slug":"工具","permalink":"https://yugd.cn/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"git","slug":"git","permalink":"https://yugd.cn/tags/git/"}]},{"title":"HTML","slug":"学习--HTML","date":"2020-05-22T04:18:43.000Z","updated":"2021-10-26T14:26:00.119Z","comments":true,"path":"posts/54626/","link":"","permalink":"https://yugd.cn/posts/54626/","excerpt":"HTML(5) 样式指南和代码约定 在文档的首行声明文档类型： 1&lt;!DOCTYPE html&gt; HTML meta 描述性标签，它用来描述我们网站的一些信息 HTML 标题 HTML 标题（Heading）是通过 &lt; h1 &gt; ~ &lt; h6 &gt; 等标签进行定义的。 123&lt;h1&gt;This is a heading&lt;/h1&gt;&lt;h2&gt;This is a heading&lt;/h2&gt;&lt;h3&gt;This is a heading&lt;/h3&gt;","text":"HTML(5) 样式指南和代码约定 在文档的首行声明文档类型： 1&lt;!DOCTYPE html&gt; HTML meta 描述性标签，它用来描述我们网站的一些信息 HTML 标题 HTML 标题（Heading）是通过 &lt; h1 &gt; ~ &lt; h6 &gt; 等标签进行定义的。 123&lt;h1&gt;This is a heading&lt;/h1&gt;&lt;h2&gt;This is a heading&lt;/h2&gt;&lt;h3&gt;This is a heading&lt;/h3&gt; HTML 链接 HTML 链接是通过 标签进行定义的。 1&lt;a href=\"http://www.w3school.com.cn\"&gt;This is a link&lt;/a&gt; HTML 段落 HTML 段落是通过 标签进行定义的。 12&lt;p&gt;This is a paragraph.&lt;/p&gt;&lt;p&gt;This is another paragraph.&lt;/p&gt; HTML 图像 HTML 图像是通过 标签进行定义的。 1&lt;img src=\"w3school.jpg\" width=\"104\" height=\"142\" /&gt; HTML 元素的属性： 属性 值 描述 class classname 规定元素的类名（classname） id id 规定元素的唯一 id style style_definition 规定元素的行内样式（inline style） title text 规定元素的额外信息（可在工具提示中显示） HTML 注释标签 够通过如下语法向 HTML 源代码添加注释： 1&lt;!-- 在此处写注释 --&gt; HTML 语义元素 header 定义文档或节的页眉 nav 定义导航链接的容器 section 定义文档中的节 article 定义独立的自包含文章 aside 定义内容之外的内容（比如侧栏） footer 定义文档或节的页脚 details 定义额外的细节 summary 定义 details 元素的标题 符号实体 HTML 支持的数学符号(常用) 12345678910111213&amp;lt; &gt; 大于号&amp;gt; &lt; 小于号&amp;amp; &amp; 引号&amp;quot; \" 引号&amp;reg; 已注册 &amp;copy; 版权 &amp;nbsp; 不断行的空 框架标签（Frame） Frame 标签定义了放置在每个框架中的 HTML 文档。 在下面的这个例子中，我们设置了一个两列的框架集。第一列被设置为占据浏览器窗口的 25%。第二列被设置为占据浏览器窗口的 75%。HTML 文档 “frame_a.htm” 被置于第一个列中，而 HTML 文档 “frame_b.htm” 被置于第二个列中： 1234&lt;frameset cols=\"25%,75%\"&gt; &lt;frame src=\"frame_a.htm\"&gt; &lt;frame src=\"frame_b.htm\"&gt;&lt;/frameset&gt; 创建 Canvas 元素 向 HTML5 页面添加 canvas 元素。(Echarts) 1&lt;canvas id=\"myCanvas\" width=\"200\" height=\"100\"&gt;&lt;/canvas&gt; HTML5 Input 类型 Input 类型 - number 1Points: &lt;input type=\"number\" name=\"points\" min=\"1\" max=\"10\" /&gt; Input 类型 - email 1E-mail: &lt;input type=\"email\" name=\"user_email\" /&gt; Input 类型 - url 1Homepage: &lt;input type=\"url\" name=\"user_url\" /&gt; Input 类型 - range 1&lt;input type=\"range\" name=\"points\" min=\"1\" max=\"10\" /&gt; 属性 值 描述 max number 规定允许的最大值 min number 规定允许的最小值 step number 规定合法的数字间隔（如果 step=”3”，则合法的数是 -3,0,3,6 等） value number 规定默认值 表单初级验证 常用方式 placeholder 提示信息 required 非空 pattern 正则表达式","categories":[{"name":"HTML","slug":"HTML","permalink":"https://yugd.cn/categories/HTML/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://yugd.cn/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"Thymeleaf","slug":"实践--Thymeleaf","date":"2020-05-16T03:32:52.000Z","updated":"2021-10-26T14:26:00.143Z","comments":true,"path":"posts/51905/","link":"","permalink":"https://yugd.cn/posts/51905/","excerpt":"Thymeleaf概述使用Thymeleaf首先需要引入命名空间 1&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;","text":"Thymeleaf概述使用Thymeleaf首先需要引入命名空间 1&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt; 基本使用方法 引用web静态资源Thymeleaf通过”@{}”来引用web静态资源，例如： 1&lt;script th:src=\"@&#123;bootstrap/js/boostrap.min.js&#125;\"&gt;&lt;/script&gt; 访问model模型中的数据，例如访问一个user对象的name属性 1&lt;span th:text=\"$&#123;user.name&#125;\"&gt;&lt;/span&gt; 数据迭代例如迭代一个userlist集合 1234&lt;tr th:each=\"user : $&#123;userlist&#125;\"&gt; &lt;td th:text=\"$&#123;user.name&#125;\"&gt;tyrone&lt;/td&gt; &lt;td th:text=\"$&#123;user.age&#125;\"&gt;18&lt;/td&gt;&lt;/tr&gt; 使用th:each做循环迭代，并使用${对象.属性}来访问具体的值 进阶 123456&lt;tr th:each=\"user,userStat:$&#123;userlist&#125;\" th:class=\"$&#123;userStat.odd&#125;?'odd':'even'\"&gt; &lt;td th:text=\"$&#123;user.id&#125;\"&gt;&lt;/td&gt; &lt;td th:text=\"$&#123;user.username&#125;\"&gt;&lt;/td&gt; &lt;td th:text=\"$&#123;user.password&#125;\"&gt;&lt;/td&gt; &lt;td th:text=\"$&#123;user.petname&#125;\"&gt;&lt;/td&gt;&lt;/tr&gt; 判断是否为空 123&lt;tr th:if=\"$&#123;messages.empty&#125;\"&gt; &lt;td colspan=\"3\"&gt;No messages&lt;/td&gt;&lt;/tr&gt; 在Javascript中访问model模型数据 1234&lt;script th:inline=\"javascript\"&gt; var user = [[$&#123;user&#125;]] console.log(user.name + \"\\t\" + user.age);&lt;/script&gt; 通过添加th:inline=”javascript”到script标签来访问model模型数据通过”[[${}]]”这种格式来获取具体的值 具体表达式 *简单表达式 * 可用值表达式(后台设置): ${…} 所有可用值表达式: *{…} 比如*{name} 从可用值中查找name，如果有上下文，比如上层是object，则查object中的name属性。 消息表达式: #{…} 国际化时使用，也可以使用内置的对象，比如date格式化数据 链接表达式: @{…}用来配合link src href使用的语法 片段表达式: ~{…}用来引入公共部分代码片段，并进行传值操作使用的语法。 *替换：|The name is ${name}| * 123&lt;a href=\"\" th:href=\"@&#123;|/name/$&#123;test.size()&#125;|&#125;\"&gt;链接地址：&lt;/a&gt; //渲染后的结果 &lt;a href=\"/name/3\"&gt;链接地址：&lt;/a&gt; 布尔操作 一元 : and or 二元 : ! , not 比较 12比较：&gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le )等于：== , != ( eq , ne ) 条件 123If-then: (if) ? (then)If-then-else: (if) ? (then) : (else)Default: (value) ?: (defaultvalue) 常用操作 日期格式化 1&lt;td th:text=\"$&#123;#dates.format(content.createDate,'yyyy-MM-dd HH:mm:ss')&#125;\"&gt;&lt;/td&gt; 下拉选择 1234&lt;select name=\"subId\" id=\"subId\" lay-verify=\"\" &gt; &lt;option value=\"\"&gt;请选择&lt;/option&gt; &lt;option th:each=\"channelsub:$&#123;subchannels&#125;\" th:selected=\"$&#123;channelsub.id == subId&#125;\" th:value=\"$&#123;channelsub.id&#125;\" th:text=\"$&#123;channelsub.name&#125;\"&gt;&lt;/option&gt;&lt;/select&gt; js取值有时候需要传递参数到js中 1234&lt;script th:inline=\"javascript\" &gt; var size= [[$&#123;test.size()&#125;]]; console.info(size)&lt;/script&gt; css取值首先需要后台设置classname、align的值 12345&lt;style th:inline=\"css\"&gt; .[[$&#123;classname&#125;]] &#123; text-align: [[$&#123;align&#125;]]; &#125;&lt;/style&gt;","categories":[{"name":"后端","slug":"后端","permalink":"https://yugd.cn/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://yugd.cn/tags/Web/"}]}],"categories":[{"name":"Java体系","slug":"Java体系","permalink":"https://yugd.cn/categories/Java%E4%BD%93%E7%B3%BB/"},{"name":"Java基础","slug":"Java基础","permalink":"https://yugd.cn/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"框架","slug":"框架","permalink":"https://yugd.cn/categories/%E6%A1%86%E6%9E%B6/"},{"name":"Java","slug":"Java","permalink":"https://yugd.cn/categories/Java/"},{"name":"项目","slug":"项目","permalink":"https://yugd.cn/categories/%E9%A1%B9%E7%9B%AE/"},{"name":"容器","slug":"容器","permalink":"https://yugd.cn/categories/%E5%AE%B9%E5%99%A8/"},{"name":"面试篇","slug":"面试篇","permalink":"https://yugd.cn/categories/%E9%9D%A2%E8%AF%95%E7%AF%87/"},{"name":"博客框架","slug":"博客框架","permalink":"https://yugd.cn/categories/%E5%8D%9A%E5%AE%A2%E6%A1%86%E6%9E%B6/"},{"name":"数据库","slug":"数据库","permalink":"https://yugd.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"jdk8新特性","slug":"jdk8新特性","permalink":"https://yugd.cn/categories/jdk8%E6%96%B0%E7%89%B9%E6%80%A7/"},{"name":"实践篇","slug":"实践篇","permalink":"https://yugd.cn/categories/%E5%AE%9E%E8%B7%B5%E7%AF%87/"},{"name":"JVM","slug":"JVM","permalink":"https://yugd.cn/categories/JVM/"},{"name":"排序算法","slug":"排序算法","permalink":"https://yugd.cn/categories/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"Linux","slug":"Linux","permalink":"https://yugd.cn/categories/Linux/"},{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"服务器","slug":"服务器","permalink":"https://yugd.cn/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"中间件","slug":"中间件","permalink":"https://yugd.cn/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"工作","slug":"工作","permalink":"https://yugd.cn/categories/%E5%B7%A5%E4%BD%9C/"},{"name":"工具","slug":"工具","permalink":"https://yugd.cn/categories/%E5%B7%A5%E5%85%B7/"},{"name":"生活篇","slug":"生活篇","permalink":"https://yugd.cn/categories/%E7%94%9F%E6%B4%BB%E7%AF%87/"},{"name":"前端","slug":"前端","permalink":"https://yugd.cn/categories/%E5%89%8D%E7%AB%AF/"},{"name":"规范","slug":"规范","permalink":"https://yugd.cn/categories/%E8%A7%84%E8%8C%83/"},{"name":"Android","slug":"Android","permalink":"https://yugd.cn/categories/Android/"},{"name":"后端","slug":"后端","permalink":"https://yugd.cn/categories/%E5%90%8E%E7%AB%AF/"},{"name":"HTML","slug":"HTML","permalink":"https://yugd.cn/categories/HTML/"}],"tags":[{"name":"进阶","slug":"进阶","permalink":"https://yugd.cn/tags/%E8%BF%9B%E9%98%B6/"},{"name":"IO","slug":"IO","permalink":"https://yugd.cn/tags/IO/"},{"name":"Spring","slug":"Spring","permalink":"https://yugd.cn/tags/Spring/"},{"name":"博客","slug":"博客","permalink":"https://yugd.cn/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Docker","slug":"Docker","permalink":"https://yugd.cn/tags/Docker/"},{"name":"MySQL","slug":"MySQL","permalink":"https://yugd.cn/tags/MySQL/"},{"name":"hexo","slug":"hexo","permalink":"https://yugd.cn/tags/hexo/"},{"name":"es","slug":"es","permalink":"https://yugd.cn/tags/es/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yugd.cn/tags/SpringBoot/"},{"name":"方法引用","slug":"方法引用","permalink":"https://yugd.cn/tags/%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8/"},{"name":"optional类","slug":"optional类","permalink":"https://yugd.cn/tags/optional%E7%B1%BB/"},{"name":"stream","slug":"stream","permalink":"https://yugd.cn/tags/stream/"},{"name":"redis","slug":"redis","permalink":"https://yugd.cn/tags/redis/"},{"name":"Neo4j","slug":"Neo4j","permalink":"https://yugd.cn/tags/Neo4j/"},{"name":"NoSQl","slug":"NoSQl","permalink":"https://yugd.cn/tags/NoSQl/"},{"name":"Dubbo","slug":"Dubbo","permalink":"https://yugd.cn/tags/Dubbo/"},{"name":"Web","slug":"Web","permalink":"https://yugd.cn/tags/Web/"},{"name":"链接","slug":"链接","permalink":"https://yugd.cn/tags/%E9%93%BE%E6%8E%A5/"},{"name":"spring","slug":"spring","permalink":"https://yugd.cn/tags/spring/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://yugd.cn/tags/MyBatis/"},{"name":"druid","slug":"druid","permalink":"https://yugd.cn/tags/druid/"},{"name":"log","slug":"log","permalink":"https://yugd.cn/tags/log/"},{"name":"日志","slug":"日志","permalink":"https://yugd.cn/tags/%E6%97%A5%E5%BF%97/"},{"name":"java","slug":"java","permalink":"https://yugd.cn/tags/java/"},{"name":"currentHashMap","slug":"currentHashMap","permalink":"https://yugd.cn/tags/currentHashMap/"},{"name":"MySQL 存储引擎","slug":"MySQL-存储引擎","permalink":"https://yugd.cn/tags/MySQL-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"name":"maven","slug":"maven","permalink":"https://yugd.cn/tags/maven/"},{"name":"日积月累","slug":"日积月累","permalink":"https://yugd.cn/tags/%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://yugd.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"锁","slug":"锁","permalink":"https://yugd.cn/tags/%E9%94%81/"},{"name":"Java","slug":"Java","permalink":"https://yugd.cn/tags/Java/"},{"name":"HashMap","slug":"HashMap","permalink":"https://yugd.cn/tags/HashMap/"},{"name":"排序总结","slug":"排序总结","permalink":"https://yugd.cn/tags/%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/"},{"name":"桶排序","slug":"桶排序","permalink":"https://yugd.cn/tags/%E6%A1%B6%E6%8E%92%E5%BA%8F/"},{"name":"归并排序","slug":"归并排序","permalink":"https://yugd.cn/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"name":"选择排序","slug":"选择排序","permalink":"https://yugd.cn/tags/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/"},{"name":"插入排序","slug":"插入排序","permalink":"https://yugd.cn/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/"},{"name":"交换排序","slug":"交换排序","permalink":"https://yugd.cn/tags/%E4%BA%A4%E6%8D%A2%E6%8E%92%E5%BA%8F/"},{"name":"面试","slug":"面试","permalink":"https://yugd.cn/tags/%E9%9D%A2%E8%AF%95/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://yugd.cn/tags/MongoDB/"},{"name":"linux","slug":"linux","permalink":"https://yugd.cn/tags/linux/"},{"name":"设计模式","slug":"设计模式","permalink":"https://yugd.cn/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"结构型模式","slug":"结构型模式","permalink":"https://yugd.cn/tags/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"行为型模式","slug":"行为型模式","permalink":"https://yugd.cn/tags/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"创建型模式","slug":"创建型模式","permalink":"https://yugd.cn/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"反向代理","slug":"反向代理","permalink":"https://yugd.cn/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"},{"name":"消息队列","slug":"消息队列","permalink":"https://yugd.cn/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"小技巧","slug":"小技巧","permalink":"https://yugd.cn/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"分页插件","slug":"分页插件","permalink":"https://yugd.cn/tags/%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6/"},{"name":"折腾","slug":"折腾","permalink":"https://yugd.cn/tags/%E6%8A%98%E8%85%BE/"},{"name":"测试","slug":"测试","permalink":"https://yugd.cn/tags/%E6%B5%8B%E8%AF%95/"},{"name":"vue","slug":"vue","permalink":"https://yugd.cn/tags/vue/"},{"name":"Android","slug":"Android","permalink":"https://yugd.cn/tags/Android/"},{"name":"框架","slug":"框架","permalink":"https://yugd.cn/tags/%E6%A1%86%E6%9E%B6/"},{"name":"随笔","slug":"随笔","permalink":"https://yugd.cn/tags/%E9%9A%8F%E7%AC%94/"},{"name":"数据格式","slug":"数据格式","permalink":"https://yugd.cn/tags/%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F/"},{"name":"脚本语言","slug":"脚本语言","permalink":"https://yugd.cn/tags/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"},{"name":"逆向工程（MyBatis）","slug":"逆向工程（MyBatis）","permalink":"https://yugd.cn/tags/%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%EF%BC%88MyBatis%EF%BC%89/"},{"name":"git","slug":"git","permalink":"https://yugd.cn/tags/git/"},{"name":"前端","slug":"前端","permalink":"https://yugd.cn/tags/%E5%89%8D%E7%AB%AF/"}]}